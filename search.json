[
  {
    "objectID": "publication.html",
    "href": "publication.html",
    "title": "Publications",
    "section": "",
    "text": "References\n\nAlho, M, M Battarbee, Y Pfau-Kempf, Yu V Khotyaintsev, R Nakamura, G Cozzani, U Ganse, et al. 2022. “Electron Signatures of Reconnection in a Global eVlasiator Simulation.” Geophysical Research Letters 49 (14): e2022GL098329. https://doi.org/10.1029/2022GL098329.\n\n\nChen, Yuxi, Gábor Tóth, Hongyang Zhou, and Xiantong Wang. 2023. “FLEKS: A Flexible Particle-in-Cell Code for Multi-Scale Plasma Simulations.” Computer Physics Communications 287: 108714. https://doi.org/10.1016/j.cpc.2023.108714.\n\n\nCozzani, Giulia, M Alho, Ivan Zaitsev, Hongyang Zhou, Sanni Hoilijoki, Lucile Turc, Maxime Grandin, et al. 2025. “Interplay of Magnetic Reconnection and Current Sheet Kink Instability in the Earth’s Magnetotail.” Geophysical Research Letters 52 (2): e2024GL111848. https://doi.org/10.1029/2024GL111848.\n\n\nDubart, M, M Battarbee, U Ganse, A Osmane, F Spanier, J Suni, Andreas Johlander, et al. 2022. “Sub-Grid Modeling of Pitch-Angle Diffusion for Ion-Scale Waves in Hybrid-Vlasov Simulations with Cartesian Velocity Space.” Physics of Plasmas 29 (10). https://doi.org/10.1063/5.0096361.\n\n\nGanse, Urs, Tuomas Koskela, Markus Battarbee, Yann Pfau-Kempf, Konstantinos Papadakis, Markku Alho, Maarja Bussov, et al. 2023. “Enabling Technology for Global 3D+ 3V Hybrid-Vlasov Simulations of Near-Earth Space.” Physics of Plasmas 30 (4). https://doi.org/10.1063/5.0134387.\n\n\nGanse, Urs, Yann Pfau-Kempf, Hongyang Zhou, Liisa Juusola, Abiyot Workayehu, Fasil Kebede, Konstantinos Papadakis, et al. 2024. “The Vlasiator 5.2 Ionosphere–Coupling a Magnetospheric Hybrid-Vlasov Simulation with a Height-Integrated Ionosphere Model.” Geoscientific Model Development Discussions 2024: 1–28. https://doi.org/10.5194/gmd-2024-101.\n\n\nGeorge, H, A Osmane, EKJ Kilpua, S Lejosne, L Turc, M Grandin, MMH Kalliokoski, et al. 2022. “Estimating Inner Magnetospheric Radial Diffusion Using a Hybrid-Vlasov Simulation.” Frontiers in Astronomy and Space Sciences 9: 866455. https://doi.org/10.3389/fspas.2022.866455.\n\n\nGrandin, Maxime, Thijs Luttikhuis, Markus Battarbee, Giulia Cozzani, Hongyang Zhou, Lucile Turc, Yann Pfau-Kempf, et al. 2023. “First 3D Hybrid-Vlasov Global Simulation of Auroral Proton Precipitation and Comparison with Satellite Observations.” Journal of Space Weather and Space Climate 13: 20. https://doi.org/10.1051/swsc/2023017.\n\n\nHoraites, Konstantinos, E Rintamäki, I Zaitsev, L Turc, M Grandin, G Cozzani, H Zhou, et al. 2023. “Magnetospheric Response to a Pressure Pulse in a Three-Dimensional Hybrid-Vlasov Simulation.” Journal of Geophysical Research: Space Physics 128 (8): e2023JA031374. https://doi.org/10.1029/2023JA031374.\n\n\nJohlander, Andreas, Markus Battarbee, Lucile Turc, Urs Ganse, Yann Pfau-Kempf, Maxime Grandin, Jonas Suni, et al. 2022. “Quasi-Parallel Shock Reformation Seen by Magnetospheric Multiscale and Ion-Kinetic Simulations.” Geophysical Research Letters 49 (2): e2021GL096335. https://doi.org/10.1029/2021GL096335.\n\n\nLi, Changkun, Xianzhe Jia, Yuxi Chen, Gabor Toth, Hongyang Zhou, James A Slavin, Weijie Sun, and Gangkai Poh. 2023. “Global Hall MHD Simulations of Mercury’s Magnetopause Dynamics and FTEs Under Different Solar Wind and IMF Conditions.” Journal of Geophysical Research: Space Physics 128 (5): e2022JA031206. https://doi.org/10.1029/2022JA031206.\n\n\n———. 2024. “Kinetic Signatures, Dawn-Dusk Asymmetries, and Flux Transfer Events Associated with Mercury’s Dayside Magnetopause Reconnection from 3D MHD-AEPIC Simulations.” Journal of Geophysical Research: Space Physics 129 (6): e2024JA032669. https://doi.org/10.1029/2024JA032669.\n\n\nPalmroth, Minna, Tuija I Pulkkinen, Urs Ganse, Yann Pfau-Kempf, Tuomas Koskela, Ivan Zaitsev, Markku Alho, et al. 2023. “Magnetotail Plasma Eruptions Driven by Magnetic Reconnection and Kinetic Instabilities.” Nature Geoscience 16 (7): 570–76. https://doi.org/s41561-023-01206-2.\n\n\nPapadakis, Konstantinos, Yann Pfau-Kempf, Urs Ganse, Markus Battarbee, Markku Alho, Maxime Grandin, Maxime Dubart, et al. 2022. “Spatial Filtering in a 6D Hybrid-Vlasov Scheme for Alleviating AMR Artifacts: A Case Study with Vlasiator, Versions 5.0, 5.1, 5.2. 1.” EGUsphere 2022: 1–18. https://doi.org/10.5194/egusphere-2022-420.\n\n\nSuni, Jonas, Minna Palmroth, Lucile Turc, Markus Battarbee, Andreas Johlander, Vertti Tarvus, Markku Alho, et al. 2021. “Connection Between Foreshock Structures and the Generation of Magnetosheath Jets: Vlasiator Results.” Geophysical Research Letters 48 (20): e2021GL095655. https://doi.org/10.1029/2021GL095655.\n\n\nTarvus, Vertti, Lucile Turc, Hongyang Zhou, Takuma Nakamura, Adriana Settino, Kevin Blasl, Giulia Cozzani, et al. 2024. “Hybrid-Vlasov Modelling of Ion Velocity Distribution Functions Associated with the Kelvin–Helmholtz Instability with a Density and Temperature Asymmetry.” The Astrophysical Journal 974 (1): 62. https://doi.org/10.3847/1538-4357/ad697a.\n\n\nTesema, Facil, Minna Palmroth, Lucile Turc, Hongyang Zhou, Giulia Cozzani, Markku Alho, Yann Pfau-Kempf, et al. 2024. “Dayside Pc2 Waves Associated with Flux Transfer Events in a 3D Hybrid-Vlasov Simulation.” Geophysical Research Letters 51 (3): e2023GL106756. https://doi.org/10.1029/2023GL106756.\n\n\nTurc, Lucile, Hongyang Zhou, Vertti Tarvus, Matti Ala-Lahti, Markus Battarbee, Yann Pfau-Kempf, Andreas Johlander, et al. 2022. “A Global View of Pc3 Wave Activity in Near-Earth Space: Results from Hybrid-Vlasov Simulations.” Frontiers in Astronomy and Space Sciences 9: 989369. https://doi.org/10.3389/fspas.2022.989369.\n\n\nZhang, Chi, Chuanfei Dong, Hongyang Zhou, Jan Deca, Shaosui Xu, Yuki Harada, Shannon M Curry, et al. 2025. “Observational Characteristics of Electron Distributions in the Martian Induced Magnetotail.” Geophysical Research Letters 52 (7): e2024GL113030. https://doi.org/10.1029/2024GL113030.\n\n\nZhang, Chi, Chuanfei Dong, Hongyang Zhou, Jasper Halekas, Masatoshi Yamauchi, Hans Nilsson, Terry Liu, et al. 2025. “Anomalous Transient Enhancement of Planetary Ion Escape at Mars.” Nature Communications 16: 3159. https://doi.org/10.1038/s41467-025-58351-y.\n\n\nZhang, Chi, Hongyang Zhou, Chuanfei Dong, Yuki Harada, Masatoshi Yamauchi, Shaosui Xu, Hans Nilsson, et al. 2024. “Source of Drift-Dispersed Electrons in Martian Crustal Magnetic Fields.” The Astrophysical Journal 972 (2): 153. https://doi.org/10.3847/1538-4357/ad64d5.\n\n\nZhang, Kun, Seth Dorfman, Lucile Turc, Urs Ganse, Chen Shi, Hongyang Zhou, and Minna Palmroth. 2025. “The Early-Phase Growth of ULF Waves in the Ion Foreshock Observed in a Hybrid‐vlasov Simulation.” Journal of Geophysical Research: Space Physics 130 (June). https://doi.org/10.1029/2025JA033848.\n\n\nZhou, Hongyang. 2023. “Vlasiator. Jl: A Julia Package for Processing Vlasiator Data.” Journal of Open Source Software 8 (84): 4906. https://doi.org/10.21105/joss.04906.\n\n\nZhou, Hongyang, Gabor Toth, Xianzhe Jia, and Yuxi Chen. 2020. “Reconnection-Driven Dynamics at Ganymede’s Upstream Magnetosphere: 3-d Global Hall MHD and MHD-EPIC Simulations.” Journal of Geophysical Research: Space Physics 125 (8): e2020JA028162. https://doi.org/10.1029/2020JA028162.\n\n\nZhou, Hongyang, and Gábor Tóth. 2020. “Efficient OpenMP Parallelization to a Complex MPI Parallel Magnetohydrodynamics Code.” Journal of Parallel and Distributed Computing 139: 65–74. https://doi.org/10.1016/j.jpdc.2020.02.004.\n\n\nZhou, Hongyang, Gábor Tóth, Xianzhe Jia, Yuxi Chen, and Stefano Markidis. 2019. “Embedded Kinetic Simulation of Ganymede’s Magnetosphere: Improvements and Inferences.” Journal of Geophysical Research: Space Physics 124 (7): 5441–60. https://doi.org/10.1029/2019JA026643.\n\n\nZhou, Hongyang, Lucile Turc, Yann Pfau-Kempf, Markus Battarbee, Vertti Tarvus, Maxime Dubart, Harriet George, et al. 2022. “Magnetospheric Responses to Solar Wind Pc5 Density Fluctuations: Results from 2D Hybrid Vlasov Simulation.” Frontiers in Astronomy and Space Sciences 9: 984918. https://doi.org/10.3389/fspas.2022.984918."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "吾生于华夏大地，求学广东十二载，安徽四载，又远赴重洋，卧于安村五年，转而再跨千里，辗转北欧，如今居于波士顿。半吊子码农，虚伪的物理学工作者。在遥远的校内年代曾试图在网上小试牛刀，却也随着岁月逐渐远去。于此地留些纪念，全是希望有一片能在忙碌和琐碎中分享的空间。以前一直有想法，只是还未实践；私底下攒了不少笔记日记，却未曾相见分享中才会可能诞生他乡遇故知的佳话。从现在开始，不晚。\n分享一首网友的小诗：\n常念世情人如衣,粗布绫罗未见齐。\n轻绡初剪柔绕指,布衣三载已凋敝。\n旧衫虽衰不忍弃,奈何骨瘦今非昔。\n衣带渐宽终不悔,憔悴形销总为伊。\n见诸于各处：灯火阑珊处，烟雨任平生，一笑作春温，料峭也无晴，竹杖且徐行。"
  },
  {
    "objectID": "posts/signal-processing/index.html",
    "href": "posts/signal-processing/index.html",
    "title": "Practical Tricks in Signal Processing",
    "section": "",
    "text": "Select the best smoothing methods that works for your data. Start from simple methods first.\nModified from ADINSTRUMENTS:\n\nMoving box averaging: rectangular window (“boxcar”) averaged value, where each point has equal weighting.\n\nsimplest\nfast even for very large window widths\n\nMedian filter: the median filter sorts the data values in the window around each sample point and returns the middle value.\n\ncomputation time \\(\\mathcal{O}(n\\log{}n\\), where n is the window width\neffectively removes impulsive spikes from signals\nIt is recommended that a window width no larger than necessary is used.\n\nTriangular (Bartlett) window: triangular (Bartlett) weighting of the data points in the moving window which generates the smoothed values. With a triangular window the points in the middle of the window matter more, and the weighting decreases to zero going out towards the edges of the window.\n\nreduces the effects of aliasing, and is often a good replacement for a traditional moving average.\nfaster than Savitzky–Golay smoothing, because computation time is independent of the window width. However Savitzky–Golay has the advantage that the amplitude of some high frequency components will be better preserved.\n\nSavitzky-Golay: fits a polynomial in a window of points around each sample point, using least squares fitting.\n\nthe degree of the fitted polynomial is usually between 2 to 6\ncomputation time proportional to window width\nhas the advantage of preserving the area, position and width of peaks.\nWhen data peaks are defined by only a few points, the Savitzky–Golay method flattens peaks less than moving average/triangular smoothing with the same window width."
  },
  {
    "objectID": "posts/signal-processing/index.html#smoothing",
    "href": "posts/signal-processing/index.html#smoothing",
    "title": "Practical Tricks in Signal Processing",
    "section": "",
    "text": "Select the best smoothing methods that works for your data. Start from simple methods first.\nModified from ADINSTRUMENTS:\n\nMoving box averaging: rectangular window (“boxcar”) averaged value, where each point has equal weighting.\n\nsimplest\nfast even for very large window widths\n\nMedian filter: the median filter sorts the data values in the window around each sample point and returns the middle value.\n\ncomputation time \\(\\mathcal{O}(n\\log{}n\\), where n is the window width\neffectively removes impulsive spikes from signals\nIt is recommended that a window width no larger than necessary is used.\n\nTriangular (Bartlett) window: triangular (Bartlett) weighting of the data points in the moving window which generates the smoothed values. With a triangular window the points in the middle of the window matter more, and the weighting decreases to zero going out towards the edges of the window.\n\nreduces the effects of aliasing, and is often a good replacement for a traditional moving average.\nfaster than Savitzky–Golay smoothing, because computation time is independent of the window width. However Savitzky–Golay has the advantage that the amplitude of some high frequency components will be better preserved.\n\nSavitzky-Golay: fits a polynomial in a window of points around each sample point, using least squares fitting.\n\nthe degree of the fitted polynomial is usually between 2 to 6\ncomputation time proportional to window width\nhas the advantage of preserving the area, position and width of peaks.\nWhen data peaks are defined by only a few points, the Savitzky–Golay method flattens peaks less than moving average/triangular smoothing with the same window width."
  },
  {
    "objectID": "posts/signal-processing/index.html#filtering",
    "href": "posts/signal-processing/index.html#filtering",
    "title": "Practical Tricks in Signal Processing",
    "section": "Filtering",
    "text": "Filtering\nFiltering is critical in signal analysis. Real data consist of signals of various frequencies, and we need to separate the them out. There are two basic classes of filters: the finite impulse response (FIR) filters, and the infinite impulse response (IIR) filters.\nUnlike what I thought originally, filters are not all based on Fourier transform.\n\nHigh Pass Filter\n\nOften requires odd number of coefficients for the window. StackOverflow\n\nFor example, in the DSP.jl package,\nfs = 2.0 # sampling rate, [Hz]\nresponsetype = Highpass(0.1; fs)\ndesignmethod = FIRWindow(hanning(63)) # high pass requires odd number FIR coeffcients\ndata_high = filt(digitalfilter(responsetype, designmethod), data)\nIn practice, usually what I need is an undistorted filter with fewer parameters. In that case, we may consider IIRs such as Butterworth(n), where n is the filter order, and apply the filter twice (with the function commonly named as filtfilt) to cancel the delays. See Caveats for more discussions.\n\n\nLow Pass Filter\nresponsetype = Lowpass(1.0; fs)\n\n\nBand Pass Filter\nA combination of high pass and low pass filterings.\nresponsetype = Bandpass(0.1, 0.5; fs)"
  },
  {
    "objectID": "posts/signal-processing/index.html#ordering-of-steps",
    "href": "posts/signal-processing/index.html#ordering-of-steps",
    "title": "Practical Tricks in Signal Processing",
    "section": "Ordering of Steps",
    "text": "Ordering of Steps\nSmoothing is essentially one kind of low pass filterings. In practice, it is often better to\n\nFirst demeaning (0th order) or detrending (1st order) with some kind of smoothers.\nThen filtering the data in the band of interest."
  },
  {
    "objectID": "posts/signal-processing/index.html#caveats",
    "href": "posts/signal-processing/index.html#caveats",
    "title": "Practical Tricks in Signal Processing",
    "section": "Caveats",
    "text": "Caveats\nOnce when I checked the outputs from my low-pass filter, I noticed a phase shift with filt. Dr. Markus Kuhn explained the reason:\n\nThe filt function applies a causal filter, i.e. one that cannot look into the future (a prerequisite for real-time processing). Therefore it can only react to its input with some delay –&gt; phase shift. However there is a simple trick: applying such a filter twice on a signal that is already completely available in memory, once in forward direction, and once in backward direction, causes these delays to cancel each other out. The filtfilt function does exactly that for you. But keep in mind that it does apply the filter twice, i.e. it will double the filter order (make its transition steeper). The result is a non-causal filter (output samples will be affected by “future” input samples).\nOther methods to obtain non-causal filters exist, for example filtering in the frequency domain, i.e. pad the signal, apply the FFT, attenuate some frequencies as desired, and then apply the inverse FFT and remove the padding (and boundary effects).If you use that method, never forget that the discrete Fourier transform operates always on a single period of a periodic signal, i.e. its last and first sample are neighbours. Hence the need for padding to separate them. The padding width should be at least the length of the impulse response of your filter."
  },
  {
    "objectID": "posts/blunt-body-flow/index.html",
    "href": "posts/blunt-body-flow/index.html",
    "title": "Blunt Body Problem in Hydrodynamics",
    "section": "",
    "text": "At first sight, this seems to be an easy problem: there should be some kind of analytical solution given an ideal shape of the obstacle, say a cylinder in 2D or sphere in 3D. Unfortunately, there’re no such simple solutions.\nThe introduction here is taken from Time-Dependent Computation for Blunt Body Flows by D. FREUDENREICH’s master of engineering thesis."
  },
  {
    "objectID": "posts/blunt-body-flow/index.html#definition",
    "href": "posts/blunt-body-flow/index.html#definition",
    "title": "Blunt Body Problem in Hydrodynamics",
    "section": "Definition",
    "text": "Definition\nThe blunt body problem consists of determining the flow field, including the location and shape of the bow shock formed, due to a supersonic flow around a body with a blunt leading edge.\nThe conservation laws which describe the motion of the flow are a set of nonlinear partial differential equations. The flow is supersonic ahead of the bow shock formed but subsonic behind it, up to sonic line, after which the flow is again supersonic, as shown in fig. 1.1; hence the problem is one of mixed supersonic-subsonic flows.\nAnother difficulty is that the boundaries in the problem are not completely defined, that is, only the shape of the body is known a priori. The other boundaries consisting of the bow shock and the sonic lines have to he determined as weIl as the flow properties in the region of flow.\n\n\n\nThe blunt body problem.\n\n\nThe key thing to remember is that there is no analytical solution yet."
  },
  {
    "objectID": "posts/blunt-body-flow/index.html#classical-shock-capturing-technique",
    "href": "posts/blunt-body-flow/index.html#classical-shock-capturing-technique",
    "title": "Blunt Body Problem in Hydrodynamics",
    "section": "Classical Shock-Capturing Technique",
    "text": "Classical Shock-Capturing Technique\nIt was not until G.Moretti and M.Abbett’s idea that this becomes computationally feasible. The time-dependency of the method is based on considering the conservation equations for the problem in their unsteady configuration. In this form the governing equations are hyperbolic with respect to time, which therefore makes the technique very well suited for the unified analysis of mixed subsonic-supersonic flows.\nThe ana1ysis is started by assuming an arbitrary shock profile AB, as shown in fig. 1.2.\n\n\n\nHydrydynamic shock illustration.\n\n\nThe region that is analysed is that part of the flow field which is bounded by the assumed shock, the body surface, the plane of symmetry (AD in fig. 1.2) and an arbitrary upper boundary which must be in the supersonic region of the flow, that is, downstream of the sonic 1ine. The reason that the upper boundary shou1d be “innnersed” in the supersonic part of the f1ow, is to ensure that no distrubances are propagated back into the region under consideration; since for supersonic flows, disturbances are only propagated downstream. Thus referring to fig. 1.2, the region of flow represented by ABCD is the one under consideration. This region is then divided into a network of points and the flow parameters inc1uding pressure, density and velocity are initia11y assumed for each point.\n\n\n\nHyperboloidal body\n\n\nA time interva1 \\(\\Delta t\\) is then considered and using a modified method of characteristics the shock shape and location are re-ca1cu1ated, as well as the flow parameters just behind the shock which must satisfy the Rankine-Hugoniot equations. Simi1ar1y on the body surface the flow variables are found using the same modified method of characteristics.\nHaving found the value of the flow parameters on the boundary points, that is, the shock and body points along AB and CD respectively in fig. 1.2, the new values of the dependent variables at the inner points between the two boundaries have to be determined. This is done by using the governing equations, which inc1ude the continuity equation, the momentum equation and the energy equation written in their unsteady form, that is, the partial time derivative \\(\\partial/\\partial t\\) of the different dependent variables is retained in the above mentioned equations. These equations are then written in a finite difference form and the new values of the flow variables at each mesh point can be determined.\nThus, the flow over the whole region ABCD can be calculated for a time step \\(\\Delta t\\) from the initial1y assumed values of the flow parameters. The above procedure is then repeated for another time step using the previously obtained values of the dependent variables as initial values. The above is then again repeated and continued until no appreciable change in the flow variables is obtained between one time step and the other, at which stage the resu1ting flow pattern is said to be the steady state solution, having been reached from the unsteady flow configuration in an asymptotic manner with respect to time.\n\nInitial Setup\nA proper initial condition would speed up the computation process significantly. However, I believe any initial condition should converge to the same steady state solution.\n\n\n\nInitial shock profile.\n\n\n\n\nGoverning Equations\nCompressible fluid dynamics? I don’t have time to go through the derivations, but it seems like classical finite difference method for solving the conservation equations. While the classical methods use central differences, the modern methods are almost all based on variations of upwind schemes."
  },
  {
    "objectID": "posts/ping/index.html",
    "href": "posts/ping/index.html",
    "title": "Internet Connection",
    "section": "",
    "text": "Since I moved to the new apartment, the intermittent internet interruption has been bothering me. However, this provides me a good opportunity to learn about basic network connection concepts and diagnostic knowledge."
  },
  {
    "objectID": "posts/ping/index.html#speed",
    "href": "posts/ping/index.html#speed",
    "title": "Internet Connection",
    "section": "Speed",
    "text": "Speed\nThe most common unit for connection speed is mega bit per second (Mbps). Compared to the common numbers shown as the download and upload speed in softwares meta byte per second (MBps), you need to divide by 8.\nIn Finland for example, the basic network service that is almost free provides 10 Mbps upload/download speed. For common use cases, this is actually enough if you do one job on one device. However, if you perform multple tasks at the same time, you will encounter unwanted delays. Typically for a family, 100 Mbps is enough."
  },
  {
    "objectID": "posts/ping/index.html#stability",
    "href": "posts/ping/index.html#stability",
    "title": "Internet Connection",
    "section": "Stability",
    "text": "Stability\nFor tasks like gaming, stability is often more important than speed. Packet loss is the term used to measure how much information is lost in the network. Jitter is another term for high variations in connection speed, which acts as another quantity of stability.\nFixing stability issues are much harder than speed."
  },
  {
    "objectID": "posts/ping/index.html#ping",
    "href": "posts/ping/index.html#ping",
    "title": "Internet Connection",
    "section": "Ping",
    "text": "Ping\nping is de-facto tool for network checking, available on all platforms. It will show you in the end of its execution summary statistics like the following:\n--- 142.250.74.142 ping statistics ---\n2342 packets transmitted, 2341 received, 0.0426985% packet loss, time 4193057ms\nrtt min/avg/max/mdev = 6.334/7.367/25.469/1.011 ms"
  },
  {
    "objectID": "posts/ping/index.html#modem",
    "href": "posts/ping/index.html#modem",
    "title": "Internet Connection",
    "section": "Modem",
    "text": "Modem"
  },
  {
    "objectID": "posts/ping/index.html#router",
    "href": "posts/ping/index.html#router",
    "title": "Internet Connection",
    "section": "Router",
    "text": "Router\nRouter provides wired and wifi connection that links you to the modem. It is similar to a network traffic control center for multiple devices. For my network instability and connection problems, they seemed to be fixed by:\n\nchanging wires (less likely, but the first thing to check)\nupgrading the firmware of the router (solved the instability issue)\ncloning device MAC address (solved WAN identification issue as shown here)\n\nRegarding firmware, nowadays routers, even though most of them do have a CPU, they don’t have an operating system. Instead, they are more like embedded systems that rely upon firmwares. In my case, upgrading the firmware does provide much more stable connection.\nAnother side note is that based on the ping tests, wired connection through the router is slower than direct wired connection: about every minute I see a response time decrease from 8ns to 16ns, while the direct wired connection shows a less varying response time."
  },
  {
    "objectID": "posts/lyrics/index.html",
    "href": "posts/lyrics/index.html",
    "title": "Lyrics Collection",
    "section": "",
    "text": "在你身边路虽远未疲倦 伴你漫行一段 接一段\n越过高峰 另一峰却又见 目标推远 让理想永运在前面\n路纵崎岖亦不怕受磨练 愿一生中苦痛快乐也体验\n愉快悲哀在身边转又转 风中赏雪雾里赏花快乐回旋\n毋庸计较 快欣赏身边美丽每一天\n还愿确信美景良辰 在脚边\n愿将欢笑声盖掩苦痛那一面\n悲也好 喜也好 每天找到新发现\n让疾风吹呀吹 尽管给我俩考验\n小雨点 放心洒 早就决心向着前"
  },
  {
    "objectID": "posts/lyrics/index.html#漫步人生路",
    "href": "posts/lyrics/index.html#漫步人生路",
    "title": "Lyrics Collection",
    "section": "",
    "text": "在你身边路虽远未疲倦 伴你漫行一段 接一段\n越过高峰 另一峰却又见 目标推远 让理想永运在前面\n路纵崎岖亦不怕受磨练 愿一生中苦痛快乐也体验\n愉快悲哀在身边转又转 风中赏雪雾里赏花快乐回旋\n毋庸计较 快欣赏身边美丽每一天\n还愿确信美景良辰 在脚边\n愿将欢笑声盖掩苦痛那一面\n悲也好 喜也好 每天找到新发现\n让疾风吹呀吹 尽管给我俩考验\n小雨点 放心洒 早就决心向着前"
  },
  {
    "objectID": "posts/lyrics/index.html#画",
    "href": "posts/lyrics/index.html#画",
    "title": "Lyrics Collection",
    "section": "画",
    "text": "画\n爱情就像蓝蓝天上，一片留白有你陪我想象\n白马突然不再抽象，青蛙终于遇见灰姑娘\n就算路还漫长，我却有一种预感，我相信这灵感\n生活就像茫茫海上，一只小船勇敢乘风破浪\n而你就像不远前方，默默张开双手的港湾\n就算路还漫长，我却有一种预感，我相信这灵感\n我把你画成花，未开的一朵花，再把思念一点一滴画成雨落下\n每当我不在，请记得我的爱，就在同一天空之下遥远地灌溉\n等待秋去春来，等待下一次花开，在咫尺的未来\n爱情就像遥遥路上一束明亮却温柔的月光\n快乐原来如此简单，你在身旁就是我的天堂"
  },
  {
    "objectID": "posts/lyrics/index.html#倾城",
    "href": "posts/lyrics/index.html#倾城",
    "title": "Lyrics Collection",
    "section": "倾城",
    "text": "倾城\n热情就算 熄灭了 分手这一晚 也重要\n甜言蜜语 谎话嬉笑 都给我一点 不要缺少\n话题尽了 也不紧要 吻我至凄冷的深宵\n繁华都市 灯光普照 然而共你 已再没破晓\n红眼睛 幽幽的看着这孤城 如同苦笑 挤出的高兴\n全城为我 花光狠劲 浮华盛世 作分手布景\n传说中 痴心的眼泪会倾城 霓虹熄了 世界渐冷清\n烟花会谢 笙歌会停 显得这故事尾声 更动听\n红眼睛 幽幽的看着这孤城 如同苦笑 挤出的高兴\n琼楼玉宇 倒了阵形 来营造这 绝世的风景\n传说中 痴心的眼泪会倾城 霓虹熄了 世界渐冷清\n烟花会谢 笙歌会停 显得这故事尾声 更动听"
  },
  {
    "objectID": "posts/lyrics/index.html#成都",
    "href": "posts/lyrics/index.html#成都",
    "title": "Lyrics Collection",
    "section": "成都",
    "text": "成都\n让我掉下眼泪的，不止昨夜的酒\n让我依依不舍的，不止你的温柔\n余路还要走多久，你攥着我的手\n让我感到为难的，是挣扎的自由\n分别总是在九月，回忆是思念的愁\n深秋嫩绿的垂柳，亲吻着我额头\n在那座阴雨的小城里，我从未忘记你\n成都，带不走的，只有你\n和我在成都的街头走一走 喔…\n直到所有的灯都熄灭了也不停留\n你会挽着我的衣袖，我会把手揣进裤兜\n走到玉林路的尽头，坐在小酒馆的门口"
  },
  {
    "objectID": "posts/lyrics/index.html#声声慢",
    "href": "posts/lyrics/index.html#声声慢",
    "title": "Lyrics Collection",
    "section": "声声慢",
    "text": "声声慢\n青砖伴瓦漆，白马踏新泥\n山花蕉叶暮色丛染红巾\n屋檐洒雨滴，炊烟袅袅起\n蹉跎辗转宛然的你在哪里\n寻寻觅觅，冷冷清清\n月落乌啼月牙落孤井\n零零碎碎，点点滴滴\n梦里有花梦里青草地\n长发引涟漪,白布展石矶\n河童撑杆摆长舟渡古稀"
  },
  {
    "objectID": "posts/lyrics/index.html#梦里水乡",
    "href": "posts/lyrics/index.html#梦里水乡",
    "title": "Lyrics Collection",
    "section": "梦里水乡",
    "text": "梦里水乡\n春天的黄昏，请你陪我到梦中的水乡。让挥动的手在薄雾中飘荡。\n不要惊醒杨柳岸，那些缠绵的往事；化作一缕轻烟，已消失在远方。\n暖暖的午后，闪过一片片粉红的衣裳。谁也载不走那扇古老的窗。\n玲珑少年在岸上，守候一生的时光：为何没能做个，你盼望的新娘？\n淡淡相思都写在脸上，沉沉离别背在肩上。泪水流过脸庞，所有的话， 现在还是没有讲。\n看那青山荡漾在水上，看那晚霞吻着夕阳。我用一生的爱，去寻找那一个家，今夜你在何方。\n转回头迎着你的笑颜，心事全都被你发现。梦里遥远的幸福，它就在我的身旁。"
  },
  {
    "objectID": "posts/lyrics/index.html#祝你一路顺风",
    "href": "posts/lyrics/index.html#祝你一路顺风",
    "title": "Lyrics Collection",
    "section": "祝你一路顺风",
    "text": "祝你一路顺风\n那一天知道你要走\n我们一句话也没有说\n当午夜的钟声敲痛离别的心门\n却打不开我深深的沉默\n那一天送你送到最后\n我们一句话也没有留\n当拥挤的月台挤痛送别的人们\n却挤不掉我深深的离愁\n我知道你有千言你有万语，却不肯说出口\n你知道我好担心我好难过，却不敢说出口\n当你背上行囊，卸下那份荣耀\n我只能让眼泪留在心底\n面带着微微笑，用力的挥挥手\n祝你一路顺风\n当你踏上月台，从此一个人走\n我只能深深的祝福你\n深深的祝福你，最亲爱的朋友"
  },
  {
    "objectID": "posts/lyrics/index.html#暧昧",
    "href": "posts/lyrics/index.html#暧昧",
    "title": "Lyrics Collection",
    "section": "暧昧",
    "text": "暧昧\n眉目里似哭不似哭\n还祈求甚么说不出\n陪著你轻呼著烟圈\n到唇边讲不出满足\n你的温柔怎可以捕捉\n越来越近却从不接触\n茶没有喝光早变酸\n从来未热恋已失恋\n陪著你天天在兜圈\n那缠绕怎么可算短\n你的衣裳今天我在穿\n未留住你却仍然温暖\n徘徊在似苦又甜之间\n望不穿这暧昧的眼\n爱或情借来填一晚\n终须都归还无谓多贪\n犹疑在似即若离之间\n望不穿这暧昧的眼\n似是浓却仍然很淡\n天早灰蓝想告别\n偏未晚"
  },
  {
    "objectID": "posts/lyrics/index.html#追光者",
    "href": "posts/lyrics/index.html#追光者",
    "title": "Lyrics Collection",
    "section": "追光者",
    "text": "追光者\n如果说 你是海上的烟火 我是浪花的泡沫 某一刻 你的光照亮了我\n如果说 你是遥远的星河 耀眼得让人想哭 我是追逐着你的眼眸 总在孤单时候眺望夜空\n我可以跟在你身后 像影子追着光梦游 我可以等在这路口 不管你会不会经过\n每当我为你抬起头 连眼泪都觉得自由 有的爱像阳光倾落 边拥有边失去着\n如果说 你是夏夜的萤火 孩子们为你唱歌 那么我 是想要画你的手\n你看我 多么渺小一个我 因为你有梦可做 也许你不会为我停留 那就让我站在你的背后\n我可以跟在你身后 像影子追着光梦游 我可以等在这路口 不管你会不会经过 每当我为你抬起头\n连眼泪都觉得自由 有的爱像大雨滂沱 却依然相信彩虹\n我可以跟在你身后 像影子追着光梦游 我可以等在这路口 不管你会不会经过\n每当我为你抬起头 连眼泪都觉得自由 有的爱像大雨滂沱 却依然相信彩虹"
  },
  {
    "objectID": "posts/lyrics/index.html#倩女幽魂",
    "href": "posts/lyrics/index.html#倩女幽魂",
    "title": "Lyrics Collection",
    "section": "倩女幽魂",
    "text": "倩女幽魂\n人生路美梦似路长 路里风霜风霜扑面干\n红尘里美梦有几多方向 找痴痴梦幻中心爱路随人茫茫\n人生是百美梦与热望 梦里依稀依稀有泪光\n何从何去去觅我心中方向 风仿佛在梦中轻叹路和人茫茫\n人间路快乐少年郎 路里崎岖崎岖不见阳光\n泥尘里快乐有几多方向 一丝丝梦幻般风度雨路随人茫茫\n丝丝梦幻般风雨路随人茫茫"
  },
  {
    "objectID": "posts/lyrics/index.html#望乡",
    "href": "posts/lyrics/index.html#望乡",
    "title": "Lyrics Collection",
    "section": "望乡",
    "text": "望乡\n夕阳河边走 举目望苍穹\n缈缈炊烟飘来了思乡愁\n多少回朝夕晨暮思念着你呦\n淼淼河水是我流淌的泪\n窗外明月光 映照我脸庞\n欲知故乡亲人是否安康\n捧一盏乡酒陪伴着你呦\n无论我身在他乡与远方\n给你我的喜与悲\n不止为那山与水\n分不清是梦与醒\n忘不掉是你身影\n穿过岁月春与秋\n尝尽世间爱与愁\n何故此时别离与拥有"
  },
  {
    "objectID": "posts/lyrics/index.html#归乡",
    "href": "posts/lyrics/index.html#归乡",
    "title": "Lyrics Collection",
    "section": "归乡",
    "text": "归乡\n运河的舟楫 南来北望\n千折百回过长江\n北固楼遥望 西津渡的过往\n看不尽满眼风光\n焦山烟雨 洒落幽幽江南\n明月何时照我还\n风涛千万里 金山水连天\n却似江心一朵莲\n南来的风 东去的水\n浮云伴着游子归\n西窗的雨 归来的你\n醉在故乡斜月里"
  },
  {
    "objectID": "posts/lyrics/index.html#浣溪沙",
    "href": "posts/lyrics/index.html#浣溪沙",
    "title": "Lyrics Collection",
    "section": "浣溪沙",
    "text": "浣溪沙\n谁道飘零不可怜 旧游时节好花天\n谁道飘零不可怜 断肠人去自经年\n一片晕红才着雨 几丝柔绿乍和烟\n倩魂销尽夕阳前 当时只道是寻常\n已惯天涯莫浪愁 寒云衰草渐成秋\n已惯天涯莫浪愁 漫因睡起又登楼\n伴我萧萧惟代马 笑人寂寂有牵牛\n已惯天涯莫浪愁 劳人只合一生休\n残雪凝辉冷画屏 落梅横笛已三更\n更无人处月胧明\n我是人间惆怅客 知君何事泪纵横\n断肠声里忆平生\n谁念西风独自凉 萧萧黄叶闭疏窗\n谁念西风独自凉 沉思往事立残阳\n被酒莫惊春睡重 赌书消得泼茶香\n谁念西风独自凉 当时只道是寻常"
  },
  {
    "objectID": "posts/lyrics/index.html#一程山水一程歌",
    "href": "posts/lyrics/index.html#一程山水一程歌",
    "title": "Lyrics Collection",
    "section": "一程山水一程歌",
    "text": "一程山水一程歌\n是我将愁耽成醉醒做睡 还是愁与我的心共已累\n非我赋诗诗赋我 非我饮酒酒饮我\n何时撷身竟已沾上苍苔冷\n世上何物最易催少年老\n半是心中积霜半是人影杳\n非我离月月离我 非我思乡乡思我\n归得昔日桥边红药不识人\n究竟是我走过路 还是路正走着我\n风过西窗客渡舟船无觅处\n是我经过春与秋 还是春秋经过我\n年年一川新草遥看却似旧\n夜深孤灯照不悔\n回首青江尽是泪\n风情拍肩怕见明月减青辉\n一程山水一程歌 一笛疏雨寒吹彻\n梦在夜夜深深尽处轻轻和"
  },
  {
    "objectID": "posts/lyrics/index.html#牵手",
    "href": "posts/lyrics/index.html#牵手",
    "title": "Lyrics Collection",
    "section": "牵手",
    "text": "牵手\n因为爱着你的爱 因为梦着你的梦\n所以悲伤着你的悲伤 幸福着你的幸福\n因为路过你的路 因为苦过你的苦\n所以快乐着你的快乐 追逐着你的追逐\n因为誓言不敢听 因为承诺不敢信\n所以放心着你的沉默 去说服明天的命运\n没有风雨躲得过 没有坎坷不必走\n所以安心的牵你的手 不去想该不该回头\n也许牵了手的手 前生不一定好走\n也许有了伴的路 今生还要更忙碌\n所以牵了手的手 来生还要一起走\n所以有了伴的路 没有岁月可回头"
  },
  {
    "objectID": "posts/lyrics/index.html#荷塘月色",
    "href": "posts/lyrics/index.html#荷塘月色",
    "title": "Lyrics Collection",
    "section": "荷塘月色",
    "text": "荷塘月色\n剪一段时光缓缓流淌\n流进了月色中微微荡漾\n弹一首小荷淡淡的香\n美丽的琴音就落在我身旁\n萤火虫点亮夜的星光\n谁为我添一件梦的衣裳\n推开那扇心窗远远地望\n谁采下那一朵昨日的忧伤\n我像只鱼儿在你的荷塘\n只为和你守候那皎白月光\n游过了四季荷花依然香\n等你宛在水中央"
  },
  {
    "objectID": "posts/lyrics/index.html#蝴蝶泉边",
    "href": "posts/lyrics/index.html#蝴蝶泉边",
    "title": "Lyrics Collection",
    "section": "蝴蝶泉边",
    "text": "蝴蝶泉边\n我看到满片花儿的开放 隐隐约约有声歌唱\n开出它最灿烂笑的模样 要比那日光还要亮\n荡漾着清澄流水的泉啊 多么美丽的小小村庄\n我看到淡淡飘动的云儿 印在花衣上\n我唱着妈妈唱着的歌谣 牡丹儿绣在金匾上\n我哼着爸爸哼过的曲调 绿绿的草原上牧牛羊\n环绕着扇动银翅的蝶啊 追回那遥远古老时光\n传诵着自由勇敢的鸟啊 一直不停唱\n叶儿上轻轻跳动的水花 偶尔沾湿了我发梢\n阳光下那么奇妙的小小人间 变模样"
  },
  {
    "objectID": "posts/lyrics/index.html#如果云知道",
    "href": "posts/lyrics/index.html#如果云知道",
    "title": "Lyrics Collection",
    "section": "如果云知道",
    "text": "如果云知道\n爱一旦结冰 一切都好平静\n泪水它一旦流尽 只剩决心\n放逐自己在黑夜的边境 任由黎明一步一步向我逼近 　　 想你的心 化成灰烬\n真的有点累了 没什么力气\n有太多太多回忆 哽住呼吸\n爱你的心我无处投递 如果可以飞檐走壁找到你 　　 爱的委屈不必澄清 只要你将我抱紧\n如果云知道 想你的夜慢慢熬\n每个思念过一秒 每次呼喊过一秒\n只觉得生命不停燃烧\n如果云知道 逃不开纠缠的牢\n每当心痛过一秒 每回哭醒过一秒\n只剩下心在乞讨 你不会知道"
  },
  {
    "objectID": "posts/lyrics/index.html#知否知否",
    "href": "posts/lyrics/index.html#知否知否",
    "title": "Lyrics Collection",
    "section": "知否知否",
    "text": "知否知否\n一朝花开傍柳 寻香误觅亭侯\n纵饮朝霞半日晖 风雨着不透\n一任宫长骁瘦 台高冰泪难流\n锦书送罢蓦回首 无余岁可偷\n昨夜雨疏风骤 浓睡不消残酒 试问卷帘人 却道海棠依旧 知否 知否 应是绿肥红瘦\n昨夜雨疏风骤 浓睡不消残酒 试问卷帘人 却道海棠依旧 知否 知否 应是绿肥红瘦"
  },
  {
    "objectID": "posts/lyrics/index.html#一絲不掛",
    "href": "posts/lyrics/index.html#一絲不掛",
    "title": "Lyrics Collection",
    "section": "一絲不掛",
    "text": "一絲不掛\n分手時內疚的你一轉臉\n為日後不想有甚麼牽連\n當我工作睡覺禱告娛樂那麼刻意過好每天\n誰料你見鬆綁了又願見面\n誰當初想擺脫被圍繞左右\n過後誰人被遙控於世界盡頭\n勒到呼吸困難才知變扯線木偶\n這根線其實說到底 誰拿捏在手\n不聚不散 只等你給另一對手擒獲\n那時青絲 不會用上餘生來量度\n但我拖著軀殼 發現沿途尋找的快樂\n仍繫於你肩膊 或是其實在等我捨割\n然後斷線風箏會直飛天國\n這些年望你緊抱他出現\n還憑何擔心再互相糾纏\n給我找個伴侶找到留下你的足印也可發展\n全為你背影逼我步步向前\n如一根絲牽引著拾荒之路\n結在喉嚨內痕癢得似有還無\n為你安心我在微笑中想吐未吐\n只想你和伴侶要好才頑強病好\n不聚不散 只等你給另一對手擒獲\n以為青絲 不會用上餘生來量度\n但我拖著軀殼 發現沿途尋找的快樂\n仍繫於你肩膊 或是其實在等我捨割\n然後斷線風箏會直飛天國\n一直不覺 綑綁我的未可扣緊承諾\n滿頭青絲 想到白了仍懶得脫落\n被你牽動思覺 最後誰願纏繞到天國\n然後撕裂軀殼 欲斷難斷在 不甘心去捨割\n難道愛本身可愛在於束縛\n無奈你我牽過手 沒繩索"
  },
  {
    "objectID": "posts/lyrics/index.html#岁月如歌",
    "href": "posts/lyrics/index.html#岁月如歌",
    "title": "Lyrics Collection",
    "section": "岁月如歌",
    "text": "岁月如歌\n爱上了看见你如何不懂谦卑\n去讲心中理想不会俗气\n犹如看得见晨曦才能欢天喜地\n抱着你我每次回来多少惊喜\n也许一生太短陪着你\n情感有若行李仍然沉重待我整理\n再见了背向你眉头多少伤悲\n也许不必再讲所有道理\n何时放松我自己才能花天酒地\n抱着你我说过如何一起高飞\n这天只想带走还是你\n如重温往日邮寄但会否疲倦了嬉戏\n天气不似预期但要走总要飞\n道别不可再等你不管有没有机\n给我体贴入微但你手如明日便要远离\n愿你可以留下共我曾愉快的忆记\n当世事再没完美可远在岁月如歌中找你"
  },
  {
    "objectID": "posts/lyrics/index.html#k歌之王",
    "href": "posts/lyrics/index.html#k歌之王",
    "title": "Lyrics Collection",
    "section": "K歌之王",
    "text": "K歌之王\n我唱得不夠動人你別皺眉 我願意和你約定至死\n我只想嬉戲唱遊到下世紀 請你別嫌我將這煽情奉獻給你\n還能憑甚麼？擁抱若未能令你興奮 便宜地唱出 寫在情歌的性感\n還能憑甚麼？要是愛不可感動人 俗套的歌詞 煽動你惻忍\n誰人又相信一世一生這膚淺對白 來吧送給你叫幾百萬人流淚過的歌\n如從未聽過誓言如幸福摩天輪 才令我因你要呼天叫地愛愛愛愛那麼多\n將我漫天心血一一拋到銀河 誰是垃圾 誰不捨我難過 分一丁目贈我\n我唱出心裡話時眼淚會流 要是怕難過抱住我手\n我只得千語萬言放在你心 比渴望地老天荒更簡單未算罕有\n誰人又相信一世一生這膚淺對白 來吧送給你叫幾百萬人流淚過的歌\n如從未聽過誓言如幸福摩天輪 才令我因你要呼天叫地愛愛愛愛那麼多\n給你用力作二十首不捨不棄 還附送你愛得過火\n給你賣力唱二十首真心真意 米高峰都因我動容\n無人及我 你怎麼竟然說K歌之王 是我\n我只想跟你未來浸在愛河 而你那呵欠絕得不能絕 絕到溶掉我"
  },
  {
    "objectID": "posts/lyrics/index.html#青城山下白素贞",
    "href": "posts/lyrics/index.html#青城山下白素贞",
    "title": "Lyrics Collection",
    "section": "青城山下白素贞",
    "text": "青城山下白素贞\n青城山下白素贞 洞中千年修此身\n勤修苦练来得道 脱胎换骨变成人\n一心向道无杂念 皈依三宝弃红尘\n望求菩萨来点化 渡我素贞出凡尘"
  },
  {
    "objectID": "posts/lyrics/index.html#地厚天高",
    "href": "posts/lyrics/index.html#地厚天高",
    "title": "Lyrics Collection",
    "section": "地厚天高",
    "text": "地厚天高\n地有多厚天有多高，地有多厚天有多高\n星星眨着眼月儿划问号，彗星拖着长长的尾巴\n彩虹来架桥，时光在飞逝\n生命知多少，风儿吹起朵朵浪花\n太阳开口笑，哦哦只要你爱想爱问爱动脑\n天地间奇妙的问题你全明了，哦只要你爱想爱问爱动脑\n天地间奇妙的问题你全明了"
  },
  {
    "objectID": "posts/lyrics/index.html#不老的传说",
    "href": "posts/lyrics/index.html#不老的传说",
    "title": "Lyrics Collection",
    "section": "不老的传说",
    "text": "不老的传说\n流传在月夜那故事\n当中的主角极漂亮\n如神话活在这世上\n为世间不朽的爱轻轻唱\n若是你共情人 热切信有爱\n永远真挚地 投入这个梦乡\n合着两眼定能遇见那爱侣\n给你讲出永不老那点真相\n徘徊夜里时常亦听到歌颂\n真爱总会是永远\n谁人亦会 重拾逝去了的梦\n在星辉闪闪午夜 飘于晚空\n流传在月夜那故事\n将星光深处亦照亮\n如神话活在这世上\n为你将不朽的爱轻轻唱\n遇着故事内描述那对爱侣\n永远不老地游在每个梦乡\n日夜变换未能换却那季节\n因那心中爱坚固永不转向\n无人夜里 铉乐在远远歌颂\n真爱总会是永远\n人成熟了 仍然被暗暗牵动\n伴星辉跟恋爱梦 深深抱拥"
  },
  {
    "objectID": "posts/lyrics/index.html#那女孩对我说",
    "href": "posts/lyrics/index.html#那女孩对我说",
    "title": "Lyrics Collection",
    "section": "那女孩对我说",
    "text": "那女孩对我说\n心很空 天很大 雲很重 我恨孤單 卻趕不走\n捧著她的名字 她的喜怒哀樂 往前走 多久了\n一個人心中只有一個寶貝 久了之後 她變成了眼淚\n淚一滴在左手 凝固成為寂寞 往回看 有什麼\n那女孩對我說 說我保護她的夢\n說這個世界 對她這樣的不多\n她漸漸忘了我 但是她並不曉得\n遍體鱗傷的我 一天也沒再愛過\n那女孩對我說 說我是一個小偷\n偷她的回憶 塞進我的腦海中\n我不需要自由 只想揹著她的夢\n一步步向前走 她給的永遠 不重"
  },
  {
    "objectID": "posts/lyrics/index.html#如果当时",
    "href": "posts/lyrics/index.html#如果当时",
    "title": "Lyrics Collection",
    "section": "如果当时",
    "text": "如果当时\n为什么 你当时对我好 又为什么 现在变得冷淡了\n我知道 爱要走难阻挠 反正不是我的 我也不该要\n你和我 曾经有共同爱好 谁的耳边 总有绝句在萦绕\n我们俩 用文言文对话真的很搞笑 还笑那曹操贪慕着小乔\n天灰了 雨坠了 视线要模糊了 此时感觉到你的重要\n爱走了 心走了 你说你要走了 我为你唱最后的古谣\n红雨瓢泼泛起了回忆怎么潜 你美目如当年 流转我心间\n渡口边最后一面洒下了句点 与你若只如初见 何须感伤离别"
  },
  {
    "objectID": "posts/lyrics/index.html#半生雪",
    "href": "posts/lyrics/index.html#半生雪",
    "title": "Lyrics Collection",
    "section": "半生雪",
    "text": "半生雪\n霜月落庭前 照谁一夜无眠 提笔惊扰烛火 回忆难写\n看人间故事 都逃不过离别 数不完的阴晴换圆缺\n半生风雪 吹不散花落时节的眼泪\n唤不回 孤雁终要南飞\n心事谁了解 唯有明月来相随\n思念予我眉间又几分憔悴\n半生风雪 吹不散岁月留下的眼泪\n换不回 青丝已尽成灰\n结局谁来写 写不完爱恨缠绵\n徒我顾影自怜自叹又几遍"
  },
  {
    "objectID": "posts/lyrics/index.html#沧海一声笑",
    "href": "posts/lyrics/index.html#沧海一声笑",
    "title": "Lyrics Collection",
    "section": "沧海一声笑",
    "text": "沧海一声笑\n滄海一聲笑 滔滔兩岸潮\n浮沉隨浪 只記今朝\n蒼天笑 紛紛世上潮\n誰負誰勝出 天知曉\n江山笑 煙雨遙\n濤浪淘盡紅塵俗世幾多嬌\n清風笑 竟惹寂寥\n豪情還剩了一襟晚照\n蒼生笑 不再寂寥\n豪情仍在痴痴笑笑"
  },
  {
    "objectID": "posts/lyrics/index.html#最初的梦想",
    "href": "posts/lyrics/index.html#最初的梦想",
    "title": "Lyrics Collection",
    "section": "最初的梦想",
    "text": "最初的梦想\n如果骄傲没被现实大海冷冷拍下 又怎会懂得要多努力 才走得到远方\n如果梦想不曾坠落悬崖千钧一发 又怎会晓得执着的人 拥有隐形翅膀\n把眼泪种在心上 会开出勇敢的花\n可以在疲惫的时光 闭上眼睛闻到一种芬芳\n就像好好睡了一夜直到天亮 又能边走着边哼着歌 用轻快的步伐\n沮丧时总会明显感到孤独的重量\n多渴望懂得的人给些温暖借个肩膀\n很高兴一路上 我们的默契那么长\n穿过风又绕了弯 心还连着像往常一样\n最初的梦想紧握在手上 最想要去的地方 怎么能在半路就返航\n最初的梦想绝对会到达 实现了真的渴望 才能够算到过了天堂"
  },
  {
    "objectID": "posts/lyrics/index.html#这世界那么多人",
    "href": "posts/lyrics/index.html#这世界那么多人",
    "title": "Lyrics Collection",
    "section": "这世界那么多人",
    "text": "这世界那么多人\n这世界有那么多人 人群里 敞着一扇门\n我迷朦的眼睛里长存 初见你 蓝色清晨\n这世界有那么多人 多幸运 我有个我们\n这悠长命运中的晨昏 常让我 望远方出神\n灰树叶飘转在池塘 看飞机轰的一声去远乡\n光阴的长廊 脚步声叫嚷 灯一亮 无人的空荡\n晚风中闪过 几帧从前啊 飞驰中旋转 已不见了吗\n远光中走来 你一身晴朗 身旁那么多人 可世界不声 不响\n笑声中浮过 几张旧模样 留在梦田里 永远不散场\n暖光中醒来 好多话要讲 世界那么多人 可是它不声 不响\n这世界有那么个人 活在我 飞扬的青春\n在泪水里浸湿过的长吻 常让我 想啊想出神"
  },
  {
    "objectID": "posts/lyrics/index.html#梦醒时分",
    "href": "posts/lyrics/index.html#梦醒时分",
    "title": "Lyrics Collection",
    "section": "梦醒时分",
    "text": "梦醒时分\n你说你爱了不该爱的人，你的心中满是伤痕。\n你说你犯了不该犯的错，心中满是悔恨。\n你说你尝尽了生活的苦，找不到可以相信的人。\n你说你感到万分沮丧，甚至开始怀疑人生。\n早知道伤心总是难免的，你又何苦一往情深？\n因为爱情总是难舍难分，何必在意那一点点温存。\n要知道伤心总是难免的，在每一个梦醒时分。\n有些事情你现在不必问，有些人你永远不必等。"
  },
  {
    "objectID": "posts/lyrics/index.html#旅行的意义",
    "href": "posts/lyrics/index.html#旅行的意义",
    "title": "Lyrics Collection",
    "section": "旅行的意义",
    "text": "旅行的意义\n你看过了许多美景 你看过了许多美女\n你迷失在地图上每一道短暂的光阴\n你品尝了夜的巴黎 你踏过下雪的北京 你熟记书本里每一句你最爱的真理\n却说不出你爱我的原因 却说不出你欣赏我哪一种表情\n却说不出在什么场合我曾让你动心 说不出离开的原因\n你累积了许多飞行 你用心挑选纪念品\n你收集了地图上每一次的风和日丽\n你拥抱热情的岛屿 你埋葬记忆的土耳其 你留恋电影里美丽的不真实的场景\n却说不出你爱我的原因 却说不出你欣赏我哪一种表情\n却说不出在什么场合我曾让你分心 说不出旅行的意义\n你勉强说出你爱我的原因 却说不出你欣赏我哪一种表情\n却说不出在什么场合我曾让你动心 说不出旅行的意义\n勉强说出你为我寄出的每一封信 都是你离开的原因\n你离开我 就是旅行的意义"
  },
  {
    "objectID": "posts/lyrics/index.html#怎叹",
    "href": "posts/lyrics/index.html#怎叹",
    "title": "Lyrics Collection",
    "section": "怎叹",
    "text": "怎叹\n唱一首水调歌头 那明月何时能有\n我站在梧桐树下 期待你回眸\n若今生牵你的手 又哪怕岁月悠悠\n只盼那清风依旧 与你长相守\n散不去只剩温柔 这秋风吹去离愁\n只感叹浮生若梦 无人在身后\n抬头看梨花翩翩 是谁在独自承受\n怎奈何蓦然回首 你皱起眉头\n怎叹呐山有木兮那木有枝 心悦君兮啊君不知\n可是前世与你错过太多事 怎叹呐秋有月兮那月有诗\n也不及与你相守时 梦里与你山水再相识"
  },
  {
    "objectID": "posts/lyrics/index.html#原來你也在這裡",
    "href": "posts/lyrics/index.html#原來你也在這裡",
    "title": "Lyrics Collection",
    "section": "原來你也在這裡",
    "text": "原來你也在這裡\n請允許我塵埃落定 用沉默埋葬了過去\n滿身風雨我從海上來 才隱居在這沙漠裡\n該隱瞞的事總清晰 千言萬語只能無語\n愛是天時地利的迷信 喔 原來你也在這裡\n啊 那一個人 是不是只存在夢境裡\n為什麼我用盡全身力氣 卻換來半生回憶\n若不是你渴望眼睛 若不是我救贖心情\n在千山萬水人海相遇 喔 原來你也在這裡"
  },
  {
    "objectID": "posts/lyrics/index.html#我的果汁分你一半",
    "href": "posts/lyrics/index.html#我的果汁分你一半",
    "title": "Lyrics Collection",
    "section": "我的果汁分你一半",
    "text": "我的果汁分你一半\n我要那个那个那个 那个那个那个 那个那个那个啊\n你要那个那个那个 那个那个那个 那个那个那个啊\n月亮弯弯 绵绵绵绵缠缠 果汁分你一半 爱相互分担\n长路漫漫磕磕磕磕绊绊 果汁分你一半 爱相互扶搀\n今晚多么美满 约会相当浪漫 我果汁分你一半\n我结账你买单谁跟谁别细算 我果汁分你一半\n偶尔我也会烦 脸色说翻就翻 我果汁分你一半\n就算怎么艰难也要保持乐观 我果汁分你一半\n当习惯成自然 一个眼神交换 我果汁分你一半\n我吃饭你刷碗 不是我要偷懒 我果汁分你一半\n偶尔你也会乱 发脾气不敢管 我果汁分你一半\n向前向后攻占 粘我阴魂不散 我果汁分你一半"
  },
  {
    "objectID": "posts/lyrics/index.html#月光",
    "href": "posts/lyrics/index.html#月光",
    "title": "Lyrics Collection",
    "section": "月光",
    "text": "月光\n哦 月光洒在每个人心上 让回家的路 有方向\n哦 离开太久的故乡 和老去的爹娘\n哦 迎着月色散落的光芒 把古老的歌谣 轻轻唱\n哦 无论走到任何的地方 都别忘了故乡\n是什么力量 让我们坚强\n是什么离去 让我们悲伤\n是什么付出 让我们坦荡\n是什么结束 让我们成长\n是什么誓言 让我们幻想\n是什么距离 让我们守望\n是什么欲望 让我们疯狂\n是什么风雨 让我们流浪\n哦 月亮高高挂在了天上 为回家的人 照着亮\n哦 离开太久的故乡 快快回去见爹娘"
  },
  {
    "objectID": "posts/lyrics/index.html#大鱼",
    "href": "posts/lyrics/index.html#大鱼",
    "title": "Lyrics Collection",
    "section": "大鱼",
    "text": "大鱼\n海浪无声将夜幕深深淹没 漫过天空尽头的角落\n大鱼在梦境的缝隙里游过 凝望你沉睡的轮廓\n看海天一色 听风起雨落 执子手吹散苍茫茫烟波\n大鱼的翅膀 已经太辽阔 我松开时间的绳索\n怕你飞远去 怕你离我而去 更怕你永远停留在这里\n每一滴泪水 都向你流淌去 倒流进天空的海底\n看你飞远去 看你离我而去 原来你生来就属于天际\n每一滴泪水 都向你流淌去 倒流回最初的相遇"
  },
  {
    "objectID": "posts/lyrics/index.html#相思",
    "href": "posts/lyrics/index.html#相思",
    "title": "Lyrics Collection",
    "section": "相思",
    "text": "相思\n红豆生南国 是很遥远的事情\n相思算什么 早无人在意\n醉卧不夜城 处处霓虹\n酒杯中好一片滥滥风情\n最肯忘却古人诗\n最不屑一顾是相思\n守着爱怕人笑 还怕人看清\n春又来看红豆开 竟不见有情人去采\n烟花拥着风流真情不在"
  },
  {
    "objectID": "posts/lyrics/index.html#情人",
    "href": "posts/lyrics/index.html#情人",
    "title": "Lyrics Collection",
    "section": "情人",
    "text": "情人\n盼望你没有为我又再渡暗中淌泪\n我不想留底 你的心空虚\n盼望你别再让我象背负太深的罪\n我的心如水 你不必痴醉\n盼望我别去后会共你在远方相聚\n每一天望海 每一天相对\n盼望你现已没有让我别去的恐惧\n我即使离开 你的天空里\n哦 你可知谁甘心归去 你与我之间有谁\n是缘是情是童真 还是意外\n有泪有罪有付出 还有忍耐\n是人是墙是寒冬 藏在眼内\n有日有夜有幻想 没法等待\n多少春秋风雨改 多少崎岖不变爱 多少唏嘘的你在人海"
  },
  {
    "objectID": "posts/lyrics/index.html#在水一方",
    "href": "posts/lyrics/index.html#在水一方",
    "title": "Lyrics Collection",
    "section": "在水一方",
    "text": "在水一方\n绿草苍苍 白雾茫茫\n有位佳人 在水一方\n绿草萋萋 白雾迷离\n有位佳人 靠水而居\n我愿逆流而上 依偎在她身旁\n无奈前有险滩 道路又远又长\n我愿顺流而下 找寻她的方向\n却见依稀仿佛 她在水的中央\n我愿逆流而上 与她轻柔细语\n无奈前有险滩 道路曲折无已\n我愿顺流而下 找寻她的踪迹\n却见仿佛依稀 她在水中伫立\n绿草苍苍 白雾茫茫\n有位佳人 在水一方"
  },
  {
    "objectID": "posts/lyrics/index.html#一路生花",
    "href": "posts/lyrics/index.html#一路生花",
    "title": "Lyrics Collection",
    "section": "一路生花",
    "text": "一路生花\n海上的晚霞像年少的畫 鋪在天空等海鷗銜走它\n遙遠的帆任風浪拍打 為夢再痛也不會害怕\n遠走的風沙去誰的天涯 春天可曾在哪裡見過他\n時間的手撫過了臉頰 他們誰都沉默不說話\n我希望許過的願望一路生花 護送那時的夢抵擋過風沙\n指尖的櫻花如詩寫誰的韶華 瘋狂的熱愛夾帶著文雅\n我希望許過的願望一路生花 將那雨中的人藏在屋簷下\n歲月在沖刷逆流滄桑的喧嘩 安靜的夜晚你在想誰嗎"
  },
  {
    "objectID": "posts/lyrics/index.html#漠河舞厅",
    "href": "posts/lyrics/index.html#漠河舞厅",
    "title": "Lyrics Collection",
    "section": "漠河舞厅",
    "text": "漠河舞厅\n我从没有见过极光出现的村落 也没有见过有人 在深夜放烟火\n晚星就像你的眼睛杀人又放火 你什么都没有说 野风惊扰我\n三千里 偶然见过你 花园里 有裙翩舞起\n灯光底 抖落了晨曦 在1980的漠河舞厅\n可是你 惹怒了神明 让你去 还那么年轻\n都怪你 远山冷冰冰 在一个人的漠河舞厅\n如果有时间 你会来看一看我吧\n看大雪如何衰老的 我的眼睛如何融化\n如果你看见我的话 请转过身去再惊讶\n我怕我的眼泪 我的白发像羞耻的笑话\n如果有一天 我的信念忽然倒塌\n城市的花园没有花 广播里的声音嘶哑\n如果真有这天的话 你会不会奔向我啊\n尘封入海吧 尘封入海吧"
  },
  {
    "objectID": "posts/lyrics/index.html#孤独患者",
    "href": "posts/lyrics/index.html#孤独患者",
    "title": "Lyrics Collection",
    "section": "孤独患者",
    "text": "孤独患者\n欢笑声　欢呼声 炒热气氛　心却很冷\n聚光灯　是种蒙恩 我却不能　喊等一等\n我真佩服我　还能幽默 掉眼泪时　用笑掩过\n怕人看破　顾虑好多 不谈寂寞　我们就都快活\n笑越大声　越是残忍 挤满体温　室温更冷\n万一关灯　空虚扰人 我却不能　喊等一等\n你说你爱我　却一直说 说我不该　窝在角落\n策划逃脱　这也有错 连我脆弱　的权利都掠夺\n我不唱声嘶力竭的情歌 不表示没有心碎的时刻\n我不曾摊开伤口任宰割 愈合　就无人晓得　我内心挫折\n活像个孤独患者　自我拉扯 外向的孤独患者　有何不可\n我不要声嘶力竭的情歌 来提示我需要你的时刻\n表面镇定并不是保护色 反而　是要你懂得　我不知为何\n活像个孤独患者　自我拉扯 外向的孤独患者　需要认可"
  },
  {
    "objectID": "posts/lyrics/index.html#你",
    "href": "posts/lyrics/index.html#你",
    "title": "Lyrics Collection",
    "section": "你",
    "text": "你\n你 从天而降的你 落在我的马背上\n如玉的模样 清水般的目光 一丝浅笑让我心发烫\n你 头也不回的你 展开你一双翅膀\n寻觅著方向 方向在前方 一声叹息将我一生变凉\n你在那万人中央 感受那万丈荣光\n看不见你的眼睛 是否会藏着泪光\n我没有那种力量 想忘也终不能忘\n只等到漆黑夜晚 梦一回那曾经心爱的姑娘"
  },
  {
    "objectID": "posts/lyrics/index.html#囚鸟",
    "href": "posts/lyrics/index.html#囚鸟",
    "title": "Lyrics Collection",
    "section": "囚鸟",
    "text": "囚鸟\n我是被你囚禁的鸟 已经忘了天有多高\n如果离开你给我的小小城堡 不知还有谁能依靠\n我是被你囚禁的鸟 得到的爱越来越少\n看着你的笑在别人眼中燃烧 我却要不到一个拥抱\n我像是一个你可有可无的影子 冷冷的看着你说谎的样子\n这撩乱的城市 容不下我的痴 是什么让你这样迷恋这样的放肆\n我像是一个你可有可无的影子 和寂寞交换着悲伤的心事\n对爱无计可施 这无味的日子 眼泪是唯一的奢侈"
  },
  {
    "objectID": "posts/lyrics/index.html#灰色轨迹",
    "href": "posts/lyrics/index.html#灰色轨迹",
    "title": "Lyrics Collection",
    "section": "灰色轨迹",
    "text": "灰色轨迹\n酒一再沉溺 何时麻醉我抑郁 过去了的一切会平息\n冲不破墙壁 前路没法看得清 再有哪些挣扎与被迫\n心一再回忆 谁能为我去掩饰 到哪里都跟你要认识\n洗不去痕迹 何妨面对要可惜 各有各的方向与目的\n踏着灰色的轨迹 尽是深渊的水影\n我已背上一身苦困后悔与唏嘘 你眼里却此刻充满泪\n这个世界已不知不觉的空虚 喔 不想你别去"
  },
  {
    "objectID": "posts/lyrics/index.html#铁血丹心",
    "href": "posts/lyrics/index.html#铁血丹心",
    "title": "Lyrics Collection",
    "section": "铁血丹心",
    "text": "铁血丹心\n依稀往梦似曾见 心内波澜现\n抛开世事断仇怨 相伴到天边\n逐草四方沙漠苍茫 （冷风吹天苍苍）\n哪惧雪霜扑面 （藤树相连）\n射雕引弓塞外奔驰 （猛风沙野茫茫）\n笑傲此生无厌倦 （藤树两缠绵）\n天苍苍野茫茫万般变幻 （应知爱意似流水 斩不断理还乱）\n身经百劫也在心间 恩义两难断"
  },
  {
    "objectID": "posts/lyrics/index.html#笑看风云",
    "href": "posts/lyrics/index.html#笑看风云",
    "title": "Lyrics Collection",
    "section": "笑看风云",
    "text": "笑看风云\n谁没有一些刻骨铭心事 谁能预计后果\n谁没有一些旧恨心魔 一点点无心错\n谁没有一些得不到的梦 谁人负你负我多\n谁愿意解释为了什么 一笑已经风云过\n活得开心心不记恨 为今天欢笑唱首歌\n任胸襟吸收新的快乐 在晚风中敞开心锁\n谁愿记沧桑匆匆往事 谁人是对是错\n从没有解释为了什么 一笑看风云过"
  },
  {
    "objectID": "posts/lyrics/index.html#假如爱有天意",
    "href": "posts/lyrics/index.html#假如爱有天意",
    "title": "Lyrics Collection",
    "section": "假如爱有天意",
    "text": "假如爱有天意\n当天边那颗星出现 你可知我又开始想念\n有多少爱恋只能遥遥相望 就像月光洒向海面\n年少的我们曾以为 相爱的人就能到永远\n当我们相信情到深处在一起 听不见风中的叹息\n谁知道爱是什么 短暂的相遇却念念不忘\n用尽一生的时间 竟学不会遗忘\n如今我们已天各一方 生活得像周围人一样\n眼前人给我最信任的依赖 但愿你被温柔对待\n多少恍惚的时候 仿佛看见你在人海川流\n隐约中你已浮现 一转眼又不见\n短暂的相遇却念念不忘\n多少恍惚的时候 仿佛看见你在人海川流\n隐约中你已浮现 一转眼又不见\n当天边那颗星出现 你可知我又开始想念\n有多少爱恋今生无处安放 冥冥中什么已改变\n月光如春风拂面"
  },
  {
    "objectID": "posts/lyrics/index.html#想见你",
    "href": "posts/lyrics/index.html#想见你",
    "title": "Lyrics Collection",
    "section": "想见你",
    "text": "想见你\n当爱情遗落成遗迹 用象形刻划成回忆\n想念几个世纪 才是刻骨铭心\n\n若能回到冰河时期 多想把你抱紧处理\n你的笑多疗愈 让人生也苏醒\n失去 你的风景 像座废墟 像失落文明\n能否 一场奇迹 一线生机 能不能 有再一次 相遇\n\n任时光更迭了四季 任宇宙物换或星移\n永远不退流行 是青涩的真心\n未来 先进科技 无法模拟 你拥抱暖意\n如果 另个时空 另个身体 能不能 换另一种 结局\n\n想见你 只想见你 未来过去 我只想见你\n穿越了 千个万个 时间线里 人海里相依\n用尽了 逻辑心机 推理爱情 最难解的谜\n会不会 妳也 和我一样 在等待一句 我愿意\n\n想见你 每个朝夕 想见你 每个表情\n想穿越 每个平行 在未来 和过去 紧紧相依\n想follow 每则IG 不错过 你的踪迹\n会不会 你也一样 等待着那句 我愿意"
  },
  {
    "objectID": "posts/lyrics/index.html#其实都没有",
    "href": "posts/lyrics/index.html#其实都没有",
    "title": "Lyrics Collection",
    "section": "其实都没有",
    "text": "其实都没有\n从什么都没有的地方\n到什么都没有的地方\n我们 像没发生事一样\n自顾地 走在路上\n忘掉了的人只是泡沫\n用双手轻轻一触就破\n泛黄 有他泛黄的理由\n思念将 越来越薄\n你微风中浮现的 从前的面容\n已被吹送到天空\n我在脚步急促的城市之中\n依然一个人生活\n我也曾经憧憬过 后来没结果\n只能靠一首歌真的在说我\n是用那种特别干哑的喉咙\n唱着淡淡的哀愁\n我也曾经做梦过 后来更寂寞\n我们能留下的其实都没有\n原谅我用特别沧桑的喉咙\n假装我很怀旧\n假装我很痛\n其实我真的很怀旧\n而且也很痛"
  },
  {
    "objectID": "posts/lyrics/index.html#rhythm-of-the-rain",
    "href": "posts/lyrics/index.html#rhythm-of-the-rain",
    "title": "Lyrics Collection",
    "section": "Rhythm of the Rain",
    "text": "Rhythm of the Rain\nListen to the rhythm of the falling rain\nTelling me just what a fool I’ve been\nI wish that it would go and let me cry in vain\nAnd let me be alone again\nThe only girl I care about has gone away\nLooking for a brand new start\nBut little does she know that when she left that day\nAlong with her she took my heart\nRain please tell me now does that seem fair\nFor her to steal my heart away when she don’t care?\nI can’t love another when my hearts somewhere far away\nRain won’t you tell her that I love her so\nPlease ask the sun to set her heart aglow\nRain in her heart and let the love we knew start to grow"
  },
  {
    "objectID": "posts/lyrics/index.html#泪桥",
    "href": "posts/lyrics/index.html#泪桥",
    "title": "Lyrics Collection",
    "section": "泪桥",
    "text": "泪桥\n无心过问你的心里我的吻\n厌倦我的亏欠 代替你所爱的人\n这个时候 我心落花一样飘落下来\n顿时 我的视线 失去了色彩\n知道你也一样不善于表白\n想象你的相爱编织的谎言懈怠\n甜美镜头竟也落花一样飘落下来\n从此 我的生命 变成了尘埃\n寂寞的人 总是习惯寂寞的安稳\n至少 我们直线 曾经交叉过\n就像站在烈日骄阳大桥上\n眼泪狂奔滴落在我的脸庞"
  },
  {
    "objectID": "posts/lyrics/index.html#如愿",
    "href": "posts/lyrics/index.html#如愿",
    "title": "Lyrics Collection",
    "section": "如愿",
    "text": "如愿\n你是 遥遥的路 山野大雾里的灯\n我是孩童啊 走在你的眼眸\n你是 明月清风 我是你照拂的梦\n见与不见都一生 与你相拥\n而我将 爱你所爱的人间 愿你所愿的笑颜\n你的手我蹒跚在牵 请带我去明天\n如果说 你曾苦过我的甜 我愿活成你的愿\n愿不枉啊 愿勇往啊 这盛世每一天\n你是 岁月长河 星火燃起的天空\n我是仰望者 就把你唱成歌\n你是 我之所来 也是我心之所归\n世间所有路都将 与你相逢\n而我将 爱你所爱的人间 愿你所愿的笑颜\n你的手我蹒跚在牵 请带我去明天\n如果说 你曾苦过我的甜 我愿活成你的愿\n愿不枉啊 愿勇往啊 这盛世每一天\n山河无恙 烟火寻常 可是你如愿的眺望\n孩子们啊 安睡梦乡 像你深爱的那样\n而我将 梦你所梦的团圆 愿你所愿的永远\n走你所走的长路 这样的爱你啊\n我也将 见你未见的世界 写你未写的诗篇\n天边的月 心中的念 你永在我身边\n与你相约 一生清澈 如你年轻的脸"
  },
  {
    "objectID": "posts/lyrics/index.html#红尘客栈",
    "href": "posts/lyrics/index.html#红尘客栈",
    "title": "Lyrics Collection",
    "section": "红尘客栈",
    "text": "红尘客栈\n天涯的尽头是风沙 红尘的故事叫牵挂\n封刀隐没在寻常人家 东篱下 闲云野鹤古刹\n快马在江湖里厮杀 无非是名跟利放不下\n心中有江山的人岂能快意潇洒 我只求与你共华发\n檐下窗棂斜映枝桠 与你席地对座饮茶\n我以工笔画将你牢牢的记下 提笔不为风雅\n灯下叹红颜近晚霞 我说缘份一如参禅不说话\n你泪如梨花洒满了纸上的天下 爱恨如写意山水画\n剑出鞘恩怨了 谁笑 我只求今朝拥你入怀抱\n红尘客栈风似刀 骤雨落宿命敲\n任武林谁领风骚 我却只为你折腰 过荒村野桥寻世外古道\n远离人间尘嚣 柳絮飘执子之手逍遥\n任武林谁领风骚 我却只为你折腰\n你回眸多娇我泪中带笑 酒招旗风中萧萧 剑出鞘恩怨了"
  },
  {
    "objectID": "posts/llm/index.html",
    "href": "posts/llm/index.html",
    "title": "Notes on Large Language Models",
    "section": "",
    "text": "Bilibili, 大模型微调，LoRA"
  },
  {
    "objectID": "posts/editor/index.html",
    "href": "posts/editor/index.html",
    "title": "Editors",
    "section": "",
    "text": "I have just learned from the Juno team that they are going to shift towards Visual Studio Code in the future. The main decision behind this is that after GitHub was bought by Microsoft in 2018, the development of Atom has been greatly slowed down. Microsoft is pushing towards Visual Studio Code, which is their long term support editor. I have experiences in both Atom and VSCode. While Juno in Atom does has some features I like (e.g. Git commit control), Atom itself has some very annoying designs like the “clever” panels to save memory and the indentation switch between tabs and whitespaces. VSCode does a much better job in code formatting, and the built-in support for command line interfaces is much faster than that in Atom. When I write Julia code and do local tests, often I prefer opening another bash window so that I can speed things up. This is definitely not satisfying. Therefore the transition from Atom to VSCode for the Juno team makes sense, and it is also another example for demonstrating the importance of having a nice basic infrastructure for an extensible project and long-term support from big tech giants.\nSometimes, monopolies are good.\n\n\nVSCode has very nice support for many languages. A nice tutorial to follow can be found here. Generally speaking, you only need to add the relevant extensions and set up the paths in the config files (.vscode/*.json).\nVSCode has a remote access feature that allows you to edit files on a remote machine through ssh. On the remote side this requires ~100MB space, otherwise the connection will return error. A workaround using symbolic link is described here.\nAn advanced usage tutorial posted by Fireship contains tips for saving you from using mouses and duplicate tasks."
  },
  {
    "objectID": "posts/editor/index.html#from-atom-to-vscode",
    "href": "posts/editor/index.html#from-atom-to-vscode",
    "title": "Editors",
    "section": "",
    "text": "I have just learned from the Juno team that they are going to shift towards Visual Studio Code in the future. The main decision behind this is that after GitHub was bought by Microsoft in 2018, the development of Atom has been greatly slowed down. Microsoft is pushing towards Visual Studio Code, which is their long term support editor. I have experiences in both Atom and VSCode. While Juno in Atom does has some features I like (e.g. Git commit control), Atom itself has some very annoying designs like the “clever” panels to save memory and the indentation switch between tabs and whitespaces. VSCode does a much better job in code formatting, and the built-in support for command line interfaces is much faster than that in Atom. When I write Julia code and do local tests, often I prefer opening another bash window so that I can speed things up. This is definitely not satisfying. Therefore the transition from Atom to VSCode for the Juno team makes sense, and it is also another example for demonstrating the importance of having a nice basic infrastructure for an extensible project and long-term support from big tech giants.\nSometimes, monopolies are good.\n\n\nVSCode has very nice support for many languages. A nice tutorial to follow can be found here. Generally speaking, you only need to add the relevant extensions and set up the paths in the config files (.vscode/*.json).\nVSCode has a remote access feature that allows you to edit files on a remote machine through ssh. On the remote side this requires ~100MB space, otherwise the connection will return error. A workaround using symbolic link is described here.\nAn advanced usage tutorial posted by Fireship contains tips for saving you from using mouses and duplicate tasks."
  },
  {
    "objectID": "posts/editor/index.html#command-line-editors",
    "href": "posts/editor/index.html#command-line-editors",
    "title": "Editors",
    "section": "Command Line Editors",
    "text": "Command Line Editors\nAfter all these years, classical command line editors like vim and Emacs are still there, while more and more young fellows are shifting towards a GUI based editor with integrated support. The only reason we are still using vim and Emacs is that it is the faster and stabler approach to edit your code on a remote server which may suffer from all kinds of connectivity issues. However, if you are able to configure your environment and connect with faster Internet, the new generation of editors are for sure better options.\nThere are still some parts that these command line editors shine over IDEs. For example, Emacs has very good support for Fortran formatting and default distinction between tabs and spaces."
  },
  {
    "objectID": "posts/editor/index.html#typora",
    "href": "posts/editor/index.html#typora",
    "title": "Editors",
    "section": "Typora",
    "text": "Typora\nIf you prefer markdowns, Typora is an excellent choice. Using together with the online figure generator draw.io, you can literally create any notes you want. I love markdown simply because of its integration with web, which is much better than LaTeX.\nNote that Typora uses mathjax as the backend LaTeX support, which is a more complete but slightly slower approach compared with KaTeX, which is a lightweight LaTeX backend that is commonly used for displaying maths, e.g., in the Julia documentations."
  },
  {
    "objectID": "posts/editor/index.html#overleaf",
    "href": "posts/editor/index.html#overleaf",
    "title": "Editors",
    "section": "Overleaf",
    "text": "Overleaf\nLast but not least, Overleaf is a good online LaTeX editor. Mostly I use LaTeX for writing papers, but I also have been using it for scientific notes and course works."
  },
  {
    "objectID": "posts/r/index.html",
    "href": "posts/r/index.html",
    "title": "R Notes",
    "section": "",
    "text": "R is popular among statisticians and biologists. It is one of the most commonly used languages in data analysis."
  },
  {
    "objectID": "posts/r/index.html#basics",
    "href": "posts/r/index.html#basics",
    "title": "R Notes",
    "section": "Basics",
    "text": "Basics\nR’s basic syntax is C-like. There are a few special usages compared to other languages:\n\n&lt;- is R’s way to express assign a value to a variable. It can also direct the other way, i.e. -&gt;. Sometimes it is equivalent to =, but in some places only &lt;- is allowed. The recommended way is to use &lt;- and forget that equals is ever allowed.\n&lt;-- is R’s global assigner. It can set global variables in a local scope.\nc() is for combine scalars into vectors.\nlist() is for creating a collection with multiple object types (similar to tuple in other languages).\nR’s vectorization is similar to MATLAB, but not strictly consistent. If you attempt to use a non-vectorized function on a vector, you will get warnings. apply() is like map() in Julia. There are more functions in the apply family.\nR uses one-based indexes (GREAT!).\nIntegers in R are shown as e.g. 2L. 3 is assumed to be the same as 3.0, i.e. numeric.\nTerminating R expressions: R doesn’t need semicolons to end a line of code (while it’s possible to put multiple commands on a single line separated by semicolons, you don’t see that very often). Instead, R uses line breaks (i.e., new line characters) to determine when an expression has ended.\nLast but not least, R is a case-sensitive language, consistent with the trend in most modern languages."
  },
  {
    "objectID": "posts/r/index.html#popular-packages",
    "href": "posts/r/index.html#popular-packages",
    "title": "R Notes",
    "section": "Popular Packages",
    "text": "Popular Packages\n\nggplot2: grammar of graphics. The most famous package in the R community.\n\nlibrary(ggplot2)\n\n# Delete the points outside the limits\ng + xlim(c(0, 0.1)) + ylim(c(0, 1000000))\nggplot(midwest, aes(x=area, y=poptotal)) + \n  geom_point(col=\"steelblue\", size=3) + # Add scatter points\n  geom_smooth(method=\"lm\") + # Add smoothing layer with a linear model \"lm\"\n  coord_cartesian(xlim=c(0,0.1), ylim=c(0, 1000000)) + # Zoom in\n  labs(title=\"Area Vs Population\", subtitle=\"From midwest dataset\", y=\"Population\", x=\"Area\", caption=\"Midwest Demographics\") # Add titles and axis labels\n\ntidyverse: providing a complete and consistent set of tools for working with functions and vectors.\n\nlibrary(purrr)\n\nmtcars |&gt; \n  split(mtcars$cyl) |&gt;  # from base R\n  map(\\(df) lm(mpg ~ wt, data = df)) |&gt; \n  map(summary) %&gt;%\n  map_dbl(\"r.squared\")\n#&gt;         4         6         8 \n#&gt; 0.5086326 0.4645102 0.4229655\nThis example illustrates some of the advantages of purrr functions over the equivalents in base R:\n\nThe first argument is always the data, so purrr works naturally with the pipe.\nAll purrr functions are type-stable. They always return the advertised output type (map() returns lists; map_dbl() returns double vectors), or they throw an error.\nAll map() functions accept functions (named, anonymous, and lambda), character vector (used to extract components by name), or numeric vectors (used to extract by position)."
  },
  {
    "objectID": "posts/r/index.html#advanced-r",
    "href": "posts/r/index.html#advanced-r",
    "title": "R Notes",
    "section": "Advanced R",
    "text": "Advanced R\nThe tricks are more-or-less similar to MATLAB and Python, such as vectorization, lazy evaluation, and integrating faster languages like C++. See more in Advanced R."
  },
  {
    "objectID": "posts/x11/index.html",
    "href": "posts/x11/index.html",
    "title": "Remote Access through X11",
    "section": "",
    "text": "When you ssh to a remote server, you may need to open graphic software through x11. Check the following things to avoid the displaying error X11 forwarding request failed on channel 0:\n\nssh -X user@server or ssh -Y user@server\nOn local machine, modify the X11forwarding to yes in /etc/ssh/sshd_config\nin /etc/ssh/ssh_config, add XAuthLocation /usr/X11/bin/xauth (The location of xauth may change from version to version!)"
  },
  {
    "objectID": "posts/x11/index.html#mac",
    "href": "posts/x11/index.html#mac",
    "title": "Remote Access through X11",
    "section": "",
    "text": "When you ssh to a remote server, you may need to open graphic software through x11. Check the following things to avoid the displaying error X11 forwarding request failed on channel 0:\n\nssh -X user@server or ssh -Y user@server\nOn local machine, modify the X11forwarding to yes in /etc/ssh/sshd_config\nin /etc/ssh/ssh_config, add XAuthLocation /usr/X11/bin/xauth (The location of xauth may change from version to version!)"
  },
  {
    "objectID": "posts/x11/index.html#wsl2",
    "href": "posts/x11/index.html#wsl2",
    "title": "Remote Access through X11",
    "section": "WSL2",
    "text": "WSL2\nWSL2 requires XWindow for GUI applications. This guide provides a good summary of how to set it up on your Win10. I have only tried the first option VcXsrv Windows X Server, which works great but I have to remember to launch it with the correct settings everytime before I start a GUI from WSL2.\nUpdate: As of 2024, WSL2 comes with GUI support. However, the biggest issue with WSL2 is that it lacks a robust way to release unused memory to the system, which in the long run causes OOM errors."
  },
  {
    "objectID": "posts/cross-wavelet/index.html",
    "href": "posts/cross-wavelet/index.html",
    "title": "Cross-Wavelet Transform",
    "section": "",
    "text": "Before we talk about cross-wavelet transform (CWT)1, we need to understand wavelet transform (WT). Before we learn wavelet transform, we’d better have a good understanding of Fourier transform. Take a look at Wavelet Transform before moving on.\nThe cross-wavelet transform (CWT) method is a technique that characterizes the interaction between the wavelet transform (WT) of two individual time-series.2\nThe CWT method allows us to measure\nSimilarity/differences between two time-series can be identified. If these behavioral states have different temporal evolution, the CWT method helps quantifying how different they are, and what the time lag between the two different behavioral states is. In short, this method is able to yield information on the spatio-temporal organization between two time-series."
  },
  {
    "objectID": "posts/cross-wavelet/index.html#synchronization",
    "href": "posts/cross-wavelet/index.html#synchronization",
    "title": "Cross-Wavelet Transform",
    "section": "Synchronization",
    "text": "Synchronization\nIf you calculate the linear correlation between two time-series, you will get one value for the whole data; if you calculate the “local” linear correlation, you will get a 1D line values; if you perform CWT, you will get a 2D spectrum, i.e. the correlation at a given frequency at a given time.\nSo far, the Hilbert transform seems to be a relevant method to detect the phase synchronization between two time-series providing that the components of the time-series possess the same frequencies. However, this method cannot be directly applied to the analysis of the phase synchronization between two plurifrequential components of a time-series. A plurifrequential time-series is composed of a time-series with multiple frequencies occurring in the same time as it is commonly the case in living systems. The CWT method would be able to deal with such plurifrequential time-series and is conjointly able to detect the phase synchronization of such time-series."
  },
  {
    "objectID": "posts/cross-wavelet/index.html#relative-phase",
    "href": "posts/cross-wavelet/index.html#relative-phase",
    "title": "Cross-Wavelet Transform",
    "section": "Relative Phase",
    "text": "Relative Phase\nCWT can measure the ordering of the interaction among components, or in a continuous manner, lag."
  },
  {
    "objectID": "posts/cross-wavelet/index.html#requirements",
    "href": "posts/cross-wavelet/index.html#requirements",
    "title": "Cross-Wavelet Transform",
    "section": "Requirements",
    "text": "Requirements\n\nSame duration for the two time-series\nSimilar sampling rate (downsampling may be useful if one of the time-series has a higher sampling rate than the other)"
  },
  {
    "objectID": "posts/cross-wavelet/index.html#example",
    "href": "posts/cross-wavelet/index.html#example",
    "title": "Cross-Wavelet Transform",
    "section": "Example",
    "text": "Example\nHere I repost the example given in the referenced tutorial. Two synthetic time-series were created. The two time-series, s1 (Figure 2A) and s2 (Figure 2B) have a duration of 102.4 s (with a sampling rate of 50 Hz). The amplitude of s1 and s2 is 1 arbitrary unit (a.u.). Both time-series have been divided into five intervals.\n\nFor the first three intervals [0–61.44], the time-series are composed of a high frequency component at 1 Hz and a low frequency component at 0.5 Hz.\nFor the last two intervals [61.44–102.4], the time-series are composed of a high frequency component (1 Hz) and an intermediate frequency component (0.75 Hz).\n1st interval: characterized by a zero degree RP between s1 and s2 (the two time-series are identical in this interval).\n2nd interval: the time-series s1 is characterized by a 90° phase lag in the high frequency component (1 Hz).\n3rd interval: a 90° phase lag is applied on s1 in the low frequency component (0.5 Hz).\n4th interval: a phase lag of 90° on the high frequency component and a phase lag of 180° on the intermediate frequency component are applied to s1.\n5th interval: a phase lag of 180° on the high frequency component and of 90° on the intermediate frequency component are applied to s1 (see Table 1 for a summary of the changes made to s1).\nNo phase lag exists in s2.\n\n\n\n\nTABLE 1. Details of the phase lag and frequency modulations of s1.\n\n\n\n\n\nFIGURE 1. Wavelet transform analysis and cross-wavelet transform (CWT) analysis of time-series (s1 and s2). (A,B) are the representations of s1 and s2, respectively; (C,E) show the normalized Fourier spectrum of (A,B), respectively. In both cases, we can observe one main peak at 1 Hz and two other peaks at 0.75 Hz and 0.5 Hz. (D,F) are WT spectra (scaleograms) of (A,B) respectively. These figures help to localize and quantify in terms of time of localization (time) and amplitude the frequency components previously identified in the Fourier spectra. In (D,F) two frequency components are present in the three first intervals of the time-series s1 and s2: one frequency at 1 Hz and one at 0.5 Hz. In the two last intervals, there are two frequencies: the frequency at 1 Hz, as in the three first intervals, and a new intermediate frequency at 0.75 Hz. (G) shows the cross-Fourier spectrum of (C,E). (H) Shows the cross-wavelet spectrum that is a representation of the common frequencies of (D,F) reflecting the local degree of interaction between the two analyzed time-series s1 and s2. (I) Shows the difference of phase of (A,B), i.e., the difference of phase between s1 and s2. The levels of gray permit us to visualize the associated relative phase (RP). a.u., arbitrary unit."
  },
  {
    "objectID": "posts/cross-wavelet/index.html#discriminate-the-properties-of-time-series",
    "href": "posts/cross-wavelet/index.html#discriminate-the-properties-of-time-series",
    "title": "Cross-Wavelet Transform",
    "section": "Discriminate the Properties of Time-Series",
    "text": "Discriminate the Properties of Time-Series\nFollowing the statistical test described in Wavelet Transform, we can obtain what is usually known as the cone of influence, which is the region under the thin black lines in Figure 1."
  },
  {
    "objectID": "posts/cross-wavelet/index.html#tools",
    "href": "posts/cross-wavelet/index.html#tools",
    "title": "Cross-Wavelet Transform",
    "section": "Tools",
    "text": "Tools\n\nMATLAB\nMATLAB’s wavelet toolbox provides wcoherence for computing the cross-wavelet tranform. The key formula is \\[\n\\frac{| S(C_x^\\ast(a,b) C_y(a,b) ) |^2}{S(| C_x(a,b) |^2)\\cdot S(| C_y(a,b) |^2)}\n\\] where \\(C_x(a,b)\\) and \\(C_y(a,b)\\) denote the continuous wavelet transforms of x and y at scales a and positions b. The superscript * is the complex conjugate and S is a smoothing operator in time and scale.\n\n\nJulia\nWaiting for the magic to happen in ContinuousWavelets.jl."
  },
  {
    "objectID": "posts/cross-wavelet/index.html#footnotes",
    "href": "posts/cross-wavelet/index.html#footnotes",
    "title": "Cross-Wavelet Transform",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis acronym is also used for continuous wavelet transform, to be distinguished from discrete wavelet transform. In MATLAB, the cwt function refers to continuous wavelet transform.↩︎\nThere is a nice reference in the field of psychology, The relevance of the cross-wavelet transform in the analysis of human interaction – a tutorial.↩︎"
  },
  {
    "objectID": "posts/javascript/index.html",
    "href": "posts/javascript/index.html",
    "title": "JavaScript",
    "section": "",
    "text": "圣诞假期到现在陆陆续续在学习一些JavaScript，期望触类旁通，理解语言的共性和不同。JavaScript作为常年霸榜的编程语言，它的兴起和流行和互联网的发展密不可分。在HTML5的时代，Javascript的地位也依旧没有任何被撼动的趋势，只是出现了更多后继衍生品，比如TypeScript。然而，现代JavaScript的这套骨架被历任程序员在实践中反复验证，证实了它的完备性和实用性。经过二十余年的发展，如今的版本几乎涵盖了我所知的所有编程概念和规则。\n计算机相关的知识，我对于互联网方面了解得最少，这也是涉猎JavaScript的动机。"
  },
  {
    "objectID": "posts/javascript/index.html#教程",
    "href": "posts/javascript/index.html#教程",
    "title": "JavaScript",
    "section": "教程",
    "text": "教程\n最新、最全、可能是我见过最好的编程语言介绍:JAVASCRIPT.INFO。在当下学习一门编程语言，借由所有人的知识共享，应该感到无比幸福。"
  },
  {
    "objectID": "posts/javascript/index.html#笔记",
    "href": "posts/javascript/index.html#笔记",
    "title": "JavaScript",
    "section": "笔记",
    "text": "笔记\n\nJavaScript is dynamically compiled，目前比较出名的编译器比如Chrome里面的Node.js。\nJavaScript is faster than Python (compiler &gt; interpreter).\nJavaScript is both functional and object-oriented.\n'use strict' is a similar workaround as implicit none in Fortran for backward compatibility.\nCallback is a pretty common concept, but very useful. A default empty callback function can be defined via cb = () =&gt; void 0.\nPromise is an alternative to callback, which in certain cases gives us more flexibility. I feel like this concept of promise is quite similar to stream/task graph in CUDA.\nGenerator is an advanced concept on top of iterables.\nThe module system in JavaScript become language-level standard in 2015."
  },
  {
    "objectID": "posts/hardware/index.html",
    "href": "posts/hardware/index.html",
    "title": "Computer Hardwares and Drivers",
    "section": "",
    "text": "第一次装机，记录一下过程。实践出真知。\n上个月让表弟从舅舅那里拉过来一台主机，比较老的配置，好像是Intel 10代以前的四核CPU，2*8GB内存，加上GTX1060的GPU。折腾了一下，死活没接上显示，查了一下可能是内存条接触不良。心下一想，索性直接去配了一台新主机，并且参考了舅舅的意见，去掉了机械硬盘和GPU，避免第一次装多些额外的麻烦。做了一些功课，考虑CPU次旗舰，工作编程软件优先，以后升级空间，于是选定了以下配置：\n\nCPU: Intel Core Ultra 7 265K Arrow Lake 20 core.这是15代，英特尔重新换了命名，颇为令人困惑。这一代为了降低功耗取消了超线程，8个性能核12个能效核。据说和前几代相比，能效核的性能大幅上升，并且没有缩缸风险。K说明自带核显，查了下性能大概略逊于主机上的1060。\nMotherboard: ASUS Z890 AYW GAMING WIFI W Intel LGA 1851 ATX. 这个是和CPU捆绑销售的,价格合理，旗舰主板，做工精良。\nMemory: G.Skill Ripjaws S5 2*16 GB DDR5-6000 PC5-48000。5代和4代似乎没什么速度差距，就是通道数目有些变化。现在的GPU里面的DDR好像编号都到6代了。内存现在非常便宜。本来考虑直接上64GB的，但想着反正一共四个插槽，先从32GB开始，要是觉得还有需求再去买两条就好了。\nSSD: Samsung 990 EVO Plus 2TB V NAND. 固态硬盘都是三星的天下。\nPower: MSI MAG A750GL 750 W ATX 3.1 Compatible。没有概念，本来在网上订的另外的店员，取货的店里刚好没有，于是店员就推荐了这一款，一样价，100刀。\nCase: Lian Li O11 Vision Compact Tempered Glass ATX Mid Tower. 白色机箱，很宽，玻璃壳，外观很简洁干净。\nFan: Be Quiet PURE ROCK 3 CPU Air Cooler。简单挑了个40刀的中间价格。自带硅脂，无需再单独购入thermal paste。\n\n以上这些加起来855刀，我觉得十分划算。考虑之后加一块5070的显卡，大概550刀。据说50系列销量不佳，之后还会降价，咱拭目以待。\n整个硬件组装过程还是比较顺利的，顺序是CPU-&gt;memory-&gt;SSD-&gt;Fan-&gt;Case-&gt;Power。唯一就是接线的时候第一次少接了几根，第一次接电没点亮。重新接好了就没问题。真正麻烦的是软件。我预先购买了一块USB，在Ubuntu官网了拷了盘，25.04。结果装好了，没有Wifi驱动。一搜，首先网友盲推LTS版本Ubuntu 24，说是新版本可能不稳定。我于是又重新拷USB，装上了24——一样，还是没有Wifi选项。又搜了半天，看到一条记录是Linux目前没有该款主板的网卡驱动，说是太新。顿时非常郁闷，那就意味这无论装哪个Linux操作系统都会遇到一样的问题。没办法，只能转战Windows。没有单独买个人版，利用学校的微软账号从Azure上面弄到一个序列号，再学习了一下Win 11的U盘安装方法。这时之前用作Ubuntu系统的安装盘无法被Windows的安装拷贝程序识别。弄半天发现是需要手动格式化，先在图形界面操作，报错read-only。又看了一阵找到一个Windows自带的命令行程序能修改读写权限，搞了两遍终于格式化成功。然后拷贝程序顺利识别，拿着U盘再去新机器上刷掉Ubuntu装Win11。第一次尝试出现了GPT header corruption错误，可能是分区错误，要调整BIOS设置。又是个坑。折腾了好一圈，看到屏幕上的建议把Boot Sector Recovery Policy 从User变成了Auto，退出BIOS，电脑自己重启了几遍后成功进入Win11系统。然而，此时竟然依然没有Wifi驱动……我打开主板说明书，翻到了驱动安装的页面，扫描二维码，到ASUS的官网注册了这块主板，用笔记本下载了WLAN和Wifi的驱动到U盘，插回PC，安装。终于，几经折腾，下午一点半开始，晚上出去吃了个饭俩小时，回来接着断断续续看，直到晚上11点42分全部搞定。偏底层的部分没有经验，不知道驱动和兼容性是这么麻烦的环节。其实现在参考资料已经很多了，但没有动手前还是很难考虑周全。我要是会写驱动，那就是和真计算机科班出身的一样了。这本来也是操作系统里面十分麻烦的环节。\n剩下的软件安装都十分顺利，WSL2+Ubuntu、VSCode、Zsh、Python、Julia、SSH、ParaView，基本一次完成。"
  },
  {
    "objectID": "posts/hardware/index.html#装机实录",
    "href": "posts/hardware/index.html#装机实录",
    "title": "Computer Hardwares and Drivers",
    "section": "",
    "text": "第一次装机，记录一下过程。实践出真知。\n上个月让表弟从舅舅那里拉过来一台主机，比较老的配置，好像是Intel 10代以前的四核CPU，2*8GB内存，加上GTX1060的GPU。折腾了一下，死活没接上显示，查了一下可能是内存条接触不良。心下一想，索性直接去配了一台新主机，并且参考了舅舅的意见，去掉了机械硬盘和GPU，避免第一次装多些额外的麻烦。做了一些功课，考虑CPU次旗舰，工作编程软件优先，以后升级空间，于是选定了以下配置：\n\nCPU: Intel Core Ultra 7 265K Arrow Lake 20 core.这是15代，英特尔重新换了命名，颇为令人困惑。这一代为了降低功耗取消了超线程，8个性能核12个能效核。据说和前几代相比，能效核的性能大幅上升，并且没有缩缸风险。K说明自带核显，查了下性能大概略逊于主机上的1060。\nMotherboard: ASUS Z890 AYW GAMING WIFI W Intel LGA 1851 ATX. 这个是和CPU捆绑销售的,价格合理，旗舰主板，做工精良。\nMemory: G.Skill Ripjaws S5 2*16 GB DDR5-6000 PC5-48000。5代和4代似乎没什么速度差距，就是通道数目有些变化。现在的GPU里面的DDR好像编号都到6代了。内存现在非常便宜。本来考虑直接上64GB的，但想着反正一共四个插槽，先从32GB开始，要是觉得还有需求再去买两条就好了。\nSSD: Samsung 990 EVO Plus 2TB V NAND. 固态硬盘都是三星的天下。\nPower: MSI MAG A750GL 750 W ATX 3.1 Compatible。没有概念，本来在网上订的另外的店员，取货的店里刚好没有，于是店员就推荐了这一款，一样价，100刀。\nCase: Lian Li O11 Vision Compact Tempered Glass ATX Mid Tower. 白色机箱，很宽，玻璃壳，外观很简洁干净。\nFan: Be Quiet PURE ROCK 3 CPU Air Cooler。简单挑了个40刀的中间价格。自带硅脂，无需再单独购入thermal paste。\n\n以上这些加起来855刀，我觉得十分划算。考虑之后加一块5070的显卡，大概550刀。据说50系列销量不佳，之后还会降价，咱拭目以待。\n整个硬件组装过程还是比较顺利的，顺序是CPU-&gt;memory-&gt;SSD-&gt;Fan-&gt;Case-&gt;Power。唯一就是接线的时候第一次少接了几根，第一次接电没点亮。重新接好了就没问题。真正麻烦的是软件。我预先购买了一块USB，在Ubuntu官网了拷了盘，25.04。结果装好了，没有Wifi驱动。一搜，首先网友盲推LTS版本Ubuntu 24，说是新版本可能不稳定。我于是又重新拷USB，装上了24——一样，还是没有Wifi选项。又搜了半天，看到一条记录是Linux目前没有该款主板的网卡驱动，说是太新。顿时非常郁闷，那就意味这无论装哪个Linux操作系统都会遇到一样的问题。没办法，只能转战Windows。没有单独买个人版，利用学校的微软账号从Azure上面弄到一个序列号，再学习了一下Win 11的U盘安装方法。这时之前用作Ubuntu系统的安装盘无法被Windows的安装拷贝程序识别。弄半天发现是需要手动格式化，先在图形界面操作，报错read-only。又看了一阵找到一个Windows自带的命令行程序能修改读写权限，搞了两遍终于格式化成功。然后拷贝程序顺利识别，拿着U盘再去新机器上刷掉Ubuntu装Win11。第一次尝试出现了GPT header corruption错误，可能是分区错误，要调整BIOS设置。又是个坑。折腾了好一圈，看到屏幕上的建议把Boot Sector Recovery Policy 从User变成了Auto，退出BIOS，电脑自己重启了几遍后成功进入Win11系统。然而，此时竟然依然没有Wifi驱动……我打开主板说明书，翻到了驱动安装的页面，扫描二维码，到ASUS的官网注册了这块主板，用笔记本下载了WLAN和Wifi的驱动到U盘，插回PC，安装。终于，几经折腾，下午一点半开始，晚上出去吃了个饭俩小时，回来接着断断续续看，直到晚上11点42分全部搞定。偏底层的部分没有经验，不知道驱动和兼容性是这么麻烦的环节。其实现在参考资料已经很多了，但没有动手前还是很难考虑周全。我要是会写驱动，那就是和真计算机科班出身的一样了。这本来也是操作系统里面十分麻烦的环节。\n剩下的软件安装都十分顺利，WSL2+Ubuntu、VSCode、Zsh、Python、Julia、SSH、ParaView，基本一次完成。"
  },
  {
    "objectID": "posts/hardware/index.html#hardware-for-coding",
    "href": "posts/hardware/index.html#hardware-for-coding",
    "title": "Computer Hardwares and Drivers",
    "section": "Hardware for coding",
    "text": "Hardware for coding\nHere is a post from BioJulia for scientists on how to write nice codes given the knowledge of computer hardwares. Very nice. Real workers know their tools."
  },
  {
    "objectID": "posts/geometric-algebra/index.html",
    "href": "posts/geometric-algebra/index.html",
    "title": "Geometric Algebra",
    "section": "",
    "text": "“A unified mathematical language for the whole of physics.” - David Hestenes\n“The most powerful and general language available for the development of mathematical physics.” - Stephen Gull, Anthony Lasenby, and Chris Doran\n\n\n\nThere is a Julia package called Grassmann.jl for doing computational geometric algebra.\nThe example of writing Maxwell’s equations in terms of geometric algebra \\[ F = J \\] makes me wonder if this is a better way to solve Maxwell’s equations numerically. I found one thesis on this topic already."
  },
  {
    "objectID": "posts/time-frequency-transform/index.html",
    "href": "posts/time-frequency-transform/index.html",
    "title": "Comparison of Time-Frequency Transforms",
    "section": "",
    "text": "Stefan Scholl made a nice comparison between different kinds of time-frequency transforms available: Fourier, Gabor, Morlet or Wigner. The paper on Arxiv is linked here. In this post, we try to recap the most important parts and attach some examples with codes."
  },
  {
    "objectID": "posts/time-frequency-transform/index.html#short-time-fourier-and-gabor-transform",
    "href": "posts/time-frequency-transform/index.html#short-time-fourier-and-gabor-transform",
    "title": "Comparison of Time-Frequency Transforms",
    "section": "Short-Time Fourier and Gabor Transform",
    "text": "Short-Time Fourier and Gabor Transform"
  },
  {
    "objectID": "posts/time-frequency-transform/index.html#wigner-ville-distribution",
    "href": "posts/time-frequency-transform/index.html#wigner-ville-distribution",
    "title": "Comparison of Time-Frequency Transforms",
    "section": "Wigner-Ville Distribution",
    "text": "Wigner-Ville Distribution\nThe Wigner-Ville distribution (WVD) overcomes the limited resolution of the Fourier and wavelet based methods using an autocorrelation approach.\nThe standard version of the autocorrelation function (ACF) considers the pointwise multiplication of a signal with a lagged version of itself and integrates the results over time. It is defined as \\[\nr_{xx}(\\tau) = \\int_{-\\infty}^{\\infty}x(t)x^\\ast(t+\\tau)\\mathrm{d}t\n\\]\nThe standard ACF is only dependent on the lag \\(\\tau\\), because time is integrated out of the result. The WVD uses a variation of the ACF, called the instantaneous autocorrelation, which omits the integration step. Thus time remains in the result. The instantaneous autocorrelation is therefore a two dimensional function, depending on \\(t\\) and the lag \\(\\tau\\): \\[\nR_{xx}(t, \\tau) = x(t+\\frac{\\tau}{2})x^\\ast(t-\\frac{\\tau}{2})\n\\]\nThe WVD calculates the frequency content for each time step t by taking a Fourier transform of the instantaneous autocorrelation across the axis of the lag variable \\(\\tau\\) for that given t \\[\n\\begin{aligned}\nW(t,f) &= \\int_{-\\infty}^{\\infty} R_{xx}(t,\\tau)e^{-2\\pi\\,i\\,\\tau}\\mathrm{d}\\tau \\\\\n&= \\int_{-\\infty}^{\\infty} x(t+\\frac{\\tau}{2})x^\\ast(t-\\frac{\\tau}{2})e^{-2\\pi\\,i\\,\\tau}\\mathrm{d}\\tau\n\\end{aligned}\n\\]\nThe result is real-valued. This way of calculation is related to the fact, that the Fourier spectrum of a signal equals the Fourier transform of its ACF. The WVD offers very high resolution in both time and frequency, this is much finer than of the STFT.\nAn important disadvantage of the WVD are the so-called cross terms. These are artifacts occurring in the result, if the input signal contains a mixture of several signal components. They stem from the fact, that the WVD is a quadratic (and therefore a non-linear) transform due to the way the instantaneous autocorrelation is calculated. The WVD of the superposition of two signals is \\[\nW_{x_1 + x_2} = W_{x_1} + W_{x_2} + 2\\mathcal{R}\\{ W_{x_1,x_2} \\}\n\\] and may be dominated by the cross term \\(W_{x_1,x_2}\\), which may have twice the amplitude of the auto terms \\(W_{x_1}\\) and \\(W_{x_2}\\). Unfortunately, the occurrence of these cross terms limits the usefulness for many practical signals.\nThe cross terms occur midway between the auto terms and often have an oscillatory (high-frequency) pattern. A method to reduce cross terms is to suppress the oscillating components by additional low-pass filtering in time and frequency. However, this suppression of cross terms comes at the expense of reduced resolution. This idea of additional cross term suppression leads to the more general formulation of time-frequency transforms called Cohen’s class. From Cohen’s class many different variants can be deduced, that basically differ in the way the low-pass filter is designed. A prominent one is the smoothed pseudo Wigner-Ville distribution (SPWVD). Other variants such as Choi-Williams, Margenau-Hill or Rihaczek can be found in literature, but often provide very similar results to the SPWVD for practical signals. The SPWVD is defined as the WVD filtered by two separate kernels \\(g(t)\\) and \\(H(f)\\) (need to be chosen prior to the transform), that smooth the WVD in frequency and time: \\[\n\\mathrm{SPWVD}(t,f) = \\int_{t_1}\\int_{f_1} g(t-t_1)H(f-f_1)W(t_1,f_1)\\mathrm{d}t_1\\mathrm{d}f_1\n\\]\nHere is the code for comparing the different method using an analytical Doppler signal:\nusing SignalAnalysis\nusing SignalAnalysis.Units: kHz, s\nusing ContinuousWavelets\nusing DSP: pow2db\nusing Wavelets: testfunction\nusing PyPlot\n\nn = 2048\nfs = 1000.\nt = range(0, n / fs, length=n) # 1kHz sampling rate\nf = testfunction(n, \"Doppler\")\nx = signal(f, fs)\n\nfig, axs = plt.subplots(5,1; figsize=(8,10), constrained_layout=true, sharex=true)\n\naxs[1].plot(t, x, label=\"Doppler\")\n\n# STFT\ny = tfd(x, Spectrogram(nfft=2^6, noverlap=2^5, window=hamming))\nvmin, vmax = extrema(y.power)\nif vmax / vmin &gt; 1e4\n   vmin = vmax / 1e4\nend\naxs[2].pcolormesh(y.time, y.freq, y.power;\n   norm=matplotlib.colors.LogNorm(;vmin, vmax),\n   cmap=matplotlib.cm.inferno)\n\nc = wavelet(Morlet(π), β=2)\nres = ContinuousWavelets.cwt(x, c)\nres = abs.(res.^2)\nfreqs = getMeanFreq(ContinuousWavelets.computeWavelets(size(res,1), c)[1])\nfreqs[1] = 0\n\nvmax = maximum(res)\nvmin = vmax / 1e4\n\naxs[3].pcolormesh(t, freqs, res';\n   norm=matplotlib.colors.LogNorm(;vmin, vmax),\n   cmap=matplotlib.cm.inferno)\n\n# WVD\ny = tfd(x, Wigner())\n@. y.power = abs(y.power)\nvmax = maximum(y.power)\nvmin = vmax / 1e4\n\naxs[4].pcolormesh(y.time, y.freq, y.power;\n   norm=matplotlib.colors.LogNorm(;vmin, vmax),\n   cmap=matplotlib.cm.inferno)\n\n# SPWVD\ny = tfd(x, Wigner(nfft=2^8, smooth=10, method=:CM1980, window=hamming))\n@. y.power = abs(y.power)\n#[y.power[i] = eps() for i in eachindex(y.power) if y.power[i] == 0]\nvmax = maximum(y.power)\nvmin = vmax / 1e4\naxs[5].pcolormesh(y.time, y.freq, y.power;\n   norm=matplotlib.colors.LogNorm(;vmin, vmax),\n   cmap=matplotlib.cm.inferno)\n\ntitles = (\"Signal\", \"STFT\", \"CWT\", \"WVD\", \"SPWVD\")\nylabels = (\"frequency [Hz]\", \"frequency [Hz]\", \"frequency [Hz]\", \"frequency [Hz]\")\n\nfor (i, ax) in enumerate(axs)\n   ax.set_title(titles[i], fontsize=\"large\")\n   i != 1 && ax.set_ylabel(ylabels[i-1], fontsize=\"large\")\n   i == 1 && ax.legend(loc=\"upper right\")\n   ax.xaxis.set_minor_locator(matplotlib.ticker.AutoMinorLocator())\n   ax.yaxis.set_minor_locator(matplotlib.ticker.AutoMinorLocator())\nend\n\naxs[end].set_xlabel(\"time [s]\", fontsize=\"large\")\n\n\n\nComparison between different time-frequency transforms with an analytical signal of Doppler shift.\n\n\nNotes:\n\nMany plot recipes automatically convert power to decibel. In MATLAB/Julia DSP, this is done via pow2db. However in many scientific domains people prefer powers, which is shown in the code above.\nThe choice of colormap range usually requires some tweaks. Practically we can first choose the maximum value and let the minimum value be a function of the maximum so as to avoid extremely large scale differences and highlight the peaks.\nThe continuous wavelet transform package in Julia is not mature. Many parameters in SignalAnalysis.jl are not documented."
  },
  {
    "objectID": "posts/command-line/index.html",
    "href": "posts/command-line/index.html",
    "title": "Command Line Tools",
    "section": "",
    "text": "When using properly, command line is often the easiest and fastest way to get tasks done, even though the same thing can be also accomplished in other ways like using Python, Perl, etc.. Many useful little tricks can be found on the internet. I have collected some of them here."
  },
  {
    "objectID": "posts/command-line/index.html#scp-with-regular-expression",
    "href": "posts/command-line/index.html#scp-with-regular-expression",
    "title": "Command Line Tools",
    "section": "scp with regular expression",
    "text": "scp with regular expression\nIt is not guaranteed that the terminal you use can recognize regular expression on the remote machine. The magic here is\nscp \"user@machine:/path/[regex here]\" ."
  },
  {
    "objectID": "posts/command-line/index.html#finding-and-replacing-text-within-files",
    "href": "posts/command-line/index.html#finding-and-replacing-text-within-files",
    "title": "Command Line Tools",
    "section": "Finding and replacing text within files",
    "text": "Finding and replacing text within files\nsed -i 's/original/new/g' file.txt\nExplanation:\n\nsed = Stream Editor\n-i = in-place (i.e. save back to the original file)\nThe command string:\n\ns = the substitute command\noriginal = a regular expression describing the word to replace (or just the word itself)\nnew = the text to replace it with\ng = global (i.e. replace all and not just the first occurrence)\n\nfile.txt = the file name"
  },
  {
    "objectID": "posts/command-line/index.html#monitoring-log-file-in-real-time",
    "href": "posts/command-line/index.html#monitoring-log-file-in-real-time",
    "title": "Command Line Tools",
    "section": "Monitoring log file in real time",
    "text": "Monitoring log file in real time\ntail -f log\nThis works, but the downside is that tail reads the whole file into buffer. As an alternative, using less is a more elegant approach:\nless +F log"
  },
  {
    "objectID": "posts/command-line/index.html#returning-the-last-n-modified-file-in-directory-in-time-order",
    "href": "posts/command-line/index.html#returning-the-last-n-modified-file-in-directory-in-time-order",
    "title": "Command Line Tools",
    "section": "Returning the last n modified file in directory in time order:",
    "text": "Returning the last n modified file in directory in time order:\nls -Art | tail -n 1\nor in reverse order:\nls -t | head -n 1"
  },
  {
    "objectID": "posts/command-line/index.html#piping-selected-files-into-tar",
    "href": "posts/command-line/index.html#piping-selected-files-into-tar",
    "title": "Command Line Tools",
    "section": "Piping selected files into tar",
    "text": "Piping selected files into tar\nls -Art | tail -n 5 | tar czvf out.tar.gz -T -"
  },
  {
    "objectID": "posts/command-line/index.html#avoiding-file-auto-purge",
    "href": "posts/command-line/index.html#avoiding-file-auto-purge",
    "title": "Command Line Tools",
    "section": "Avoiding file auto purge",
    "text": "Avoiding file auto purge\nOn many file systems, there may be some rules for file housekeeping. One trick to avoid it is to touch each and every file in the repository. This can be done through the following command:\nfind /home/example -exec touch {} \\;"
  },
  {
    "objectID": "posts/command-line/index.html#counting-files",
    "href": "posts/command-line/index.html#counting-files",
    "title": "Command Line Tools",
    "section": "Counting Files",
    "text": "Counting Files\nls -F | grep -v / | wc -l\nls -F list all files and append indicator (one of */=&gt;@|) to entries’ grep -v / keep all de strings that do not contain a slash; wc -l count lines."
  },
  {
    "objectID": "posts/command-line/index.html#checking-missing-sequence-files",
    "href": "posts/command-line/index.html#checking-missing-sequence-files",
    "title": "Command Line Tools",
    "section": "Checking missing sequence files",
    "text": "Checking missing sequence files\nAssume the files share the pattern FILE_DDD.txt.\nExample 1:\nfor i in {1..14}\ndo\nseq=`printf \"%03d\" $i`\nif [ ! -f \"FILE_${seq}.txt\" ]\nthen\necho \"FILE_${i}.txt\"\nfi\ndone\nAssume a series of files with numbers indicating the day of a year and the hour of day: &gt; GLDAS_NOAH025SUBP_3H.A2003001.0000.001.2015210044609.pss.grb &gt; GLDAS_NOAH025SUBP_3H.A2003001.0600.001.2015210044609.pss.grb &gt; GLDAS_NOAH025SUBP_3H.A2003001.1200.001.2015210044609.pss.grb &gt; GLDAS_NOAH025SUBP_3H.A2003001.1800.001.2015210044609.pss.grb\nfor a in file_{001..365}.{00..18..6}.txt\ndo\n  [[ -f $a ]] || echo \"$a\"\ndone\nNote the usages of .. in the above examples. This is very useful to generate a continous list of strings\nAssume just number ordering:\nub=1000 # Replace this with the largest existing file's number.\nseq \"$ub\" | while read -r i; do\n    [[ -f \"$i.txt\" ]] || echo \"$i.txt is missing\"\ndone\nSomeone suggested awk, but I am not familiar with it at all."
  },
  {
    "objectID": "posts/command-line/index.html#list-file-names-using-regular-expression",
    "href": "posts/command-line/index.html#list-file-names-using-regular-expression",
    "title": "Command Line Tools",
    "section": "List file names using regular expression",
    "text": "List file names using regular expression\nExample 1: finding files within sequence and deleting\nls | grep -P \"^08[5-9].*[0-9]\" | xargs -d \"\\n\" rm\nExample 2\nfind your-directory/ -name 'A*[0-9][0-9]' -delete"
  },
  {
    "objectID": "posts/command-line/index.html#removing-prefix-from-files",
    "href": "posts/command-line/index.html#removing-prefix-from-files",
    "title": "Command Line Tools",
    "section": "Removing prefix from files",
    "text": "Removing prefix from files"
  },
  {
    "objectID": "posts/command-line/index.html#changing-file-extensions",
    "href": "posts/command-line/index.html#changing-file-extensions",
    "title": "Command Line Tools",
    "section": "Changing file extensions",
    "text": "Changing file extensions\nfor f in *.html; do\n    mv -- \"$f\" \"${f%.html}.php\"\ndone"
  },
  {
    "objectID": "posts/command-line/index.html#sudo",
    "href": "posts/command-line/index.html#sudo",
    "title": "Command Line Tools",
    "section": "sudo",
    "text": "sudo\nsudo -s: run shell by root without changing a directory, also env vars (that could be set in, e.g. .bash_profile) wouldn’t be imported.\nsudo -i: run shell by root, import env vars and change directory.\nsu -: first change user, then run shell. It means that all env vars were cleaned and “clean” root session was executed.\nsu: command doesn’t clean env vars, it just changes a user to root and keeps env vars for old user.\n\nMany more to be added later! Some additional private notes on scripting are listed in this repo."
  },
  {
    "objectID": "posts/mexico/index.html",
    "href": "posts/mexico/index.html",
    "title": "墨西哥杂记",
    "section": "",
    "text": "我把旅行中零散的记录收集在一起，再额外补充一些，作为17年墨西哥旅行的纪念。感谢泽哥、佳星和颖怡的同行，感谢热情的墨西哥人民。\n据说墨西哥很多地方非常危险，犯罪率极高，美国官方都不建议作为旅行目的地。幸好，作为旅游胜地的坎昆和首都的墨西哥城，至少在我看来，并无危险。\n坎昆的海滩有着绝美的风景，沙滩、海水和天空的层级感非常强烈。可我这个海边的孩子，对于这些的记忆已然足够丰富，于是便唤不起多少的惊奇。\n圣诞夜，坎昆的餐厅多数关门歇业，当地的超市也在八点钟关门，找个晚饭变成了件不容易的事。庆幸的是，我们在一家酒吧旁边找到了一家还在营业的墨西哥餐厅。服务员很热情，即便连英语都不会说，仍然尝试着在谷歌翻译的帮助下通过肢体语言来和我们沟通。可就在这家如同街边排档般的餐厅里，我们找到了梦幻一般的美食：pozole，唇齿留香的墨西哥玉米肉汤。以玉米糠（hominy）为底，和猪肉、番茄一起熬制半日，加入鹰嘴豆，呈现鲜红的肉汤，那恰到好处的酸味刺激着味蕾，软糯的豆子和鲜嫩的猪肉一起，构成了一道完美的晚餐。比起tacos，这道无心插柳的美食让我重新认识了墨西哥菜。据说玉米是阿兹特克人民神圣的植物，所以这道玉米肉汤也是当地节日必不可少的菜品之一。 题外一句，UM的颜色是maize and blue，这黄色，就是玉米黄。\nxplor, 一天的丛林探险体验，这辈子没穿鞋走的最长的路。高空的滑索、地下河的竹排、丛林的越野车，以及与鸟儿争食的自助食物。\nchichen itza, 玛雅文化的分布之一，世界新七大奇迹之一。走在园区里，随着导游的讲解，你不得不佩服古玛雅工程师的天宫之巧：击掌回声的设计，密室里扩音器的结构，四面台阶与玛雅阴阳历法的对应关系，大金字塔内嵌小金子塔的轮回构思……同样的，那个竞技场的7/14次回声的设计，穿越孔环的球类竞技，也是令人倍感惊奇。传说中这里举行着类似今日世界杯一样的比赛，每队7人，胜者的队长会被败者取下头颅，达成献祭神明的光荣使命，而头骨会被摆入东侧的英灵冢。这种不可思议的文化传统，表征着古人对于自然的敬畏。刻在竞技场的图腾似乎印证着这个说法：一全副武装的力士左手提着头骨右手持剑，而另一侧一具无头人像单膝跪地，从颈部长出三头长蛇——羽化的蛇图腾，正是玛雅人憧憬的圣灵。\n玛雅文明遍布于如今的北美五国，各自又有和而不同的发迹。chichen itza 存在的sinkhole，吸引了最早的一千玛雅人来此定居。很难想象这片丛林之中，竟然会存在天然的地下水坑和洞穴，给文明添上了一线生机。后来由于资源的用尽，玛雅人离开的曾经繁华的故土，散布于整个中美地带。传闻中玛雅的灭亡被部分人归因于殖民者的入侵，而导游作为玛雅人的后裔，倒是为西班牙人说了句话：当年玛雅以及阿兹特克的没落，大都不是由于殖民者主观的杀戮，而是他们无意中带来的瘟疫席卷了美洲。墨西哥人的这种历史态度，是我未曾预料而又敬畏有加的。\n连着三天吃着路边的小摊，一侧是酒吧的重金属轰鸣，另一侧是墨西哥小哥灿烂的笑容。我完全听不懂西班牙语，他也几乎不懂英语，但是今晚我独自前去，却连谷歌翻译也不需要，凭着比划和猜测就能明白彼此的意思。我吃着猪肚汤，想象着把这家餐厅搬到国内的夜市上人潮如涌的场景。不过他们未必乐意把店开到异国他乡：坎昆是他们生活的地方，他们希望的不定是荣华财富，而更可能是平淡中的小幸福。至少对于我这个异国游客，能够在这里吃上三天的当地美食，我觉得三生有幸。我们穿越了游人如织的海景酒店，吃过海边的卷饼饮过龙舌兰，在我看来，却远不及那招手即停的飞奔的公交，以及这市井生活中通宵的小店。对面的购物广场，是现代化城市的标准配置；而如我走遍天涯，却只想见识各地实在的风景。不是摩登就意味着快乐，也不是繁荣就会带来享受，人们追求着所谓更好的物质，却离一颗安定娴静的心愈来愈远。 我无须碧海蓝天来疏解烦躁的心情，只希望在旅行中探索人性和生命的意义。如同那张印刻在脑海里墨西哥小哥的笑脸，这段记忆，日后定会被我一次次提起。\n我愈发地享受着，在异国他乡，没有手机信号，充满语言障碍，远离日常的旅行。如果不逃离，你在哪里，都在那里。\n墨西哥城西北370公里，5个小时的大巴车程，传说中的旅游胜地瓜纳华托。 这里没有COCO电影里那么浪漫，但是已然十分惊艳。建在山里的城镇，一级一级扶摇直上，层层叠叠，尤其是夜晚灯光亮起，如繁星点缀，闪烁夺目。大街小巷都飘荡着节日的歌声，在崎岖回绕的建筑里穿行。我们住的宾馆，就有四层三十多间房，分布极不规则，愈往上房间愈少。而白天的市镇呈现出不一样的繁华，到处都满是人群，集市里尤其热闹。这个城市因为银矿而兴，老城地下更是隧道遍布，密集得如同排水网。而历史上，这些隧道的确也起到过泄洪的作用：山间曾经洪水肆虐，故而山城房屋越盖越高，低洼处也早已被打通至别处。\n墨西哥城亦是别具特色。对于一个中国人而言，来到另一个第三世界国家的人口密集的首都都是别样的经历。墨西哥城，正是个污染严重、交通拥挤、人口稠密、盛衰交杂的高原都市。她集中了全国五分之一的人口，承担了一半以上的贸易和经济活动，跟国内的密集人口地区非常相似。在城市中心区的步行街，每天早十点到晚十点都是人满为患，比之南京路是有过之而无不及。中心区大都是西班牙风格的建筑，白天街边都是商贩，金银首饰居多，而服装玩具电器也是交错其间。餐厅大都不在一楼，需要穿越街边的商贩从不起眼的狭窄入口进入，若非服务员带领则极难寻找。\n在墨西哥，亚洲人绝对是稀有物种。颖怡和佳星一天内被三番五次地要求合影，珍奇的异国人也有了明星的感觉。 大晚上的步行街，ATM机前面竟然排起了长龙，不经让人疑惑墨西哥人究竟是如何逛街的。\n不懂西班牙语，这种体验非常有趣。在宪法广场西侧寻找餐厅的时候，只朝天一指，估摸着餐厅的位置，就有路上的餐厅服务员说着西语过来给我们引路；点菜的时候常手舞足蹈，要一杯白水（agua）都能出现四五种可能。那日在面包店还看见了traditional agua，竟然是种紫色的布丁，让我们不禁猜测这个单词到底是个啥意思。\n墨西哥的几个重要时间点： * 13xx，Aztec王朝建立，历经七代； * 1519，西班牙殖民入侵，Aztec王朝覆灭； * 1810，在拿破仑战争席卷整个欧洲大陆期间，墨西哥宣布独立 * 1829，墨西哥建国，其后军事政变频发，独裁更迭频繁； * 1846-1848，美墨战争，墨西哥割让得克萨斯、加利福尼亚和新墨西哥州； * 1862，法国以“索债”为名，联合英国、西班牙军事入侵，奥地利大公被扶持为墨西哥皇帝； * 1867，Benito Juárez（墨西哥民族英雄和领袖，身高146）赶走了法国侵略者，枪决傀儡皇帝； * 1876-1910，Porfirio Díaz 独裁统治三十余年； * 1916，现代资产阶级民主政府建立\nAztec的金字塔在宪法广场的东北方保存了一处遗址，遗骸处依稀可见当年王朝的恢宏建筑。历经二百年，七任帝王，金字塔就扩建了七次，正如同玛雅人金字塔随时间轮回的扩增。而里处金字塔上神庙的复原发现，当年此处其实矗立着两座神殿，如同日月调和、阴阳相济，代表墨西哥人对自然的认知。如今的国家大教堂围栏里也分了大小两座，不知道是否也是遥相呼应的手笔。\n从墨西哥城中心的城堡Castillo de Chapultepec俯视整座城市，庞大、朦胧、现代与传统相融。公园中的人类历史馆讲述了美洲大陆的迁徙发展史，从亚洲跨越白令海峡到美洲，从玛雅到中墨西哥的Aztec。墨西哥是个多民族国家，她经历过封建、经历过殖民、经历过独裁，最后才过渡到民主，中北部的自然景象和东南部也全然迥异。历史上曾发生过不止一次的文明中断，而大面积的统一王朝直到14世纪才出现。看墨西哥的历史让我领悟了历史学的横向脉络，就像天体科学中的地质和大气研究一样：你会知道什么是生存的基本条件，什么是文明的基本要素，以及什么是繁荣延续的基本前提。而大类总是相通的：资源、文字、商业、科技。Aztec鼎盛的时期，是我国的明代——双方的实力对比，坦诚地说，不是一个级别。但是，文化的脉络、发展的轨迹，诸如此类的事物，却是惊人的相似。我遗憾地看到西班牙语遍布着整个拉丁美洲，说明在重要环节的缺失，会为社会的发展埋下严重的隐患。西班牙当年为了彻底征服Aztec王朝，把首都Tenochtitlan夷为平地，并且在神庙的遗址之上直接修建了教堂和宫殿。Castillo de Chapultepec屹立于墨西哥城内不多见的山丘之上，建于18世纪末，是西班牙总督的夏季行宫，原址就曾是阿兹台克建筑，后来成为西班牙修道院。我很好奇，墨西哥人民，尤其是Aztec的后代，是如何看待那段抹不去的殖民历史。\nTelcel是墨西哥随处可见的电信公司，也是拉丁美洲最大的电信公司，我原本以为是国有企业。但联想到曾经的世界首富Carlos Slim是墨西哥的电信巨子，若是国有就很难自圆其说。果然在多年前的新闻中查证，他在90年代初墨西哥国企转型期间收购了Telmex，随后便依托电信业的发展建立了庞大的商业帝国。在墨西哥，你是躲不开他旗下的产业的：从电话网络、轮胎瓷砖，到电视餐饮。人们抨击他从垄断和独裁中得来的财富，也有墨西哥人愤怒地控诉在这篇贫富差距巨大的国土中竟然出现了世界首富。他工作的时候几乎不做慈善，人们抨击他；在后来做了部分慈善，人们说他伪善。事实上，树大招风，你做什么，都有人抨击你。我欣赏他的一句话：拯救贫穷不能靠做慈善，而应该依靠教育和就业。他还知道中国的古谚：授人以鱼，不如授人以渔。\n据曾经生活在美国西海岸的朋友说，洛杉矶现在的第一大种族可能是墨西哥裔。室友去德州旅游归来，也说西语在休斯顿之类的地方要胜过英语。从美墨边境开车进入墨西哥检查极松，但入美国境却检查极严。川普曾说过要在美墨边境修一堵墙，来阻止墨西哥的偷渡者——不知道墨西哥的北部，是否代表着贫穷、混乱和毒品。\n在墨西哥，无论是坎昆还是墨西哥城，巨头主导的景象还是清晰可见的。坎昆的旅游项目几乎都被XCaret包办了，出租车和巴士也是统一把持；墨西哥城大部分的出租都是一样的长相，长途汽车站的巴士公司两强相争，更别提OXXO和Telcel这类零售和电信巨头。这里的资本化程度并不低，在拉丁美洲更是仅次于巴西的第二大经济和教育中心。美国资本的渗透也是非常明显。\n现金支付是当地大部分地区主要的方式，直到现在仍有大量居民不随身携带信用卡。网络支付发展缓慢，从我试图在线支付AeroMexico的选位费和长途巴士车费的屡次失败中就有切身体会。\n玉米是墨西哥最主要的食物，tacos遍地。墨西哥离不开洋葱和香菜，以及各式辣椒酱组成的salsa。但这次，我发现墨西哥的饮食不止以前理解中的那般粗旷，炸鱼干、芒果布丁、玉米肉汤、bistec asando烤肉、腌仙人掌、烤猪蹄、甚至面包都做得有滋有味。\n琐碎的感慨，离散的片段，浮光掠影，人世沉浮。"
  },
  {
    "objectID": "posts/mexico/index.html#section",
    "href": "posts/mexico/index.html#section",
    "title": "墨西哥杂记",
    "section": "2021/02/23",
    "text": "2021/02/23\n中国人并不了解墨西哥。对于我们而言，墨西哥的形象深深伴随着美国的影视作品：毒枭、偷渡、黑帮，不是已经黑在美国就是在前往美国的路上。2020年，墨西哥可能是中美贸易战的最大受益者，对美出口贸易甚至超过了中国。墨西哥是目前世界第十五大工业国，汽车工业占比30%，然而产品多数在北美内销了，所以国人对其的熟悉程度甚至还不如孟加拉的毛衣。三年前我去的时候，切身体验就是和中国很像。然而比之中国，他们的工业品牌更加稀缺，种类也高度依赖美国的风向，所以备受掣肘。摆脱美国小弟的形象，发展本土独立品牌，将是墨西哥未来寻求的道路。\n然而督工比我看得深刻的地方，就是找到为什么墨西哥没有在这么长的独立时间内建立本国完善的工业体系并晋升发达国家。落后国家为了建立现代化的工业体系，需要靠国家力量对本国产业进行补贴。比如苏联、中国在工业起步阶段都是靠农业倒贴工业，手段主要是关税和直接对企业发放补贴。然而墨西哥并不具备靠农业支持工业的条件，根源在于土改不彻底。于是墨西哥的方法是借外债。1982年外债危机爆发，这条路就被堵死了。对外，在资本主义国家进行自由贸易而没有太多的限制条件，并不是每个国家都能享受到的。在20世纪中后叶，能享受到单方面保护本国产业同时进行国际贸易的国家主要集中在苏联附近，都是靠政治上的牵制。而墨西哥位于北美洲，紧邻美国，倒向苏联阵营几乎不可能。墨西哥的地理位置，决定了她没得多余选择，只能在闭关锁国和彻底开放之间抉择；当遇到债务危机被迫开放的时候，墨西哥所有的工业企业无论是否准备好了，都必须暴露给全世界的竞争对手，所以墨西哥最终丧失了主导自身工业化的机会。几轮债务危机后，墨西哥的商业银行体系几乎全部外资化。北美自由贸易体系签署后，美国的廉价农产品大量涌入墨西哥，低效率的小农场快速破产，所以墨西哥的人均GDP停留在了一万美元的水平上，陷入了所谓的“中等收入陷阱”，在可期望的未来没有快速改善经济条件的机会。\n我的个人经验是，墨西哥主食玉米，同时近些年大量种植牛油果。玉米她几乎不可能种得过美国，牛油果估计是倾举国之力推销的农产品。然而牛油果的种植需要的水量惊人，据传对土地干旱有明显的加速效应。牛油果就好比智利的樱桃，都是想靠一种招牌农产品打通国际贸易的敲门砖。"
  },
  {
    "objectID": "posts/chrome/index.html",
    "href": "posts/chrome/index.html",
    "title": "Chromium Browsers",
    "section": "",
    "text": "When I bought a new laptop a few months ago, I decided to get a new Win10. Now the default browser on Win10 is Edge, which is built upon Google’s Chromium kernel. Things went well in the beginning. I compared the usage of Edge and Chrome, and found that the former consumes less memory than the latter, and the response times were both decent. I chose to use Edge for most regular works, and added an extension for blocking ads.\nUntil 2 weeks ago, some weird things happened. Besides the default home page, Edge also opened another url which displays traffic-pixel in the beginning and quickly jumped to Google search engine. WHen Edge was opened on the background, the new tag of Google will randomly pop out, which is really annoying. I thought this might be a virus, even though a seemingly innocent one. However, I didn’t find anything at all by searching in Google. Then I switched to Bing, and changed a few keywords. The first result with a link to Reddit immediately caught my eye: there were some guys discussing about this 19 days ago! Under their investigation, the culprit is the Edge extension AdBlocker! Indeed when I turned it off, the auto-generated new tag never come back again. Apparently Google’s engineers did some hack into this extension because AdBlocker targets at blocking ads on YouTube.\nI should be more careful about using Chromium extensions, especially on Edge. The available choices are limited on the market. Maybe the better choice is to install extensions from Chrome if I really want to."
  },
  {
    "objectID": "posts/practice-c++/index.html",
    "href": "posts/practice-c++/index.html",
    "title": "Practicing C++",
    "section": "",
    "text": "If scientists read coding standards and recommendations like C++ Core Guidelines in the first place, then it is less likely that science codes will be poor in performance and unmaintainable.\nQuoted from A Tour of C++: &gt; With the growth of the language and its standard library, the problem of popularizing effective programming styles became critical. It is extremely difficult to make large groups of programmers depart from something that works for something better. There are still people who see C++ as a few minor additions to C and people who consider 1980s Object-Oriented programming styles based on massive class hierarchies the pinnacle of development. Many are struggling to use C++11 well in environments with lots of old C++ code. On the other hand, there are also many who enthusiastically overuse novel facilities. For example, some programmers are convinced that only code using massive amounts of template metaprogramming is true C++. &gt; What is Modern C++? In 2015, I set out to answer this question by developing a set of coding guidelines supported by articulated rationales. I soon found that I was not alone in grappling with that problem and together with people from many parts of the world, notably from Microsoft, Red Hat, and Facebook, we started the “C++ Core Guidelines” project [Stroustrup,2015]. This is an ambitious project aiming at complete type-safety and complete resource-safety as a base for simpler, faster, and more maintainable code [Stroustrup,2015b]. In addition to specific coding rules with rationales, we back up the guidelines with static analysis tools and a tiny support library. I see something like that as necessary for moving the C++ community at large forward to benefit from the improvements in language features, libraries, and supporting tools."
  },
  {
    "objectID": "posts/practice-c++/index.html#performance-tips",
    "href": "posts/practice-c++/index.html#performance-tips",
    "title": "Practicing C++",
    "section": "Performance Tips",
    "text": "Performance Tips\n\nLearn a profiler, e.g. Intel Advisor & VTunes, and go through the suggestions.\nUse preincrement rather than postincrement if possible to avoid extra saving of previous value, since the canonical form of postincrement looks like\n\nT T::operator++(int)\n{\n  T old( *this ); // remember our original value\n  ++*this;        // always implement postincrement\n                  //  in terms of preincrement\n  return old;     // return our original value\n}\nThis is mostly useful for iterators but not arrays, because compilers are generally smart enough to optimize for array loops.\n\npass objects by (const) reference to functions\nreturn objects by (const) reference whenever practical\nmake sure you declare a reference variable when you need it:\n\nclass Foo\n{\n    const BigObject & bar();\n};\n\n// ... somewhere in code ...\n//BigObject obj = foo.bar();  // OOPS!  This creates a copy!\n\nconst BigOject &obj = foo.bar();  // does not create a copy\n\nDon’t declare (actually, define) object variables before their use/initialization (as in C). This necessitates that the constructor AND assigment operator functions will run, and for complex objects, could be costly.\nUse heap memory (dynamic allocation) only when necessary. Many C++ programmers use the heap by default. Dynamic allocations and deallocations are expensive.\nMinimize the use of temporaries (particularly with string-based processing). Stroustrup presents a good technique for defining the logical equivalent of ternary and higher-order arithmetic operators in “The C++ Programming Language.”"
  },
  {
    "objectID": "posts/practice-c++/index.html#styling-tips",
    "href": "posts/practice-c++/index.html#styling-tips",
    "title": "Practicing C++",
    "section": "Styling Tips",
    "text": "Styling Tips\n\nSince C++11, there is a so called “range-based for loop”, which acts like\n\nvector&lt;int&gt; vi;\n...\nfor(auto i : vi) \n   cout &lt;&lt; \"i = \" &lt;&lt; i &lt;&lt; endl;\nIf you prefer the iterator style, you can write something like\nfor(std::vector&lt;T&gt;::iterator it = v.begin(); it != v.end(); ++it) {\n   it-&gt;doSomething();\n}\n\nThe keyword virtual in front of function declaration in subclasses is not necessary, but it helps readability if one only sees the subclass.\nThe keyword auto is helpful for readability, but don’t abuse it."
  },
  {
    "objectID": "posts/practice-c++/index.html#syntaxes",
    "href": "posts/practice-c++/index.html#syntaxes",
    "title": "Practicing C++",
    "section": "Syntaxes",
    "text": "Syntaxes\n\nAfter C++11, iterators is the preferred way of looping through vectors. Together with auto, it makes things nice and clean:\n\nauto numbers = std::vector&lt;int&gt;{1, 1, 2, 3, 5, 8};\nfor (auto iter = numbers.begin(); iter != numbers.end(); ++iter)\n{\n   std::cout &lt;&lt; *iter &lt;&lt; '\\n';\n}\n\nfor (auto& iter = numbers.begin(); iter != numbers.end(); ++iter)\n{\n   std::cout &lt;&lt; iter &lt;&lt; '\\n';\n}\nHowever, be careful when you refer to, e.g. vector of vectors:\nfor(vector&lt; vector&lt;int&gt; &gt;::iterator row = dataset.begin(); row != dataset.end(); ++row)\n{\n   //for(vector&lt;int&gt;::iterator col = row-&gt;begin(); col != row-&gt;end(); ++col)\n   for(auto col = (*row).begin(); col != end(*row); ++col)\n   {\n      cout &lt;&lt; *col &lt;&lt; ' ';\n   }\n   std::cout &lt;&lt; std::endl;\n}\nWithout the parentheses before and after *row, the compiler will make a binding error about which should the begin function applys to! Check a later bullet point of using arrow operator instead.\nAlternatively, the above can be easily achieved by\nfor ( const auto v : dataset )\n{\n   for ( auto x : v ) std::cout &lt;&lt; x &lt;&lt; ' ';\n   std::cout &lt;&lt; std::endl;\n}\n\nArrow operator: the following two expressions are equivalent\n\nfoo-&gt;bar()\n(*foo).bar()\n\nIn abstract classes you can see virtual functions. If you see any\n\nvirtual void getParameters()=0;\ninside a class declaration, it indicates that this is a pure virtual function, i.e., one that needs to be implemented in the derived classes.\n\nstatic keyword\n\n“static” for variables, class members and functions have different meanings. Check this tutorial.\n\nprivate and protected keywords\n\nPrivate members are only accessible within the class defining them.\nProtected members are accessible in the class that defines them and in classes that inherit from that class.\n\nconst & constexpr keywords"
  },
  {
    "objectID": "posts/ubuntu-sound/index.html",
    "href": "posts/ubuntu-sound/index.html",
    "title": "Ubuntu Soundtrack",
    "section": "",
    "text": "I’ve been using Ubuntu 18 for quite some time now. One thing that is frequently not working properly is the sound output switches. It happens from time to time that if I connect my Ubuntu laptop to a monitor, or a headset, the system will lose track of its desired sound output. I have to go into the sound settings and manually switch the output profile between HDMI and hifi (which I suppose is the default laptop sound output). A little bit tedious."
  },
  {
    "objectID": "posts/software-installation/index.html",
    "href": "posts/software-installation/index.html",
    "title": "Software Installation",
    "section": "",
    "text": "The first thing to tell if one is familiar with codes is whether he or she can compile it. As I move to new group using a completely different code, this is a good chance to learn the workflow."
  },
  {
    "objectID": "posts/software-installation/index.html#design",
    "href": "posts/software-installation/index.html#design",
    "title": "Software Installation",
    "section": "Design",
    "text": "Design\nI would say Vlasiator chose a very different approach compared to SWMF, the latter of which has everything bundled together as a stand-alone package. I love the design that there is no absolute path in the config or Makefile. Meanwhile I don’t like the choice of Makefiles set by an environment variable, neither do I enjoy reading the installation guidance with pieces of information here and there. The lack of help information is really a big barrier for new users.\nHonestly this is the first time I’ve ever looked into the details of C++ package dependencies. I spent some time understanding which files/packages should be in the lib paths, and which should be in the include paths. I looked at how Vlasiator handles all the dependencies in the Makefile as well as the parameters, and thought there might be a way to greatly simplify the installation process. At this point I still don’t know how Vlasiator chooses which problem to solve, but that should be an easy one.\nHere is a list of issues that I found:\n\nWhen using git for an open source project held on GitHub, we should usually access through https but not ssh.\nOverall the dependencies are too complicated to handle manually. I have been working with scientific codes for years now, but it still took me quite a while to install all the dependencies.\nThe installation guide wiki page is not easy to follow. I would be amazed if any outsiders successfully compile the code by following the guidance.\nChanging all the parameters directly in the Makefile is not a good idea; explicitly listing all the compilation dependencies is also unnecessary and unmaintainable for large C++ projects.\nSource codes should be better organized by folders.\n\nI remember during the past few months at Michigan, I complained quite a bit about how BATSRUS can utilize the modern workflow better and become more productive. I would not realize the actual situation in other scientific groups if I did not move. This is the process from which I learn.\nFinally after more than two days of work, I got something that works as I wished. Similar to the Config.pl file in SWMF, the new configure.py file is used to set the parameters and library paths before compilation. Alternatively, one can just type -install to make a fresh installation. This file is borrowed from the Athena++ code at Princeton with many modifications. I would say in the world of scripting, the most commonly used ones I see are Python, Perl and Shell. Exactly which one is used is highly dependent on the time it is written. Either one will work if you put enough effort, but it is nice to at least have a taste for each of them. As a fan of Julia, even though I really want to use it here, I know it will be slow and unportable at the current time without an interpreter. As a rule of thumb, understand your goal and choose wisely according to your needs.\nMeanwhile, I also tried to reorganize the code placement to make it look better. I don’t know if other guys will like it or not; let’s just wait and see.\nThe current situation at the Vlasiator group reminds me of the potentially similar one happened at CSEM 20 years ago, when Gábor were recruited by Tamas and became the leader in code development. That is good and bad, in some sense. We are no longer in the world 20 years ago. Yesterday when I was wandering around the campus, I saw the computer science department right below my office, with the introduction of Linus Tolvards everywhere. If one truly believe in the concept of open-source, make it easy to install the code is the first step, and then collaboration and improvements will come as a group effort. Admittedly it would still be a practical issue to figure out how to avoid unnecessary competition and “stealing”, especially when it comes to fundings. But I have faith."
  },
  {
    "objectID": "posts/software-installation/index.html#progress",
    "href": "posts/software-installation/index.html#progress",
    "title": "Software Installation",
    "section": "Progress",
    "text": "Progress\nIt turns out that a real compatible work takes me not two days but two weeks. After getting the advices from group members, I realized that totally abandoning the previous customized Makefile workflow is not ideal, and I have spent quite some time coming up with a proper way of setting those library paths in the main Makefile as well as customized ones back and forth. Keeping codes that are presumably useful in the future is also not a good idea, which is something I have read about a couple of months ago, and now it goes into practice.\nSo now on a fresh new machine running Ubuntu, one can simply do\n./configure.py -install\nmake\nto generate the binary executable if Boost is already installed in the default location. This can be polished better if more user cases are collected, but at this point I don’t have to do anything further. Loading and saving customized Makefiles are also plausible, but additional improvements are only possible if anybody uses and complains.\nThe golden rule for me as an open-source project: if it cannot be compiled and run the first time, don’t waste your time on it unless there is really something interesting underneath!\nPackage dependency is a hell. For example, if you install one of the most famous plotting packages nowadays matplotlib using pip, you need to not only say pip install matplotlib, but also other packages if you want to display the figures on the screen, otherwise by default it will use the agg backend with no display. That is why some people recommend installing it using apt-get under Ubuntu/Debian. However, the system-wise package management system seems to have some issue recognizing my self-installed version of python3.9 instead of the system default python3.6. Lately people recommend using Conda to handle all Python dependencies, and indeed I have better experience with conda. Nothing is perfect.\nNext step is obviously testing. This is kind of missing for Vlasiator. Currently the existing part uses shell script to do testing, but I would say either the shell scripts need improvement, or they should be replaced with Makefile or other scripting languages. Let’s wait for the next chapter."
  },
  {
    "objectID": "posts/io/index.html",
    "href": "posts/io/index.html",
    "title": "IO Hardwares",
    "section": "",
    "text": "Data access speed is important. In many applications, it is more important to have faster data access speed than higher CPU frequency.\nThere are several new types of data storage hardwares, which are closer to the speed of RAM compared with the SATA HDD:\n\nSATA SSD: solid state drive, commonly seen nowadays on even PCs.\nNVMe SSD: a new protocol for flash media storage. 10x faster address seek time than SATA SSD.\n\nTypical file transfer speeds: | HDD | SATA SSD | NVMe SSD | |—–|———–|———-| |200MBps| 550MBps | 3GBps |\nAmong the NVMe devices, Intel Optane is currently the most expensive one."
  },
  {
    "objectID": "posts/latexdiff/index.html",
    "href": "posts/latexdiff/index.html",
    "title": "Using latexdiff",
    "section": "",
    "text": "Compare the differences between files is a tedious task. However, if you pick the right tool, it may become as easy as one line command.\nFor my first paper, I learned a little bit of using the package trackchanges. This package provides some basic commands of manually pointing out the removal, substitution and comments. It is good enough if you use it from the first place. What if I added some changes and forgot to track them initially? Then probably you should turn to latexdiff.\nlatexdiff is an invaluable utility that makes it easy to markup and view changes made to the document. It definitely reduced my burden of having to read through two files simultaneously where it would be easy to overlook subtle changes like word substitutions and changing numbers or signs in an equation. My advisor, who is an expert in Perl, specifically pointed out that latexdiff is an excellent script written in Perl. I searched on Google and found the author named F.J. Tilmann; he is supposed to be a scientist who happened to know Perl pretty well. And this script has been developed and maintained by him since 2004. You can check it out here. A basic introductino is provided on Overleaf.\nI spent two hours on my first attempt to make it work, but I failed. Then my advisor and I sat down together and digged into the problem. After about half an hour, we finally figured out that the issue for my latex source file is that in the lstlisting environment where I showed some demo codes for OpenMP, there is a single dollar sign $ in the text, which is interpreted as the math environment in Latex. Since that one $ is assumed to come in pair to mark the beginning and end of math input, latexdiff made a mistake all across the file trying to match that $ sign with some other one that comes later. Unfortunately for string parsing tasks, similar symbols like single quote, double quote that cannot be distinguished either the start or end position will be a nightmare.\nAnyway, we finally found the problem. Actually, there is an option named PICTUREENV which can be used to exclude some kind of environments. However, it didn’t work for me."
  },
  {
    "objectID": "posts/la/index.html",
    "href": "posts/la/index.html",
    "title": "洛杉矶杂记",
    "section": "",
    "text": "09/06/2018\n第一次来洛杉矶，来到了加州大学洛杉矶分校。这时仍是他们的夏季学期，但学校里却依然人潮涌动。来回两遍，我已经对这里的方位烂熟于心。 齐怡师妹很热情，这其实只是我第二次跟她讲话，然而人家开组会到六点多还依旧请我们出来吃东西，并一路把我们送回住处。和她聊天的过程中，有种安心的感觉——或许就是师妹的人格魅力。那种不紧不慢、娓娓道来的谈吐，和大方得体，出落有度的风范，看得出门第。四川妹子，了不得。看清一个人本不需要很久，只在于你的观察是否用心。\n\n\n09/07/2018\n夜幕下的格里菲斯天文台，迷雾中的洛杉矶夜景。在木星和土星之间驻足留影，和外号“大猩猩”的美国人讲着中文谈笑风生。偶遇林峰，也是一种缘分。\n\n\n09/09/2018\nCamilla带着我跟Yash参观了UCLA的地球物理系、物理系和天文台。惊讶地发现他们这里大部分的地方大门不锁，出入数学楼的屋顶轻而易举。殊不知，站台天台上，真的能看到璀璨的星空，即便是繁华如洛杉矶。Camilla说她以前经常来这里，特别喜欢天台的感觉。仰望星空的习惯，也许就是这样培养起来的吧。她跟我们讲了很多学校的趣闻，比如物理系门口的反向喷泉。传说在校学生如果不小心溅到了喷泉的水就会挂科，所以在毕业季，常会看到即将离校的学生把曾经的作业和考卷丢进喷泉里——因为他们再也不用担心成绩的问题了。物理系的老楼楼檐上涂画着各式神奇的图案，像极了外星人留下的讯息。\n这几天快到他们开学的日子，一波又一波的新生被分成了一个个小团体开始各类熟悉校园的活动。大清早广场上人满为患人头攒动，到了晚上只听见沿路引吭高歌恣肆大笑。Camilla和Yash在感慨，现在的年轻人打成一片的时间真是快得惊人。回想当初，Camilla说最开始和她在一起分组活动的伙伴，后来几乎再也没有在学校有过交集。大学的分化和选择有多繁杂，可见一斑。\n我们聊天，聊七宗罪、聊金钱的罪恶、聊饮食、聊老师。直到这一刻我才感到，思想的交流也可以通过非母语来完成。这种人生的思辨，语言不过是一种载体。语言当然是重要的；但我一直觉得，一个人对于思考、对于情绪的体察、对于条理的分析，是不存在语言的障碍的。人类这一物种神奇的其中一处，便是我们殊途同归的内核构造。\n\n\n09/12/2018\n这次会议让我受益良多。我终于感觉自己能学习到很多不了解的东西，也能认知到众多方法的来龙去脉。以人为鉴知得失，你能看清好坏，辨明真伪，就已不易。诚然，我还是不擅长交际，也不是那么喜欢交际。但是，在科学这种领域，懂的自然懂，不懂装懂就是件累人的差事。真才实学，是我一直追求的境界。\nYash有一个设计并实现电离层电磁模型的想法，用以取代现有的静电模型。我非常想和他一起做这个项目。\n\n\n09/13/2018\n申请经费要趁早：这活耗时耗力，却不一定有好结果。\n晚宴上，当David展示出当年他的导师和学生们在一起的照片，我不禁感慨良多。照片里的诸位，如今几乎都是教授级别的人物，依旧活跃在科研的舞台上。这个模拟的国际学校已经办了13届了，并且依旧充满了活力。受益良多，远比于其他的会议。\n\n\n09/14/2018\n仍旧感到有些寂寥。谁不想身边有人陪伴的感觉。怅然若失，不能自拔。"
  },
  {
    "objectID": "posts/biostation/index.html",
    "href": "posts/biostation/index.html",
    "title": "Biostation Retreat",
    "section": "",
    "text": "系里组织的第一次博士生的出游活动，一看是临近北密的学校的生物站，时间允许二话不说就去了。五年级的博士生只有我跟毅轩两人，其他都是些年轻的面孔。同届的学生估计大都很忙吧。作为系里五年来第一次的集体出游，真是要给研究生会的同学点个赞。\n北密嘛，老地方了，连绵的森林、起伏的山丘、错落有致的风景。生物站坐落于湖边，阵阵妖风过境常有虎啸山林之感，夜晚临近天色骤暗，伸手不见五指。那种原始的和自然的亲近感，出没在消失的灯光里。湖上涟漪涌动，岸边停靠的小舟可以随取随划，硕大的湖面一眼忘不见对头。我们在林间穿梭，走下峡谷追随溪水的流向，直到估摸着午饭的时间才匆匆折返。美国同胞热爱徒步，此言不虚。到了下午，他们争先恐后跳入湖中，徐徐寒意根本不足为惧，唯有那种湖水与肌肤尖锐的触觉才能激发年轻的荷尔蒙。我已经老到脱不开午憩的程度，对于下水更是毫无兴趣。可能写几行代码才是更能刺激我的事情吧。 两晚的破冰行动（ice breaker）是出游的最大亮点。往事不堪回首，我漂洋过海四年，竟从来没有和美国同学有过这般非正式的交流互动。那些先入为主的概念，那些自以为是的矜持，全都是心里的小鬼在作祟。比如那个轮转一圈的你画我猜游戏，起初我以为凭我的绘画水平能成为众人的笑柄，甚至都动了缩在一旁观摩的念头，但实际参与下来才发现大家水平其实都差不多，就无非图个乐开心一下。另外的两个事实猜测游戏，真是陌生人社交里面的经典，参与其中才会意识到这种互动的卓有成效。中文、英文，其实不太重要，关键的是你敢说、会说。我要跨出这一步，建立自己的社交圈子。不怕出丑、敢于表现。 还是一些小细节更有意思。玩儿猜纸条上写的事实是关于谁的游戏时，我一下就听出来那个有关同性恋的故事是北大师弟写的，原因有二：他在游戏开始前主动提出能否更换纸条，因为他已经觉察出可能不妥；那种表达方式，太中国化。我完全能够理解他的尴尬之处，而他在承认之后的淡定解释也让我十分钦佩。那的确有点冷场，比如开头的Gay被变通的美国同学解释为Guy，也能体现出情商之高。Shannon是一路坐我车的美国胖妞，麻省人，非常和蔼健谈，年轻而有主见。她是新来的系主任Tujia的第一个学生，在Emory上了四年本科，偶然的机会和系主任想做的极光与机器学习研究一拍即合。我第一次和美国人谈论起中国的问题，中国和美国的差异，以及我眼中未来的发展方向。我们从纸质期刊聊到媒体站队，从言论控制聊到社会进程，那种表达的畅快感是前所未有的。我还成功得推销了一把Julia，人类努力的结晶应该有更多人来享受。Alan是大气那边的三年级，异常的活泼健谈，母亲是波多黎各人，开起玩笑信手拈来。Tim是我的室友，Gabor多年来招的第一个美国人，典型的Geek，Sheldon类型，smart is the new sexy.至今依然保持着早睡早起的规律作息，不顾旁人阻拦捧起一泓溪水一饮而尽，高中时就做过关于陶瓷超导的课题研究。Gabor会喜欢这个学生的，道不同不相为谋。Zach Butterfield 带我们去参观了他们组里做光合作用空气组分的野外观测塔，还舍身为我们示范了一下爬上近20米高台的英姿飒爽。Sarah作为整个活动的组织者尽心尽力，拿出了一个领导者应有的风范和担当。还有一个拥有奥地利美国双重国籍的Dan，一个曾参与大学冰球联赛的Dan，一个满口英式英语的芬兰小哥，Zach & Emily，扭伤了脚踝的小哥，也很Geek但有时也有点儿Creepy的小胖哥Chris，讲了个高中时科学小组的高尔夫发射器设计被Sarah说非常Chris的故事，Michael Jackson died on my birthday的金发美女小姐姐，热情开朗的Natasha，和活泼可爱的师妹樱潇……更不用说多年的好朋友毅轩，马上就要毕业了，以后去台湾一定找他。人有时会有惊人的记忆力，那种沉浸的快感令人陶醉。 师妹在回来的车上还问我该怎么提高英语，聊起来说她考过五次托福，申请之路也是一波三折。偶然机会才得知是兰州人，南京大学人才济济，我辈之中后生可畏。\n除了我们之外，一群Rackham fellow的老教授们也在那里召开讨论班一类的活动。这个生物站已有110年历史，夜不闭户，wifi信号却异常地好。想象着那种在大自然的怀抱中科研的场景，就连写出来的代码，也应该更富诗意吧。 投我以木桃，报之以琼瑶。愿密大一直守护着这世间的美好。"
  },
  {
    "objectID": "posts/presentation/index.html",
    "href": "posts/presentation/index.html",
    "title": "简报制作",
    "section": "",
    "text": "作报告的时候，我们可以尝试加入电影一样的运镜方法。这方面比较亮眼的产品是一款叫Prezi的在线编辑器。 用它做出来的展示品不仅可以实现运镜效果，还可以在视频及视频会议中达成类似动态展示的效果。官方支持里面竟然没有中文，这是有点令人意想不到的。\n我已经在设想，比如做一个关于磁层中波动研究的成果展示，在主页面放一张全局磁层背景图，每一个感兴趣的区域是一个可以缩放的节点，每次运镜就跳转到那个区域，伴随的是各式各样的分析图像和动画。接近动态的展示效果，绝对能让人眼前一亮。难怪在Youtube PAPAYA频道介绍时用的雷人标题是“台下为什么跪了”。从一个类似科普的大气科学展示例子中，我们大致就能感受到这种不同于传统PPT甚至PDF的动态风格。"
  },
  {
    "objectID": "posts/presentation/index.html#体验",
    "href": "posts/presentation/index.html#体验",
    "title": "简报制作",
    "section": "体验",
    "text": "体验\n我试用了一下免费版，很多功能不支持。可能收费版本会好很多。目前最大的一个问题是，完全不支持中文输入。"
  },
  {
    "objectID": "posts/gravity-wave/index.html",
    "href": "posts/gravity-wave/index.html",
    "title": "Gravity Wave",
    "section": "",
    "text": "Make analogies of what you don’t know to what you know."
  },
  {
    "objectID": "posts/gravity-wave/index.html#questions",
    "href": "posts/gravity-wave/index.html#questions",
    "title": "Gravity Wave",
    "section": "Questions",
    "text": "Questions\n\nWhat is a gravity wave?\nHow can we observe gravity waves?\nWhy is it important?"
  },
  {
    "objectID": "posts/gravity-wave/index.html#basic-math-tools",
    "href": "posts/gravity-wave/index.html#basic-math-tools",
    "title": "Gravity Wave",
    "section": "Basic Math Tools",
    "text": "Basic Math Tools\nEinstein notation\nCovariance and contravariance of vectors\nI found a series of Khan lectures on the maths related to Einstein notation. I should go through the basics before doing anything special, cuz you can only speak after you learn the language.\nThere is a simple example for superscript and subscript. A simple rule is that subscripts represent row vectors and superscripts represent column vectors. (This is ONLY true for Euclidean space.)\nA Complete Guide to The Ricci Tensor.\nRiemann geometry"
  },
  {
    "objectID": "posts/gravity-wave/index.html#section",
    "href": "posts/gravity-wave/index.html#section",
    "title": "Gravity Wave",
    "section": "",
    "text": "Take a look at electromagnetic tensor. The Maxwell’s equations can be derived from from the Lagrangian formulation."
  },
  {
    "objectID": "posts/gravity-wave/index.html#section-1",
    "href": "posts/gravity-wave/index.html#section-1",
    "title": "Gravity Wave",
    "section": "",
    "text": "Degree of freedom:\n\nsymmetry of 3x3 tensor –&gt; 6\ntraceless: \\(g_{ii} = 0\\) –&gt; 5\n\n\nDimensional Analysis"
  },
  {
    "objectID": "posts/gravity-wave/index.html#physics",
    "href": "posts/gravity-wave/index.html#physics",
    "title": "Gravity Wave",
    "section": "Physics",
    "text": "Physics\n\nComparison With Electromagnetic Waves\n\n\nCosmic Microwave Background\nCosmic microwave background.\n\n\nMore questions\n\nDo photons have energy?\nE and B modes w.r.t. polarization and their naming origin.\nScalar, vector, and tensor modes in gravitational waves? Here is a related paper of simulations."
  },
  {
    "objectID": "posts/east-america/index.html",
    "href": "posts/east-america/index.html",
    "title": "东游记",
    "section": "",
    "text": "白雾飞溅成雾，阳光幻化成虹；隆隆落水相伴，偏偏海鸥共舞。\n一路东行，从安娜堡出发，到克利夫兰、水牛城、大瀑布、波士顿、然后纽约。\n出来旅行一趟，父亲丢了一根充电线，母亲丢了一件毛衣，还差点把自己手机丢在别人餐厅里。人年纪大了就是容易丢东西，没法回避的话，关键在于如何防范和面对这样的遭遇。丢东西不可怕，可怕的是持续的抱怨和负面情绪。共勉。\nFort Lee有家包不同，上海菜，水平之高着实令人惊异。相比之下，法拉盛的南翔小笼就相形见绌了。中国人常言酒香不怕巷子深，那天在包不同，我们足足等了40分钟，吃完出来八点多还是有人在等位，足见这店家的口碑。\n自己在纽约游荡的日子，这次逛了一圈在皇后街的纽约科技馆。科技馆在1964年世博会的旧址上，其余的地方也被改造成公园、运动场，以及博物馆和动物园。每年一度的美网也在这里举行，各类运动的爱好者们也屡见不鲜。最有意思的一种可供出租的手摇式自行车，人几乎是躺在里面，全凭手臂摇动把手前进，速度也不见得慢。 科技馆没有我想象的大，里面全是孩子，布展也是略显凌乱。作为科技馆，和一般博物馆最重要的区别在于互动性——这一点上，它做得很出色：几乎所有的展览都可以动手操作，鲜有维修或是坏了的机器。小朋友们哪里有耐心阅读所有的说明文字，大都是上去一顿操作，如果没有得到及时的反馈就很快丧失兴趣，进而转向下一个展品。也就像我这种悠哉的游客还懂一些科学，看到感兴趣的展品会仔细端详一阵。偶然间看到一台出错的电脑，Suns的机器报错在黑白屏上，倒是让我驻足看了一会。一个馆里的年轻伊斯兰女孩儿看到了这一幕，过来问我是否知道怎么维修这台电脑。我笑笑说其实也不怎么懂，只是快有个计算机的辅修学位，看到这些东西可能有些兴趣。她又问我那我的主修是什么，我说是物理。她一脸惊叹和略显崇拜的表情，告诉我前面还有很多物理展览可以看看。我有些小得意，又又点不太好意思，说我就是感兴趣才来参观的。最后一句祝福，我们便分开了。单纯而可爱的姑娘。 倒还是有些收获。看到了数学家们如何嘲笑物理学家、化学家的思维逻辑；看到了几何曲线最直观的美；知道了一种证明圆柱和平面的截面是椭圆的方法；看到了Zeta函数的几何形状；看到了闵可夫斯基几何的精妙结论；看到了古老而直观的网格灯泡乘法器；看到一张近现代数学从15世纪以来由巨人谱写的年表.；看到了木卫三掠过大红斑的壮观图片…..我忽然想起了伟大科学家朴素观念的开端：时间与空间的联系；事物与周期性的联系；连续和离散的关系；数字和几何的关系……重要的是想法。"
  },
  {
    "objectID": "posts/parallelism/index.html",
    "href": "posts/parallelism/index.html",
    "title": "Parallel Programming Concepts",
    "section": "",
    "text": "很长时间我都没能准确理解多进程之间的工作关系，特来梳理一下。名词上可能不太准确，但是尽量争取概念上是对的。"
  },
  {
    "objectID": "posts/parallelism/index.html#execution-units",
    "href": "posts/parallelism/index.html#execution-units",
    "title": "Parallel Programming Concepts",
    "section": "Execution Units",
    "text": "Execution Units\nThe smallest execution unit the computer system can handle is thread, which in principle can be even transferred between different cores. Old computers can only execute single thread from each single program on a single CPU core, so there is no need to distinguish between threads and processes. With the advance of multi-core systems, we need to build the level of abtractions.\n\nThread is now truely the smallest execution unit.\nA process can launch multiple threads among a number of cores within one processor.\nA program can have multiple processes on different processors.\nThe abstraction makes it such that it is not a strict 1-to-1 mapping between physical processors and virtual processes. For instance, an MPI program can launch more processes than what is physically available on the system.\n\n简单的比喻，一个多进程程序就像一个团队一起做一件事情：一个进程就是一个人，一个线程就是一个人可以同时做好几件事情。"
  },
  {
    "objectID": "posts/parallelism/index.html#standards",
    "href": "posts/parallelism/index.html#standards",
    "title": "Parallel Programming Concepts",
    "section": "Standards",
    "text": "Standards\nBe aware of the difference between a protocol and an implementation.\n\nMessage Passing Interface (MPI) is a standardized and portable message-passing standard designed to function on parallel computing architectures.\n\nMPICH, OpenMPI are implementations of MPI.\nEven though originally only C, C++, and Fortran are supported, there are now bindings which are libraries that extend MPI support to other languages by wrapping an existing MPI implementation such as MPICH or Open MPI.\n\nOpenMP (Open Multi-Processing) is an application programming interface (API) that supports multi-platform shared-memory multiprocessing programming in C, C++, and Fortran.\n\nOpenMP implementations are coupled into vendors’ compilers, if they are claimed to support a certain OpenMP version.\n\n\nAny low level parallel library needs to deal with the system. In C++, there is a standard library pthread which allows you to interact with system threads (which is not available in the high level OpenMP); In Julia, the standard library Distributed is a native implementation of one-sided communication between processes. The implementation details envolves many network concepts like hand-shaking, data packing/serializing/deserializing, etc."
  },
  {
    "objectID": "posts/parallelism/index.html#how-to-get-a-faster-multi-processing-framework",
    "href": "posts/parallelism/index.html#how-to-get-a-faster-multi-processing-framework",
    "title": "Parallel Programming Concepts",
    "section": "How to Get a Faster Multi-Processing Framework",
    "text": "How to Get a Faster Multi-Processing Framework\nFactors that affect the parallel system’s performance:\n\nnetwork connection speed\nchecking procedures when establishing the connection, sending/receiving messages, and closing the connection\nthe size of data that requires communicating\nthe frequency of communication\n\nFrom a software programmer’s perspective, only the last two points can be controlled."
  },
  {
    "objectID": "posts/parallelism/index.html#设计理念",
    "href": "posts/parallelism/index.html#设计理念",
    "title": "Parallel Programming Concepts",
    "section": "设计理念",
    "text": "设计理念\n在并行领域，实际程序的执行效率天差地别。这就好比说众人拾柴火焰高，然而三个臭皮匠还不一定顶得过一个诸葛亮：我们经常能见到所谓并行程序比串行程序还慢的情况。宏观上来讲，提高并行效率无非这么几条原则：\n\n保证每个“人”有能力高效工作（efficient serial execution）；\n保证每个“人”有活可干（load-balancing）；\n减少不必要的开会，任务分配下去后，少量高效地沟通，最后一道汇总（reducing communication）。\n\n并行程序就好比一家公司，成天开会的公司干不成活的。"
  },
  {
    "objectID": "posts/parallelism/index.html#modern-philosophy-of-concurrency",
    "href": "posts/parallelism/index.html#modern-philosophy-of-concurrency",
    "title": "Parallel Programming Concepts",
    "section": "Modern Philosophy of Concurrency",
    "text": "Modern Philosophy of Concurrency\nQuoted from the Go language documentation:\n\nDo not communicate by sharing memory; instead, share memory by communicating.\n\nChannel is a programming concept for implementing this idea. A channel in programming has two halves: a transmitter and a receiver. A channel is said to be closed if either the transmitter or receiver half is dropped."
  },
  {
    "objectID": "posts/basketball-court/index.html",
    "href": "posts/basketball-court/index.html",
    "title": "Basketball Court in Shenzhen",
    "section": "",
    "text": "在深圳找个合适的篮球场真是不容易。到了夏天太阳暴晒，无阴凉处五点以前基本上不用考虑。"
  },
  {
    "objectID": "posts/basketball-court/index.html#福田附近",
    "href": "posts/basketball-court/index.html#福田附近",
    "title": "Basketball Court in Shenzhen",
    "section": "福田附近",
    "text": "福田附近\n\n景田村：步行7分钟，仅有一个半场，免费，人多。\n印力中心：在山姆，地铁2号线侨香，步行1km，距离24分钟。有部分阴凉，时常有培训。\n香蜜湖PW篮球公园：地铁9号线香梅，步行340m，距离15分钟。无阴凉。还有一家总店，离得很近，已经关门了。\n香蜜公园体育中心：地铁2号线侨香或者香梅北，步行800m，距离20分钟。收费散客10元，无阴凉。市政运动设施，维护良好。\n皇冠篮球场：在车公庙，地铁9号线下沙，步行1km，距离26分钟。\n深圳湾：2号线福田转11号线后海，步行1.1km，距离39分钟。去过一次，无阴凉，\n梅林Q-Park-V5：地铁9号线上梅林，步行1.5km，距离32分钟。\n红树西岸会所：一个小号室内空调全场，场地条件非常不错，仅提供包场，距离40分钟。\n宝安体育中心：传说中动作非常大的场地，距离50分钟。"
  },
  {
    "objectID": "posts/pic/index.html",
    "href": "posts/pic/index.html",
    "title": "Kinetic Plasma Simulations",
    "section": "",
    "text": "昱曦向我推荐了一个Anatoly Spitkovsky的动力学模拟的讲座，\n这里整理一些笔记。"
  },
  {
    "objectID": "posts/pic/index.html#what-are-we-missing-from-fluid-descriptions",
    "href": "posts/pic/index.html#what-are-we-missing-from-fluid-descriptions",
    "title": "Kinetic Plasma Simulations",
    "section": "What Are We Missing From Fluid Descriptions",
    "text": "What Are We Missing From Fluid Descriptions\n\nFree energy contained within each fluid species due to interactions is completely lost due to the fact that we only use one bulk velocity to describe each fluid. For example, two counter-streaming plasma beams have average velocity 0 under the fluid descriptions, neglecting the fact that particles can turn due to collision or other types of interactions.\nThe counter-intuitive fact about collisions in plasma: the more particles we have within the Debye cube, the less collisional the plasma is. Collisions in plasma usually happens in Coulomb interactions. Remember what’s special about plasma is its collective behavior, and the Debye length is the physical length scale at which quasi-neutral charge particles can be considered as a whole that effectively shielded far-distance Coulomb interactions. From the perspective of one particle, the more charged particles I have around me, the more neutrality it is and then it would be easier for me to move freely in space.\nIn fluid descriptions, if you set up a pulse which has all sorts of wave lengths in it, as it propagates, all wave lengths travels at the same speed. On the contrary, if you turn to kinetic descriptions, you can both get physical and numerical dispersions, which essentially means that different waves travel at different speeds, and you will see wiggles behind the initial pulse because the short wave lengths do not travel as fast as the long wave lengths."
  },
  {
    "objectID": "posts/pic/index.html#caveats-in-understanding-pic",
    "href": "posts/pic/index.html#caveats-in-understanding-pic",
    "title": "Kinetic Plasma Simulations",
    "section": "Caveats in Understanding PIC",
    "text": "Caveats in Understanding PIC\n\nIt is not correct to think macro particles as real particles. Otherwise you will fall into some niche corners: for example, what will happen if relativistic effects are taken into account? The faster the particle moves, the smaller its mass is? The proper way to think of macro particles is that it is a way of sampling the velocity space distributions at a given (x,y,z,vx,vy,vz) locations. Remember macro particles are not treated as delta-distributed in space: it has a finite shape function within a distance, which is equivalent to a group of particles with the same velocity distributed within a small spatial location. The key benefit in doing this is to avoid the strong short-distance Coulomb interaction (e.g. no large angle scattering) between point particles while maintain the long-distance Coulomb interaction between groups of particles as a whole, or in other words, more plasma-like.\nA more mathematical description of the interaction between the grid and the macro particles involves the words scatter and gather:\n\na scatter operation deposit particle charge on mesh\na gather operation interpolate fields to particle position and compute the force\nmomentum conservation requires that the scatter and gather operation are symmetric, so most of the time we use the same interpolation scheme for these two operations.\n\nThe biggest contraint on the leap-frog scheme is that the discrete time step is limited by the electron plasma frequency \\(\\omega_p\\):\n\nif \\(\\omega_p \\Delta t \\le 2\\), the scheme is stable, but suffers from phase error;\nif \\(\\omega_p \\Delta t \\le 2\\), there will be an anti-damping component (i.e. negative imaginary part following the usually sinuisoidal perturbation expression) in the frequency which makes the scheme unstable.\n\nBe careful in evaluating the implicit time-stepping versus explicit time-stepping. A numerical solver, no matter how elegant it is, should not over-shadow the original equation. Simplicity and understandability are more important than performance.\nNoise: low-order interpolation creates spikes and in turn shows up as noise in the electric field.\nFiltering of shape functions: the more “compact” the shape function is, the more higher k (short wave length) power it has. The convolution of two shape functions is equivalent to the multiplication of their Fourier transforms. Therefore the smoothing of real space shape functions acts as smoothing in the frequency space.\n\nThis is important because the discretization step introduces a correction term to the actual wave numbers and it acts to dampen the high k modes. If not damped, these high frequency wave modes will not disappear; instead, they show up as aliased low frequency modes on your discretized grid which has nothing to do with real physics! This usually leads to extra heating in the system; in worse situations, it may even distablize the system!\nIf Debye length is not resolved on the grid, aliasing will heat up the plasma until Debye length is resolved. This is known as numerical heating.\n\nAn alternative way is to increase the number of macro particles: the spikes of low order interpolation will get averaged out. However, the problem in doing this is that the ratio of the mean amplitudes of the fluctuations to the slowly varying component varies as \\(\\frac{1}{\\sqrt{n}}\\), and the effect of these fluctuations is greatly enhanced because our numerical model typically uses far fewer particles than are present in reality.\nDecentering is the key in many numerical schemes, e.g. leap-frog, constraint transport, divergence-free Yee grid. In terms of Yee grid, this dual mesh like discretization is very natural when you perform the integral of curvature calculations of the EM field.\nWhen solving the conversation equations especially the mass conservation equation, numerial dispersion is bad because when you get negative density you get stuck, but it is kind of alright for a EM field solver because negative electric field is still fine.\nNature is hyperbolic but not elliptic. The Poisson equation, which is elliptic, acts as a constraint from the charge conservation. You can of course solve the Poisson equation directly (typically using FFT method), but that requires information from all over the domain. The nature does not need to know Poisson equation to evolve the charge and currents: conservation law comes in the first place! Parallelization, localization, whatever you call it—I don’t need to call my mum 5000 km away everytime I want to make soup.\n\nThere are schemes which carefully calculate the charge depositions and thus guarantee charge conservation. However, high order (&gt;1) charge deposition schemes are ~ 25 times more expensive than 1st order?\nMost PIC codes don’t solve for Poisson equation: they assume charge conservation is valid throughout the time advance as long as the initial condition is charge conserved.1 There are two reasons behind this: 1. we assume this error is small that it does not affect the solution drastically; 2. Poisson solver is usually the most expensive part if included. If in the problem we are dealing with we do need to satisfy Poisson equation, in practice we do corrections every few time steps to as a trade-off.\n\n\n\nWhat happens if we start with charge imbalance? For example, let’s say we only initialize electrons in the domain and forget about ions. To satisfy Poisson’s equation, the simplest solution would be zero electric fields. This means that the code thinks there is an opposite and equal charge density ion species to my initialized electrons. When electrons start moving, ions will sit on the grid. This is an easy way to simulate infinite mass of ions.\nHigh order FDTD schemes (4th spatial order) work better at reducing unphysical Cherenkov instability. Cherenkov instability relates to the dispersion error caused by the leap-frog scheme. Especially for relativistic particles, the dispersion error may create particles that travel faster than the speed of light in the medium (although still less than the speed of light in vacuum), which then becomes the recipe for the Cherenkov radiation. It’s similar to the sonic boom of a supersonic aircraft. Anatoly called this the “pedestrian” version because a strict analysis of the numerical Cherenkov instability also involves interaction with plasma modes, and the math quickly becomes “ugly”.\nvPIC is known for its speed. Why can it achieve it and why doesn’t all PIC codes follow? This is the art of balance, or trade-off: vPIC chooses to use the simplest schemes whenever possible and hope that all the statistical noises will be suppressed with enough number of macro particles per cell. As a comparison, the validity of a solution may be kept with 4 particles per cell with high order schemes and corrections, while vPIC may require 100 particles per cell; if vPIC is 25 times faster, then the final result is equivalent. However, one disadvantage I can think of about vPIC is that it then may require more memory/storage, which puts pressure on the hardwares.\nThe asymptotic behavior of applying stencil filters N times is the multiplication of cosine functions. To think it in an easy way, cos(0) = 1 which gives the center value of the stencil (i.e. original value), and as this angle goes to \\(\\pm 90^\\circ\\), the weight factor goes to 0. Of course we can have negative factor values as well.\nBoundaries\n\nPeriodic: I am thinking if the periodic vectors in Julia can be easily used in our kernel codes without introducing ghost cells? Is it general enough to be compatible with other boundaries?\nPerfectly conducting walls: tangential E –&gt; 0, perpendicular B –&gt; 0 (w.r.t. the wall boundary). A common problem arises in simulating a circle/sphere boundary in a Cartesian grid, where this stair-like inner boundary appears. By smoothing the electric field at the boundaries, which means that instead of strictly setting the transverse electric field to 0, we switch to kill part of it and hope it help smooth out the transition.\nOpen boundary: absorbing layer, perfectly matched layer (PML), transmitting wall. The idea of PML is to add a diffusive term to the Maxwell’s equations, which you say that there is region on the grid with finite conductivity, which in turn damps out the field. This works like absorbing material with different conductivity for E and B fields. Another approach is the transmitting wall. This works well if the wave propagation direction is normal to the wall (i.e. no oblique waves), which is usually true if the wall is far away from the source. This is pretty cheap compared to PML.\nMoving window, or a shift in the frame of reference, is sometimes used in beam and shock simulation. The simulation box is assumed to fly at the speed of light to follow a fast beam.\nInjection of particles: we can have moving injectors, for example, in shock simulations.\n\nFor PIC codes, usually parallel domain decomposition is not an issue, but load balancing is. For the typically case Anatoly showed, 90% of the time is spent with particles, and 10% of the time is spent with fields. The larger density gradients you have in your problem, the more severe the load balancing issue is. Shock and reconnection, the two main problems space physics studies, unfortunately fall into this regime.\nEmission of non-thermal radiation: most often the frequency of the energetic radiation is not resolved by the grid. If we care about radiation, we need to add photons as a separate species, and for example the radiation reaction force as an additional term in the equation of motion for pulsar simulations, or a force term for the inverse Compton scattering.\nThe laser-plasma field is adding extra physics for high-intensity laser that will reach a fraction of the critical field when QED effects and pair creation become important.\nFor black hole magnetospheres and pulsars, we need to consider general relativistic effects with non-Euclidian metrics.\nStreaming instabilities, like Weibel instability, can be important at collisionless shocks.\n\n\nCaution is required, but one can be paralyzed by a conservative attitude into missing profitable applications. — Birdsall & Langdon (1991)"
  },
  {
    "objectID": "posts/pic/index.html#a-few-words-about-hybrid-pic",
    "href": "posts/pic/index.html#a-few-words-about-hybrid-pic",
    "title": "Kinetic Plasma Simulations",
    "section": "A Few Words About Hybrid PIC",
    "text": "A Few Words About Hybrid PIC\n\nAn important limitation of full PIC methods is the limited separation of scales. Only microscopic systems can be modelled. In particular, it’s hard to model electron/ions plasmas with realistic mass ratio, since \\(\\omega_p \\propto 1/\\sqrt{m}\\), the real ratio will give a ~43 times difference. Hence ion acceleration is hard to capture with PIC (except in the ultra-relativistic limit).\nHybrid codes treat ions as macro-particles and electrons as massless neutralizing fluid (methods works for non-relativistic plasmas), which means that in the electron momentum equation, we assume the electron inertia term \\(n_e m_e\\frac{d\\mathbf{V}_e}{dt}\\) is 0, and the generalized Ohm’s law can be derived based on this. Note again that in this simplified model electric field is now a state quantity that is determined by ion density, velocity, magnetic field, and electron pressure gradient.\n\nHybrid model is not accurate at the shock. The closure of the electron pressure term usually assume some kind of equation of state, which involves a constant polytropic index \\(\\gamma\\) in \\(P \\propto n^\\gamma\\). The most common assumption is an adiabatic system, which is not true across the shock.\nIons are pushed at least twice in each timestep due to the requirement of proper centering in time for the EM fields. The numerical scheme looks a bit convolved because electric field and magnetic field are defined at staggered time stamps, but you need a future electric field to get a future magnetic field.\nAn interesting side effects is in the wave dispersion for whistler mode: \\(\\omega \\propto k^2\\), so as you refine the grid more and more (i.e larger and larger k), the whistler goes faster and faster in an unbounded manner! In real physics, the whistler is bounded by electrons; since we don’t have real electrons in a hybrid system, we cannot stop its growth. Therefore in practice we need to filter out the high spatial-frequency waves to make the code stable and hopefully lead to convergence. This is usually achieved by filtering the currents, but not fields. Anatoly said that’s because it’s much easier to maintain charge conservation when manipulating the currents. This also explains why in the older iPIC3D model filtering/smoothing the electric field does not end up doing anything better. However, if your scheme maintains charge conservation while filtering the fields, you should be fine.\n\n我觉得混合模拟中的这套逻辑非常奇特。等离子体本来是一个整体，电子离子和电磁场共同作用形成一个体系。然而这里面的关系却是不对等的：粒子离开了电磁场就会变成杂乱无章的个体，但电磁场忽视一两个粒子对整个体系一点影响也没有。如果把离子比作中产阶级，把电子比作底层阶级，电磁场比作政府，那么混合模拟就好比我们只关心社会大尺度包括的问题，而仅把底层民众的声音当作一个背景声音，简化个体意志的影响。然而神奇的是，底层民众的行动依旧会被电磁场牢牢把持，甚至可以通过仅仅观察底层人民受影响的程度来映射整个政府的运作，而无需考虑中产阶级。我又想起了Y.Y课上做的社会比喻，那是一个起点，但整个模型的复杂程度可与描述社会相当。"
  },
  {
    "objectID": "posts/pic/index.html#footnotes",
    "href": "posts/pic/index.html#footnotes",
    "title": "Kinetic Plasma Simulations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAfter years of fighting with numerical artifacts, Yuxi and Gábor came up with a Poisson equation correction to the semi-implicit PIC solver in FLEKS.↩︎"
  },
  {
    "objectID": "posts/haskell/index.html",
    "href": "posts/haskell/index.html",
    "title": "Haskell",
    "section": "",
    "text": "那天无意中发现Qusai练手写了一点的Haskell，想着这小子也挺与时俱进的嘛，终于不再整天抱着那Python了。但想想看我对于Haskell的了解也就停留在知道这是一门纯粹的函数式编程语言，觉得不行，还是得多了解一点，于是翻开了Haskell的维基，从最基础的开始学起。看完初级篇，觉得该教程写得非常出色。对于没有编程基础但是懂数学的人，我相信他们也能理解；对于我这种有点编程基础的人，它很快地能把你从主流的语言的使用习惯引导至Haskell独特的编程体系中。函数式编程的核心，是用类似迭代的写法代替循环。途中看着看着，觉得很多部分在Julia中也有类似的使用方法，于是就去查了一下Julia的维基，但并没有看见Julia借鉴了Haskell。这说明它们的这些特点都是学习自更古老的语言，比如Scheme，Lisp。\n切莫唯一门语言独尊。有偏向和选择是好的，出发点是目的，而不是为了技术而技术。\n我了解的用Haskell编写的最出名的软件是Pandoc，是一个Berkley哲学系的教授的作品。"
  },
  {
    "objectID": "posts/refactor/index.html",
    "href": "posts/refactor/index.html",
    "title": "Refactoring",
    "section": "",
    "text": "所谓refactoring，指的是在不改变程序外部功能的情况下对内部结构进行优化调整，\n逐渐我也开始遇到这类问题，希望借鉴一些历史经验。有一本书《Refactoring: Improving the Design of Existing Code》，作者是Martin Fowler和Kent Beck，最早出版于1999年1。整理一些笔记于此。\n时刻记得Donald Knuth的话：\n在诸多程序中，我们能看到冗杂、混乱的逻辑和实现。是的，的确对一些当前的情况能跑，但是一碰就碎，一改就错。常见的例子：\nWhat is it that makes programs hard to work with?"
  },
  {
    "objectID": "posts/refactor/index.html#steps-in-refactoring",
    "href": "posts/refactor/index.html#steps-in-refactoring",
    "title": "Refactoring",
    "section": "Steps in refactoring",
    "text": "Steps in refactoring\n\nBuilding tests.\nChanging the program in small steps, so it’s easy to trace bugs. Follow the rhythm: test, small change, test, small change…\nNever be afraid to rename things for clarity, especially internally2.\n\nMost refactorings reduce the amount of code. If you happen to have one which increases it, think twice.\nQuoted from Don Roberts &gt; The first time you do something, you just do it. The second time you do something similar, you wince at the duplication, but you do the duplicate thing anyway. The third time you do something similar, you refactor. &gt; Three strikes and you refactor.\nWhen do you need to refactor:\n\nwhen adding a function;\nwhen fixing a bug;\nwhen reviewing codes.\n\nWhat you need to achieve with refactoring:\n\nTo enable sharing of logic.\nTo explain intention and implementation separately.\nTo isolate change.\n\nI use an object in two different places. I want to change the behavior in one of the two cases. If I change the object, I risk changing both. So I first make a subclass and refer to it in the case that is changing. Now I can modify the subclass without risking an inadvertent change to the other case.\n\nTo encode conditional logic.\n\nPolymorphism\nDispatch\n\n\n\nSpecial Attention to Classes and Objects\n\n如果一项功能需要基于一个外来类的特性的判断，那很可能这个部分最好放在这个类自己的方法之中。\n有时候判断分支可以用polymorphism来替代。或者in a Julian way, multiple-dispatch，基于变量类型的由编译器决定的函数调用，而不是程序员手写的分支。\n\n\n\nChanging Interfaces\nIf a refactoring changes a published interface, you have to retain both the old interface and the new one, at least until your users have had a chance to react to the change. Fortunately, this is not too awkward. You can usually arrange things so that the old interface still works. Try to do this so that the old interface calls the new interface. In this way when you change the name of a method, keep the old one, and just let it call the new one. Don’t copy the method body—that leads you down the path to damnation by way of duplicated code. You should also use the deprecation facility in your programming language to mark the code as deprecated. That way your callers will know that something is up.\n\n\nWhen Shouldn’t You Refactor?\nThere are times when you should not refactor at all. The principle example is when you should rewrite from scratch instead. There are times when the existing code is such a mess that although you could refactor it, it would be easier to start from the beginning. This decision is not an easy one to make, and there are no good guidelines for it.\nAnalysator就是一个很好的例子。\n\n\nPerformance\nKeep performance in mind, but as a general rule, cleaner code provides more space for optimization. Performance optimization often makes code harder to understand, but you need to do it to get the performance you need.\nThe interesting thing about performance is that if you analyze most programs, you find that they waste most of their time in a small fraction of the code. If you optimize all the code equally, you end up with 90 percent of the optimizations wasted, because you are optimizing code that isn’t run much. The time spent making the program fast, the time lost because of lack of clarity, is all wasted time.\nOne live example quoted from the book: &gt; Our biggest improvement was to run the program in multiple threads on a multiprocessor machine. The system wasn’t designed with threads in mind, but because it was so well factored, it took us only three days to run in multiple threads.\n回想我为BATSRUS加多线程的经历，以及后续GPU代码的开发，真是感同身受。\n\n\nBad Smells in Code\n\nDuplication\n\n我自己最常干这种事情是在写画图脚本的时候。当你一次性想画多张图的时候，你会很容易先画一个，然后复制粘贴改个变量名就弄出多个。然而事后你会发现这种做法是多么不利于代码的反复利用和阅读。引以为戒。\n\nLong method\nLarge class\nLong parameter list\nData clump: bunches of data that hang around together really ought to be made into their own object\nSwitch statements: alert when you see the same switch statement scattered about a program in multiple places.\n\n我自己见过，也写过很多这样的例子。在实际操作中并非你一开始想象得那么简单：比如你最早写了一个绘图函数可以画等高线。后来你想扩展这个函数，可以改坐标单位。然而这个x、y轴的数据多处被用到，每一处用到的地方你都需要加一个有关单位的判断；然而按照原始的逻辑，把这些判断后的东西写在一起可能就比较奇怪。又比如Bart实现solid body的方法，非常的hacking，就是一个变量在原本算法逻辑中反复判断：这一步该不该打开，下一步该不该关上……最后的成品就是由无数个重复判断叠加在一起，对不对全看写的时候脑子清不清楚。\n\nComments: many are misused as deodorant. It’s surprising how often you look at thickly commented code and notice that the comments are there because the code is bad.\n\n最近的一个例子，Vlasiator中fix initial and boundary velocity block counts不一样的问题。之所以需要一大段注释，是因为代码本身逻辑混乱。\nA good time to use a comment is when you don’t know what to do, but not explain why you do poorly.\n\n\nHere is a live example in Python 3.9 for bad smell in code: \nRemember to always keep the code simple and self-descriptive, such that no extra explanatory comments are needed if possible."
  },
  {
    "objectID": "posts/refactor/index.html#mindset",
    "href": "posts/refactor/index.html#mindset",
    "title": "Refactoring",
    "section": "Mindset",
    "text": "Mindset\nSometimes, refactoring is more about soft skills and decision making. I watched this interesting video\n\n\nwhile thinking more about my experience in real working environment. Select who to work with may be more important than the work itself."
  },
  {
    "objectID": "posts/refactor/index.html#footnotes",
    "href": "posts/refactor/index.html#footnotes",
    "title": "Refactoring",
    "section": "Footnotes",
    "text": "Footnotes\n\n\npossible working link here↩︎\n对于某些冥顽不化抱残守缺的码农，祝你好运。哦对了，Analysator至今的调用方式还是import pytools:sweat_smile:↩︎"
  },
  {
    "objectID": "posts/paraview/index.html",
    "href": "posts/paraview/index.html",
    "title": "Paraview Usage Notes",
    "section": "",
    "text": "Paraview is a powerful tool for visualization and postprocessing, but it requires some effort to get familiar with it. The learning curve suddenly becomes steep at some point."
  },
  {
    "objectID": "posts/paraview/index.html#common-issues",
    "href": "posts/paraview/index.html#common-issues",
    "title": "Paraview Usage Notes",
    "section": "Common Issues",
    "text": "Common Issues\n\nReader\n\nFilename does not support ~\nThe data are not actually read until you call Render() or UpdatePipeline()\n\nClip and Slice Clip is for volume while slice is only for surface\nUnderstanding Stream Tracer\nFrom the official document: &gt;Stream Tracer filter generates streamlines in a vector field from a collection of seed points. Production of streamlines terminates if: &gt;* a streamline crosses the exterior boundary of the input dataset (ReasonForTermination=1) &gt;* an initialization issue (ReasonForTermination=2) &gt;* computing an unexpected value (ReasonForTermination=3) &gt;* reached the Maximum Streamline Length input value (ReasonForTermination=4) &gt;* reached the Maximum Steps input value (ReasonForTermination=5) &gt;* velocity was lower than the Terminal Speed input value (ReasonForTermination=6).\n&gt;This filter operates on any type of dataset, provided it has point-centered vectors. The output is polygonal data containing polylines.\nMostly I don’t need to compute vorticity, even though it is available. Surface streamline is available.\nThe cell data attribute for streamlines displays the streamlines as Poly-Line, with forward and backward integration separately.\nBad X server connection\nAs quoted from the discourse: &gt; An X server is required for all ParaView packages except the osmesa package, even if offscreen rendering is used and no window is opened. This is because most OpenGL applications on linux still depend on X to draw anything, even if no window appears.\nOn Frontera, simply by module load swr qt5 ospray paraview won’t work, because the default paraview module requires X server. Kitware provides a headless version with no dependency on the X server named osmema, and that’s the right one to load.\nContour plot for vector components\nBy default in edit/settings, under the data processing options, the Auto conversion properties is off. Turn this on to allow the contour filter to be used for vector objects."
  },
  {
    "objectID": "posts/paraview/index.html#unsolved-issues",
    "href": "posts/paraview/index.html#unsolved-issues",
    "title": "Paraview Usage Notes",
    "section": "Unsolved Issues",
    "text": "Unsolved Issues\n\nWhy can’t I do stream tracing on the original unstructured data? Currently I can only use the stream tracer filter for the clipped data.\nGet field topology from stream tracing\nSurface contour for the AMReX distributed data with no ghost cell information. As a comparison, VisIt does not have this issue.\nUser-defined file format reader. In principle we shall be able to write either C++ or Python reader, but there has not been such a thing as a clear tutorial. For these kind of tasks, it is almost impossible to make it smooth without asking a user’s feedback. (This is probably one of the reasons why IKEA’s furniture installation instructions are so good!) A tool exists for porting a VisIt plugin to ParaView. Maybe I should try to make it work for the Vlasiator output format."
  },
  {
    "objectID": "posts/paraview/index.html#comparing-with-tecplot",
    "href": "posts/paraview/index.html#comparing-with-tecplot",
    "title": "Paraview Usage Notes",
    "section": "Comparing with Tecplot",
    "text": "Comparing with Tecplot\nI have no doubt that Tecplot is a good software, but I gradually shifted towards ParaView because it’s open source and free. Same things happen in many different fields: a paid software would lose users to its free competitors if the latter becomes powerful enough. Honestly ParaView is still buggy and unstable compared to Tecplot, but one shining feature of ParaView is that it is built upon a very good open source file format VTK and it supports a wide range of different formats. Tecplot, from my personal experience, is way behind in this category. Service and maintainence can earn you money, but not the code itself. Look at the boosting Python community.\nAs a side note, if I were to start writing a new model, I will not design my own file format. The better way is to be compatible with one of the existing mainstream format for saving effort in data processing."
  },
  {
    "objectID": "posts/paraview/index.html#comparing-with-visit",
    "href": "posts/paraview/index.html#comparing-with-visit",
    "title": "Paraview Usage Notes",
    "section": "Comparing with VisIt",
    "text": "Comparing with VisIt\nVisIt is another big project based upon VTK. My feeling is that in all circumstances, the GUI part feel old fashioned. Is it a curse developed by research institutes only?"
  },
  {
    "objectID": "posts/paraview/index.html#vtk-library",
    "href": "posts/paraview/index.html#vtk-library",
    "title": "Paraview Usage Notes",
    "section": "VTK Library",
    "text": "VTK Library\nRead the VTK textbook\nI found a library binding called PyVista. I want to develop a Julia version of it."
  },
  {
    "objectID": "posts/streamline/index.html",
    "href": "posts/streamline/index.html",
    "title": "Plotting of Streamlines",
    "section": "",
    "text": "The built-in streamline function of Matplotlib/MATLAB is not proper for scientifically visualizing field information. 一开始在MATLAB上开发VisAna的时候，记得Gabor就在说怎么这个磁力线莫名其妙地断了，旁边贾老师说这是MATLAB画图导致的问题，不是我程序写错了。后来转战Julia，改用Matplotlib，这个问题不但没有解决，还变得愈演愈烈。\n问题的表现有几点：\n\nThe only control parameter for streamlines are density, which indicates that there are algorithms behind the scene to select and remove extra lines in a dense region.\nTherefore there are lines ending for no physical reason, which is not suitable for scientifically interpreting the field data.\n\nTake a look at the official streamline plots: \nThis is definitely what you expect. I noticed that there is a minlength argument described in streamplot. Maybe give that a try?\nThe solution turns out to be doing tracing alone. In SpacePy, there’s a standalone C code for tracing one line at a time and output the point data. Initially I copied the C code, compiled it into a dynamic library, and then call the function directly from Julia. Next I incorporate the function into the plotting function I have and use it instead of the original streamplot in Matplotlib.\nMaybe in Matplotlib 3.6, we can get a new keyword that provides continuous streamlines.\n\n2D stream tracing is not that hard. Essentially this is just solving ODEs with the chosen numerical schemes. Let’s start with a fixed stepsize and move on to an adaptive stepsize (which is what’s being used in BATSRUS). More complicated stuffs include tracing in 3D general mesh. Work in progress.\nOne example in Python is given in this post. Essentially it is solving ODEs and connect points into lines. At each step in the discretized equation, a interpolation function is provided to calculate the vector field direction at a given point.\nI have built a small package FieldTracer.jl for tracing streamlines and fieldlines in 2D and 3D. It is now almost feature complete. One specific reason I need this is to select fixed seeds for animations, such that there won’t be sudden jumps of field lines between frames.\nUpdate: After Matplotlib 3.8, there is a new keyword in streamplot which controls whether the streamlines should be broken or not."
  },
  {
    "objectID": "posts/dc/index.html",
    "href": "posts/dc/index.html",
    "title": "DC 三番记",
    "section": "",
    "text": "第三次来华盛顿了，一开始找路的时候才发现，还是不够了解这座城市。下了地铁找个路南北都能弄反，回忆了半天愣是没想起来曾经住过的宾馆在哪里。直到重新绕着市中心转了一圈，在中国城里曾经吃过的馆子再来一遍，才让过往的记忆浮出水面，重焕光彩。最终才发现，现在住的Marriot，离曾经的Renaissance，不过一百米的距离。我见识过的财政部、国防部、白宫、华盛顿纪念碑、林肯纪念堂、美国历史博物馆、国家自然历史博物馆、奥巴马喜欢的Shake Shack 快餐店……隐藏的记忆里的老地方，需要一点点被唤醒。\n\n忆往昔\n上次来这里，误打误撞地找上瑞典驻美国领事馆，在华盛顿港附近徘徊了两个小时，虽然险些误了正事，但也算见识到了河岸边的绮丽风景。在出租车上赶路又恰巧看见了绝美的丛林风景，同非洲兄弟的一席聊天也道出了生活的不定和机遇。之后在国会山和中央车站间闲逛了一个下午，连着之前一家人在美国国庆逛过的地方，算是把整条中轴线补了个全。论壮观程度，美国的首府真不算什么；但这里反映出的国家精神和人民意志，却是全世界其他国家需要借鉴和学习的。\n\n\n看而今\n这次来开AGU年会，完全本着轻松愉悦的心态。虽然文章依旧没有发出来，但是我更淡定了，更从容了，更明白自己在意的是什么了。华盛顿是个我熟悉又陌生的城市，也是期待着这些天的美妙际遇：曾经的老师们还在不在，同学们过得好不好，睿智的姑娘们会不会经过我的身旁？\n第二次参观空间博物馆，看得比第一次稍微细致了些。平常周日的早上，人不多，可以慢慢品味。海军展览室里有完整的航空母舰模型，耗时11年打造，精细程度令人叹为观止。荧幕上展示的则是核心的喷气式起飞辅助装置，也是航母的核心技术之一。我看到的视频里有三条航道，每一条的发射时间大约间隔数分钟，所以估计下来平均一分钟能发射一架战斗机。我印象中还有更先进的电磁式辅助装置，能做到20秒发射一架，但可惜没能在展览中见识到。在二楼大厅的另一侧大屏幕上循环播放的则是发现者号最后一次发射的最后三分钟，你能看到人类迄今为止在航天发射上的最高成就，正如指令词中所说的，“the tribute of hard work and pride of the space team”. 我更感兴趣的展馆则被放在了二层中央，展示的是人类对于太阳系的探索。水金地火木土天海冥，每一个都是独特的存在，每一个都存在未解的谜团。而我每次看到类似的展出，也能收获一些此前不了解的知识，毕竟学海无涯。木星的磁层扰动冠绝太阳系，而且信号的长短分明，指引着截然不同的物理现象；海王星肉眼观察呈现的湛蓝色，是由于甲烷的存在；大行星的卫星越小越呈现出不规则的形状，甚至于近乎扁平的椭球体……联系之前才补充了一遍的潮水涨落和月球形状稳定性的定性解释，是不是觉得真正的知识都是相通的？\n然而，总有不尽如人意的地方。误丢钱包一事，那群黑人安保人员的态度，让我异常愤怒。进门安检时，我把大衣和口袋里的钱包手机房卡放在了一起，收起来的时候钱包被卷入了大衣的帽子里却浑然不知。当我逛了近二十分钟发觉了一个很有意思的涡轮发动机想拍照时，才下意识地惊觉钱包不见了。第一反应当然是落在了安检处，于是我毫不犹豫地直接找了过去，却被几个黑人安保当作是没事儿找茬的人一般在哪儿冷嘲热讽。他们叫我去安保处，安保处的另外两个目光呆滞的黑人大叔更是一副要死不活的态度。那根本就不能叫失物招领处，那就是穷头陌路所。唯一态度比较好的是他们安保的头儿，能冷静的叫我再检查一遍随身的衣物，并告诉我他以往的经验。最后还是我自己找到的，脱下大衣翻了一遍，无意中看见了落在帽子里的黑色钱包。而那三个混蛋的安保，那句混账的“back off”，让我对美国的国民素质产生了切身的怀疑。都有耳闻过美国首府的乱，而一般提到美国治安之乱，往往都脱不开黑人数量之多。华盛顿的中心区便是如此，你能看见的酒店前台、星巴克服务员、博物馆安保，清一色全是黑人兄弟姐妹。我宁愿称之为断裂的美国文化，堂堂自诩世界第一大国，华府之下的国家博物馆安保也如此不堪。我并非指责所有的黑人群体，而恰恰相反，我指责更多的造成这一切的“纯种”美国人。黑人是美国种族歧视中被压迫的代表，他们的或过激或懒散的反应都是在夹缝般的生存空间中孕育出来的。在曼哈顿的小巷中迷路也有黑人大哥主动帮我指路，在华盛顿的酒店附近找门也有黑人小姐姐帮忙指引。当你看到一群如同僵尸般的黑人安保人员时，你不会埋怨某一个人——这是一个群体的代表。回到事件本身，我只是笃定钱包是在过安保的时候丢的，玻璃心的工作人员显然把这当成了我对他们的刁难，认为他们偷窃了我的钱包。不解决事情而选择上纲上线，人有时候就会有种种不理智的行为。\n还记得电影《水形物语》中的黑人清洁大妈吗？人可以生活得辛苦，但这不妨碍我们有良知和热心肠。\n又仔细逛了一次自然历史博物馆。哺乳动物三要素：hair, milk, earbone。人类不可思议的进化，脑容量突然增长的时间与气候变冷存在高度相关性。人类的祖先究竟是什么仍然是个谜。生物之间的基因相似度远高于想象：人与猿有98.5%；与猩猩有98%；与老鼠有90%；就连香蕉树，都有70%。而现今地球上任意两个人之间的基因相似度，则高达99.9%。究竟是什么成就了每个独一无二的个体？西非某个念不出名字的古老村落站在历史与现代的交汇点上何去何从，整个非洲大陆的现代化何去何从，都是巨大的问题。霸王龙骨架的复原、体重的估计、运动的方针、速度的估算，自然与科技的成就相映成辉。那毒蛇下颚处独特的突出骨架结构；那苍蝇蚊子蝴蝶的嘴部构造；那些巧夺天工的自然奇景……我喜欢这里。\n排队进场的时候，一位亚裔美国女士开起了随行的法国人的玩笑。排队示意谦让，被“嘲讽”为虚伪；先生问博物馆里能否饮酒，被数落脑子里全是酒精。法国最近国内不太平，又是恐怖分子杀人，又是全国性的游行，但依旧改不了法国人骨子的浪漫洒脱。我们区分人不应依据肤色人种，而应依据文化渊源。如此来看，即便未来的法国“黑化”，他骨子里仍然会是法国。\n\n\n杂谈闲侃\n英国人果然是走在世界平等的最前沿。跨性别的认知并不妨碍人们成为杰出的科研工作者。\n科学家的耻辱，就是Collison。 阿谀奉承，避而不答，问东答西，敷衍其辞。他根本没有做科学家的基本素质。\n午餐时跟偶遇的美国大叔聊天，是今天最有意思的事情。他已白发苍苍，约莫耳顺年纪，是Boulder的一位系统控制工程师，第一次来AGU，曾在Boeing待过，也做过大型的望远镜项目。我跟他聊我的见解体会，他会用委婉而礼貌的方式举出例子来反驳；我跟他聊人工智能技术，他也会拿出身边的例子相互印衬；我跟他聊中美技术和体制差别，他也会站在理智民众的立场上看待中国的技术崛起。我喜欢跟陌生人聊天，何况是如此的主动而温和的长者。\n普林斯顿的模拟组，有历史渊源，也有中流砥柱。说起来，Gabor不也是普林出来的嘛。百万行代码之上成就专家，我服。\n如果你没能用一个简单清晰的例子来讲述你要说的东西，就说明你还没有真的懂。——张首晟 人生要做一点大事，要追求从根本上解决问题的理论和彻底颠覆游戏规则的技术，而不是在旧框架里修修补补。\n张首晟用了一个圣诞假期搞明白的区块链，我又要用多久呢？显然我现在还是没有真正明白。\n看到一个对硬件线程和软件线程的类比，我觉得茅塞顿开。硬件线程好比泳道，软件线程好比泳者。当人决定要游到对岸去时，会首先选择/被分配一条泳道；如果前方存在障碍，那么他还可能切换泳道；如果是一个团队比赛，那么多位选手平行分配会使团队时间更少。\n孟醒师姐身上，带着中国古典女性的安静和典雅。同门师姐，我第一次见，便觉得世间竟有如此美好。安欣师兄，第二次见，微信头像写着洛伦兹公式，对各种波动如数家珍，非常厉害，非常欣赏。\n做出更好的可视化效果图，就要抛弃过时的传统。这次还听说有GPU渲染（render）的动画技术，用Paraview做的，非常有兴趣。\n大红袍味道相当不错，名不虚传。点菜的师傅很江湖很老道，最后的成品也不错，就是口重了些。\n彭烨和冠宁的暧昧举动，基本说明他们成了。虽然没有什么言语上的直接交流，但是通过肢体语言同样可以说明问题。彭烨是个文静的好姑娘。庞冠宁这个老混蛋，原来早就喜欢她了吧。一切皆不是无中生有：命中有时终须有，命里无时莫强求。\nTamas不知所云的演讲，不知道他自己是否真的弄明白了。但更关键的，是看到真正干事的人。杨晨师姐很厉害。\n第二次AGU，有了更多的收获。最主要的，就是认定了自己想做什么。我不懂的东西那么多，我不能把我的事情也那么多。但总有我明白的，真正掌握的，以及对于未知的鉴别力。吾之所向，一往无前：做出顶级的模拟，设计顶级的架构。\n会议结束的晚上，我竟然失眠了。脑海中盘旋了无数的想法，仿佛就要爬起来直接把它们变为现实，想法清醒得很，却奈何眼睛实在撑不住。开完会让我感到兴奋而不是疲惫，是一个好的征兆。\n回密歇根的航班，经历了人生中最刺激的气流颠簸。纵然我再知道现代民航客机的安全性，身体对于外界剧烈变化的反应是隐藏不住的。手心里冒的汗，椅子脚上蹬直的脚板，邻座美国妹子双手紧握双目合十的神态……肉眼可见的机翼的抖动，以及急速下坠时的失重感。由于异常的气流，飞机不得不在几分钟内从3500迈下降到2000迈，我们一行也算是用生命体验自然的扰动。我感到自己仿佛就是空间中的粒子，乘在介于波动和不稳定性的作用之中，随着曲线极速起伏。那跟任何的过山车都不能比：因为你不能预测接下来会发生什么，震荡何时消失，没有所谓的轨迹和终点。但稳下来后会涌出强烈的对比，平滑和激变间的界限竟然是这么分明，这么直观。我满脑子都是这些天看到的那一条条抖动的曲线：那一刻它们不是死的，而是活的。 真是有意思。在我对着笔记本正思考着如何处理电磁波的模拟时，一切突如其来。在晃动中我一把接住了滑落桌板的电脑，顺手塞进了书包，思忖着，可不要是我最后一次写Matlab。爱得深沉，最新敲的几行代码还没存呢，可不能就这样。\n终究是一个理性的、感性的、乐观的人。"
  },
  {
    "objectID": "posts/hair/index.html",
    "href": "posts/hair/index.html",
    "title": "染发剂",
    "section": "",
    "text": "老妈需要了解市场上的染发剂是否对人体有损伤。"
  },
  {
    "objectID": "posts/shared-library/index.html",
    "href": "posts/shared-library/index.html",
    "title": "Shared Library",
    "section": "",
    "text": "This is a collection of knowledge about shared/dynamic libraries.\nLibraries are an indispensable tool for any programmer. They are pre-existing code that is compiled and ready for you to use. Most larger software projects will contain several components, some of which you may find use for later on in some other project, or that you just want to separate out for organizational purposes. When you have a reusable or logically distinct set of functions, it is helpful to build a library from it so that you do not have to copy the source code into your current project and recompile it all the time - and so you can keep different modules of your program disjoint and change one without affecting others. Once it is been written and tested, you can safely reuse it over and over again, saving the time and hassle of building it into your project every time."
  },
  {
    "objectID": "posts/shared-library/index.html#pros-and-cons",
    "href": "posts/shared-library/index.html#pros-and-cons",
    "title": "Shared Library",
    "section": "Pros and Cons",
    "text": "Pros and Cons\nA dynamic library offers the following features: * The object modules are not bound into the executable file by the linker during the compile-link sequence; such binding is deferred until runtime. * A shared library module is bound into system memory when the first running program references it. If any subsequent running program references it, that reference is mapped to this first copy. * Maintaining programs is easier with dynamic libraries. Installing an updated dynamic library on a system immediately affects all the applications that use it without requiring relinking of the executable. * Smaller executable file\nDeferring binding of the library routines until execution time means that the size of the executable file is less than the equivalent executable calling a static version of the library; the executable file does not contain the binaries for the library routines.\n\nPossibly smaller process memory utilization\n\nWhen several processes using the library are active simultaneously, only one copy of the memory resides in memory and is shared by all processes.\n\nPossibly increased overhead\n\nAdditional processor time is needed to load and link-edit the library routines during runtime. Also, the library’s position-independent coding might execute more slowly than the relocatable coding in a static library.\n\nPossible overall system performance improvement\n\nReduced memory utilization due to library sharing should result in better overall system performance (reduced I/O access time from memory swapping).\nPerformance profiles among programs vary greatly from one to another. It is not always possible to determine or estimate in advance the performance improvement (or degradation) between dynamic versus static libraries. However, if both forms of a needed library are available to you, it would be worthwhile to evaluate the performance of your program with each."
  },
  {
    "objectID": "posts/shared-library/index.html#from-source-code-to-running-a-program",
    "href": "posts/shared-library/index.html#from-source-code-to-running-a-program",
    "title": "Shared Library",
    "section": "From Source Code to Running a Program",
    "text": "From Source Code to Running a Program\n\nC Preprocessor: This stage processes all the preprocessor directives. Basically, any line that starts with a #, such as #define and #include.\nCompilation Proper: Once the source file has been preprocessed, the result is then compiled. Since many people refer to the entire build process as compilation, this stage is often referred to as compilation proper. This stage turns a .c file into an .o (object) file.\nLinking: Here is where all of the object files and any libraries are linked together to make your final program. Note that for static libraries, the actual library is placed in your final program, while for shared libraries, only a reference to the library is placed inside. Now you have a complete program that is ready to run. You launch it from the shell, and the program is handed off to the loader.\nLoading: This stage happens when your program starts up. Your program is scanned for references to shared libraries. Any references found are resolved and the libraries are mapped into your program.\n\nSteps 3 and 4 are where the magic (and confusion) happens with shared libraries.\nNow, on to our (very simple) example.\nfoo.h:\n#ifndef foo_h__\n#define foo_h__\n \nextern void foo(void);\n\n#endif  // foo_h__\nfoo.c:\n#include &lt;stdio.h&gt;\n\nvoid foo(void)\n{\n    puts(\"Hello, I am a shared library\");\n}\nmain.c:\n#include &lt;stdio.h&gt;\n#include \"foo.h\"\n \nint main(void)\n{\n    puts(\"This is a shared library test...\");\n    foo();\n    return 0;\n}\nfoo.h defines the interface to our library, a single function, foo(). foo.c contains the implementation of that function, and main.c is a driver program that uses our library. Assume that for the purposes of this example, everything will happen in /home/username/foo.\n\nStep 1: Compiling with Position Independent Code\nWe need to compile our library source code into position-independent code (PIC)1:\n$ gcc -c -Wall -Werror -fpic foo.c\n\n\nStep 2: Creating a shared library from an object file\nNow we need to actually turn this object file into a shared library. We will call it libfoo.so:\n$ gcc -shared -o libfoo.so foo.o\n\n\nStep 3: Linking with a shared library\nAs you can see, that was actually pretty easy. We have a shared library. Let us compile our main.c and link it with libfoo. We will call our final program test. Note that the -lfoo option is not looking for foo.o, but libfoo.so. GCC assumes that all libraries start with lib and end with .so or .a (.so is for shared object or shared libraries, and .a is for archive, or statically linked libraries).\n$ gcc -Wall -o test main.c -lfoo\n/usr/bin/ld: cannot find -lfoo\ncollect2: ld returned 1 exit status\nTelling GCC where to find the shared library\nUh-oh! The linker does not know where to find libfoo. GCC has a list of places it looks by default, but our directory is not in that list.2 We need to tell GCC where to find libfoo.so. We will do that with the -L option. In this example, we will use the current directory, /home/username/foo:\n$ gcc -L/home/username/foo -Wall -o test main.c -lfoo\n\n\nStep 4: Making the library available at runtime\nGood, no errors. Now let us run our program:\n$ ./test\n./test: error while loading shared libraries: libfoo.so: cannot open shared object file: No such file or directory\nOr on Mac Mojave with gcc9 from another directory:\n$ ./ex1/test\ndyld: Library not loaded: libfoo.so\n  Referenced from: .../ex1/test\n  Reason: image not found\nAbort trap: 6\nOh no! The loader cannot find the shared library.3 We did not install it in a standard location, so we need to give the loader a little help. We have a couple of options: we can use the environment variable LD_LIBRARY_PATH for this, or rpath. Let us take a look first at LD_LIBRARY_PATH:\nUsing LD_LIBRARY_PATH\n$ echo $LD_LIBRARY_PATH\nThere is nothing in there. Let us fix that by prepending our working directory to the existing LD_LIBRARY_PATH:\n$ export LD_LIBRARY_PATH=/home/username/foo:$LD_LIBRARY_PATH\n$ ./test\nThis is a shared library test...\nHello, I am a shared library\nGood, it worked! LD_LIBRARY_PATH is great for quick tests and for systems on which you do not have admin privileges. As a downside, however, exporting the LD_LIBRARY_PATH variable means it may cause problems with other programs you run that also rely on LD_LIBRARY_PATH if you do not reset it to its previous state when you are done.\nUsing rpath\nNow let s try rpath (first we will clear LD_LIBRARY_PATH to ensure it is rpath that is finding our library). Rpath, or the run path, is a way of embedding the location of shared libraries in the executable itself, instead of relying on default locations or environment variables. We do this during the linking stage. Notice the lengthy -rpath=/home/username/foo option. The -Wl portion sends comma-separated options to the linker, so we tell it to send the -rpath option to the linker with our working directory.\n$ unset LD_LIBRARY_PATH\n$ gcc -L/home/username/foo -Wl,-rpath=/home/username/foo -Wall -o test main.c -lfoo\n$ ./test\nThis is a shared library test...\nHello, I am a shared library\nExcellent, it worked. The rpath method is great because each program gets to list its shared library locations independently, so there are no issues with different programs looking in the wrong paths like there were for LD_LIBRARY_PATH.\nrpath vs. LD_LIBRARY_PATH\nThere are a few downsides to rpath, however. First, it requires that shared libraries be installed in a fixed location so that all users of your program will have access to those libraries in those locations. That means less flexibility in system configuration. Second, if that library refers to a NFS mount or other network drive, you may experience undesirable delays - or worse - on program startup.\nUsing ldconfig to modify ld.so\nWhat if we want to install our library so everybody on the system can use it? For that, you will need admin privileges. You will need this for two reasons: first, to put the library in a standard location, probably /usr/lib or /usr/local/lib, which normal users do not have write access to. Second, you will need to modify the ld.so config file and cache. As root, do the following:\n$ cp /home/username/foo/libfoo.so /usr/lib\n$ chmod 0755 /usr/lib/libfoo.so\nNow the file is in a standard location, with correct permissions, readable by everybody. We need to tell the loader it is available for use, so let us update the cache:\n$ ldconfig\nThat should create a link to our shared library and update the cache so it is available for immediate use. Let us double check:\n$ ldconfig -p | grep foo\nlibfoo.so (libc6) =&gt; /usr/lib/libfoo.so\nNow our library is installed. Before we test it, we have to clean up a few things:\nClear our LD_LIBRARY_PATH once more, just in case:\n$ unset LD_LIBRARY_PATH\nRe-link our executable. Notice we do not need the -L option since our library is stored in a default location and we are not using the rpath option:\n$ gcc -Wall -o test main.c -lfoo\nLet us make sure we are using the /usr/lib instance of our library using ldd:\n$ ldd test | grep foo\nlibfoo.so =&gt; /usr/lib/libfoo.so (0x00a42000)\nGood, now let us run it:\n$ ./test\nThis is a shared library test...\nHello, I am a shared library\nThat about wraps it up. We have covered how to build a shared library, how to link with it, and how to resolve the most common loader issues with shared libraries - as well as the positives and negatives of different approaches."
  },
  {
    "objectID": "posts/shared-library/index.html#resources",
    "href": "posts/shared-library/index.html#resources",
    "title": "Shared Library",
    "section": "Resources",
    "text": "Resources\nShared libraries with GCC on Linux\nCreating dynamic libraries"
  },
  {
    "objectID": "posts/shared-library/index.html#footnotes",
    "href": "posts/shared-library/index.html#footnotes",
    "title": "Shared Library",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPosition Independent Code (PIC) is code that works no matter where in memory it is placed. Because several different programs can all use one instance of your shared library, the library cannot store things at fixed addresses, since the location of that library in memory will vary from program to program. In PIC, each reference to a global item is compiled as a reference through a pointer into a global offset table. Each function call is compiled in a relative addressing mode through a procedure linkage table. The size of the global offset table is limited to 8 Kbytes on SPARC processors. The -PIC compiler option is similar to -pic, but -PIC allows the global offset table to span the range of 32-bit addresses. Always try -pic first for smaller binary sizes; Use -PIC is you encountered an error.↩︎\nGCC first searches for libraries in /usr/local/lib, then in /usr/lib. Following that, it searches for libraries in the directories specified by the -L parameter, in the order specified on the command line.↩︎\nThe default GNU loader, ld.so, looks for libraries in the following order: 1. DT_RPATH section of the executable, unless there is a DT_RUNPATH section. 2. LD_LIBRARY_PATH. This is skipped if the executable is setuid/setgid for security reasons. 3. DT_RUNPATH section of the executable unless the setuid/setgid bits are set (for security reasons). 4. /etc/ld/so/cache (disabled with the -z nodeflib linker option). 5. default directories /lib then /usr/lib (disabled with the -z nodeflib linker option).↩︎"
  },
  {
    "objectID": "posts/experiment/index.html",
    "href": "posts/experiment/index.html",
    "title": "Experiment Design",
    "section": "",
    "text": "Any successful experiment requires careful design beforehand. There are systematic methods for ensuring the validity of test results."
  },
  {
    "objectID": "posts/experiment/index.html#control-groups",
    "href": "posts/experiment/index.html#control-groups",
    "title": "Experiment Design",
    "section": "Control Groups",
    "text": "Control Groups\nTo reduce variables in any type of experiment, it is recommended to include both positive and negative controls in the experimental design. Negative controls are particular samples included in the experiment that are treated the same as all the others but are not expected to change from any variable in the experiment. The positive control sample will show an expected result, helping the scientist understand that the experiment was performed properly."
  },
  {
    "objectID": "posts/experiment/index.html#statistics-significance",
    "href": "posts/experiment/index.html#statistics-significance",
    "title": "Experiment Design",
    "section": "Statistics Significance",
    "text": "Statistics Significance\nWe do not want standalone samples for proving the assumptions: in practice we would aim for increasing the number of samples to improve te statistical significance of our results."
  },
  {
    "objectID": "posts/figure/index.html",
    "href": "posts/figure/index.html",
    "title": "Figure Processing",
    "section": "",
    "text": "I have tried an excellent PNG file compressor online: TinyPNG. Usually this can compress a figure by about 60% without lossing visually detectable quality! This should always be used whenever possible.\nUnlike JPEG, PNG doesn’t typically have a lossy compression scheme. What TinyPNG can achieve is something I haven’t really found an alternative for. I made a donation of $5 to them. Great work!\n\nffmpeg has some built-in compressor when combining figures into movies, so it make less sense to compress each figure before passing them to ffmpeg.\nWhen merging images, the size reduction is lost for the combined image because 24-bit colors is the default settings for PNG savings. We need to optimize the image again.\n\nThis video explains many things about the differences between PNG and JPEG:\n\n\nSo basically, if you can count the number of colors in your image (e.g. most scientific plottings), use PNG. Even though PNG supports 24-bit colors, 8-bit (256 colors) is enough for most scientific images. This is the most important trick used in TinyPNG."
  },
  {
    "objectID": "posts/figure/index.html#image-compression",
    "href": "posts/figure/index.html#image-compression",
    "title": "Figure Processing",
    "section": "",
    "text": "I have tried an excellent PNG file compressor online: TinyPNG. Usually this can compress a figure by about 60% without lossing visually detectable quality! This should always be used whenever possible.\nUnlike JPEG, PNG doesn’t typically have a lossy compression scheme. What TinyPNG can achieve is something I haven’t really found an alternative for. I made a donation of $5 to them. Great work!\n\nffmpeg has some built-in compressor when combining figures into movies, so it make less sense to compress each figure before passing them to ffmpeg.\nWhen merging images, the size reduction is lost for the combined image because 24-bit colors is the default settings for PNG savings. We need to optimize the image again.\n\nThis video explains many things about the differences between PNG and JPEG:\n\n\nSo basically, if you can count the number of colors in your image (e.g. most scientific plottings), use PNG. Even though PNG supports 24-bit colors, 8-bit (256 colors) is enough for most scientific images. This is the most important trick used in TinyPNG."
  },
  {
    "objectID": "posts/figure/index.html#image-manipulation",
    "href": "posts/figure/index.html#image-manipulation",
    "title": "Figure Processing",
    "section": "Image Manipulation",
    "text": "Image Manipulation\nThere are many online image merging and splitting tools available. However, we can also process images by writing some codes in Julia! This can be easily achieved with Images.jl.\n\nBasics\nIn Julia, images as multidimensional arrays are stored in column-major order, which means that for an image with size size(img) = (512, 768), the first index corresponds to the vertical axis (column, height) and the second to the horizontal axis (row, width).\nTo use Images.jl, add using Images to the beginning of the script.\n\n\nCropping\nThe syntax is\nimg_source[y1:y2, x1:x2]\nFor example, to crop an image from sides by 1/8 of img_source each side and leave it as it is from top to bottom,\nimg_cropped = @view img_source[ :,floor(Int, 1/8*img_size[2]) : floor(Int, 7/8*img_size[2])]\n\n\nResizing\nResizing is a method to resize an image to a given specific output image shape.\nimg_square = imresize(img_source, (400, 400))\n\n\nRescaling\nRescale operation resizes an image by a given scaling factor. The scaling factor can either be a single floating point value, or multiple values - one along each axis. Image scaling is the process of changing the size of an image while preserving the original aspect ratio.\nimg_small = imresize(img_source, ratio=1/4);\nimg_short = imresize(img_source, ratio=(1/4, 1));\n\n\nMerging\n\nLayout: 1 on the left, 2 rows on the right\n\ndir = \"./\"\nima = load(dir*\"1a.png\")\nimb = load(dir*\"1b.png\")\nimc = load(dir*\"1c.png\")\nsa = size(ima)\nim_right = vcat(imb, imc) # 1b and 1c have the same sizes\nsright = size(im_right)\n\n# Resize the image\npercentage_scale = sa[1] / sright[1]\nnew_size = trunc.(Int, sright .* percentage_scale)\nim_right_rescaled = imresize(im_right, new_size)\n\nim = hcat(ima, im_right_rescaled)\nsave(\"1.png\", im)\n\nLayout: 2 rows * 2 columns\n\ndir = \"./\"\nima = load(dir*\"2a.png\")\nimb = load(dir*\"2b.png\")\nimc = load(dir*\"2c.png\")\nimd = load(dir*\"2d.png\")\nsa = size(ima)\nsc = size(imc)\n# Resize the bottom image\npercentage_scale = sa[2] / sc[2]\nnew_size = trunc.(Int, sc .* percentage_scale)\nim_rescaled = imresize(imc, new_size)\n\nim_left = vcat(ima, im_rescaled) # 1a and 1b have the same sizes\nim_rescaled = imresize(imd, new_size)\n\nim_right = vcat(imb, im_rescaled) # 1a and 1b have the same sizes\n\nim = hcat(im_left, im_right)\nsave(\"1.png\", im)"
  },
  {
    "objectID": "posts/video/index.html",
    "href": "posts/video/index.html",
    "title": "Making Videos from Figures",
    "section": "",
    "text": "An animation is simply frames of figures. It is pretty helpful to be proficient at generating a set of figures and combining them into a video. However, naively combining figures into animations ends up in huge files: for a 1920x1080 resolution video at a frame rate of 24, one minute takes 2460192010803 ~ 9 GB! Video files stored in computers take advantage of multiple compression techniques to reduce the storage requirements, including intra prediction (帧内预测), inter prediction (帧间预测), transform (转换), quantization (量化)，deblocking filter (去区块滤波器), entropy encoding (熵编码). These can be summarized into three main modules as described in H.265/HEVC:"
  },
  {
    "objectID": "posts/video/index.html#making-figures",
    "href": "posts/video/index.html#making-figures",
    "title": "Making Videos from Figures",
    "section": "Making Figures",
    "text": "Making Figures\nGuidelines in making figures from time-series data:\n\nReuse whatever possible. The figure canvas, axis, colorbar can often be reused. Instead of creating and deleting objects, think about the possibilty of modifying the properties of objects or replacing the data. Many practical examples can be found in Vlasiator.jl using Matplotlib."
  },
  {
    "objectID": "posts/video/index.html#concatenating-figures-into-videos",
    "href": "posts/video/index.html#concatenating-figures-into-videos",
    "title": "Making Videos from Figures",
    "section": "Concatenating Figures Into Videos",
    "text": "Concatenating Figures Into Videos\nI have encountered the task of combining figures into a video several times. In the early days, I used built-in MATLAB functions for concatenating figures into videos. There are some shortcomings with this method:\n\nIt requires a MATLAB license.\nThe simple brute force algorithm generates large video files, and you cannot control the output resolution.\n\nThen I tried the VideoIO package in Julia, but unfortunately, currently it lacks the support for VGBA encoding format.\nAfter searching more on the web, I found a neat solution to these kinds of task: ffmpeg. I installed it through Macports on Mac, but you can also download it directly from the website for installation on other platforms.\n\nUsing FFmpeg\nAlthough it seems easy to make videos from figures, it is actually not. You need to have some basic understandings of how figures are saved and how different video formats are structured. The best tool for video format conversion and filtering is FFmpeg. Here is a nice intro to FFmpeg in Chinese\n\n\nI have encountered several issues when using ffmpeg:\n\nImage size must be a multiple of 2.\n\nMy png files generated from Matplotlib have odd pixel numbers for both width and height.\nFrom one of the answers posted on StackOverFlow &gt;As required by x264, the “divisible by 2 for width and height” is needed for YUV 4:2:0 chroma subsampled outputs. 4:2:2 would need “divisible by 2 for width”, and 4:4:4 does not have these restrictions. However, most non-FFmpeg based players can only properly decode 4:2:0, so that is why you often see ffmpeg commands with the -pix_fmt yuv420p option when outputting H.264 video.\nThere is an option -2 in specifying the size. For example, &gt;-vf scale=1280:-2 Set width to 1280, and height will automatically be calculated to preserve the aspect ratio, and the height will be divisible by 2\n&gt;-vf scale=-2:720 Same as above, but with a declared height instead; leaving width to be dealt with by the filter.\n\nmovie that is generated by ffmpeg is not playable.\n\nFrom ffmpeg wiki: &gt;You may need to use -vf format=yuv420p (or the alias -pix_fmt yuv420p) for your output to work in QuickTime and most other players. Some players only support the YUV planar color space with 4:2:0 chroma subsampling for H.264 video. Otherwise, depending on your source, ffmpeg may output to a pixel format that may be incompatible with these players.\nUse -vf format=yuv420p or -pix_fmt yuv420p in the command line options.\n\nMissing frames from the input figure list.\n\nIf one of your figure file is corrupted (e.g. empty), ffmpeg will stop reading all the subsequent figures.\n\nOrder of files are messed up.\n\nThe best practice is to pad zeros such that all the file names have the same width.\n\nH.264 v.s H.265\nH.265 is superior in most cases, but it is not fully supported on all video players and platforms. Try to use H.265 if possible to save half the storage space compared with H.264.\n比起H.264/AVC，H.265/HEVC提供了更多不同的工具来降低码率，以编码单位来说，最小的8x8到最大的64x64。信息量不多的区域（颜色变化不明显，比如一张汽车图片中车体的红色部分和地面的灰色部分）划分的宏块较大，编码后的码字较少，而细节多的地方（比如轮胎）划分的宏块就相应的小和多一些，编码后的码字较多，这样就相当于对图像进行了有重点的编码，从而降低了整体的码率，编码效率就相应提高了。同时，H.265的帧内预测模式支持33种方向（H.264只支持8种），并且提供了更好的运动补偿处理和矢量预测方法。\n在相同的图像质量下，相比于H.264，通过H.265编码的视频码流大小比H.264减小约39%-44%。通过主观视觉测试得出的数据显示，在码率减少51%-74%的情况下，H.265编码视频的质量还能与H.264编码视频质量近似甚至比之更好。本质上，这代表着比预期的信噪比更好。\n\n\n\nTL;DR\nFinally, the following command works for converting figures into videos:1\nffmpeg -r 12 -pattern_type glob -i '*.png' -vcodec libx265 -vf scale=1080:-2 -pix_fmt yuv420p pi.mp4\nIf libx265 is not supported, you can revert back to libx264.\nTo transcode into H.265 using FFmpeg,\nffmpeg -i input.mp4 -map 0 -c copy -c:v libx265 output.mp4"
  },
  {
    "objectID": "posts/video/index.html#merging-videos",
    "href": "posts/video/index.html#merging-videos",
    "title": "Making Videos from Figures",
    "section": "Merging videos",
    "text": "Merging videos\nNote that this is different from concatenating frames in multiple videos. We have three convenient filters to use: vstack, hstack, and xstack.\n\nMerge two videos horizontally\n\nFrom this thread:\nffmpeg -i left.mp4 -i right.mp4 -filter_complex hstack -vcodec libx265 output.mp4\nBy default FFmpeg outputs H.265 encoded videos.\n\nMerge three videos horizontally\n\nffmpeg -i input0 -i input1 -i input2 -filter_complex \"[0:v][1:v][2:v]hstack=inputs=3[v]\" -map \"[v]\" -vcodec libx265 output\n[0:v] and [1:v] refer to the first and second video streams from the first and second inputs. The -map option determines which streams should be included in the output file.\nIf the videos do not have the same width or height, we need to first rescale the videos:\nTo rescale to a target height while keeping the same ratio and an even width pixel number:\nffmpeg -i input.mp4 -vcodec libx265 -vf scale=-2:1418 rescaled.mp4\nTo rescale to a target width while keeping the same ratio and an even height pixel number:\nffmpeg -i input.mp4 -vcodec libx265 -vf scale=726:-2 rescaled.mp4"
  },
  {
    "objectID": "posts/video/index.html#footnotes",
    "href": "posts/video/index.html#footnotes",
    "title": "Making Videos from Figures",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSince this command uses glob, it does not work on Windows.↩︎"
  },
  {
    "objectID": "posts/compiler/index.html",
    "href": "posts/compiler/index.html",
    "title": "Compilers",
    "section": "",
    "text": "Check the post How to Install GCC Compiler on Ubuntu."
  },
  {
    "objectID": "posts/compiler/index.html#installations",
    "href": "posts/compiler/index.html#installations",
    "title": "Compilers",
    "section": "",
    "text": "Check the post How to Install GCC Compiler on Ubuntu."
  },
  {
    "objectID": "posts/compiler/index.html#flags",
    "href": "posts/compiler/index.html#flags",
    "title": "Compilers",
    "section": "Flags",
    "text": "Flags\nAs programmers, we tend to be smarter than compilers. More often than not, we can’t. Nowadays, compilers comes with hundreds of flags to choose from. To make lives easier, compiler developers provide some neat flags for most common optimizations, namely -Ox series. I am not a fan of compiler flags, nor do I pretend that I can be smarter by compiling the code beyond the default compiler settings. Recently I have been testing Vlasiator on multiple platforms. I am shocked by the differences caused simply by GCC optimization flags. Here are a few things I have learned so far.\n\nStandard optimization flags are safer\n\nOn my Ubuntu laptop with GCC 7.5 (which is pretty old for sure), the results are consistent with standard -O0, -O1, -O2 and even -O3 flags. As promised, the default flags are guaranteed to work in most scenarios.\n\nBe cautious about -ffast-math\n\nIEEE standard is there for a reason. -ffast-math is a higher level flag which consists of multiple low level flags to speeds floating point operations up by loosening the IEEE restrictions. On one specific test, adding this flag gives me 10% speed boost at the cost of inconsistent results: 0.2% relative difference in plasma bulk speed values for one spatial cell running for 3600s simulation time.\n\nBe cautious about avx instructions\n\nIn my understanding, the avx series of instructions simply means vectorization of more operations in the cache. In the current Vlasiator Makefile, there is a -mavx flag together with specific vectorization class from an external C++ library.\nIn other recommended flag settings, many people mentioned the -march flag. For example, -march=native tried to detect the CPU architecture you are compiling on and add hardware-specific instructions, mostly avx-related flags, to your program.\nSurprisingly, this also affects the results quite significantly. Although the speed improved by 10% beyond pure -O3, the plasma bulk speed difference is also about 0.2%.\n\nBe careful about -Ofast\n\nOn top of the previous two observations, I need to be really careful about the most aggressive -Ofast flag, which includes -ffast-math."
  },
  {
    "objectID": "posts/compiler/index.html#vlasiator",
    "href": "posts/compiler/index.html#vlasiator",
    "title": "Compilers",
    "section": "Vlasiator",
    "text": "Vlasiator\nHowever, even if I turn off all the optimization flags, Vlasiator still shows different result on different platforms. This indicates that there are even more hidden facts underneath."
  },
  {
    "objectID": "posts/nbody/index.html",
    "href": "posts/nbody/index.html",
    "title": "N-Body Simulation",
    "section": "",
    "text": "N体问题是力学中的著名基础问题，当\\( N \\)时的解析解迄今依旧是个问题，仅在某些特殊情况下（比如其中若干个粒子/物体的质量相对极小）有解析解。 N体问题也是粒子模拟中的经典问题，分子动力学的入门例子就是一个势场中粒子的相互作用问题。\n昨日我在学校的图书馆闲逛，发现一本Molecular And Particle Modelling Of Laminar And Turbulent Flows, Donald Greenspan, 2005，实际上就是一本有关分子动力学的书，每章最后竟然还带了一些Fortran77的程序，引发了我的兴趣。于是我翻到了这本书的电子版，尝试着看看有没有可能把这些例子跑起来。\n结果呢，有点失望。Fortran77不愧是知名的科学黑料，当我浏览第一个例子时就有些头大：\n\n这里的循环全是用GOTO实现的，而且老习惯喜欢用大写字母，却还大小写混用（Fortran是不区分大小写的），非常难读；\n程序一开始有一个读初始位置和速度的部分，但是显然没有提供数据文件；\n虽然逻辑不复杂，但是这个实现非常“糟糕”，典型的科学家写码；\n印在PDF或者在线网站上的格式无法正确用编辑器显示，尤其是空格和换行。\n\n我的本意是如果能快速运行，或者简单改成现代语言，作为一个程序小例子玩一玩挺好的。 结果尝试了半天，发现如果想解决以上几个问题需要花费更多精力，还不能保证跑起来没问题，很快萌生放弃的念头。\n在网上搜了一下，Julia社区中已经有了一个开发中的NBodySimulator，展现了极大的潜力。 他不仅涵盖了分子动力学，还有众多能归纳为N个物体相互作用的系统。本质上N体问题是一个ODE常微分方程组，所以DifferentialEquations.jl这个库天然适合处理这类问题。 与其费心费力改写老旧Fortran77,不如直接拥抱新时代。\nN体模拟比等离子体模拟要简单，不失为一个很好的模拟入门训练。"
  },
  {
    "objectID": "posts/sweden/index.html",
    "href": "posts/sweden/index.html",
    "title": "瑞典游记",
    "section": "",
    "text": "瑞典，北境上的富庶王国。第一次踏上欧洲的领土，竟然是飞越了大西洋，途径冰岛，来到了波罗的海之旁。 波士顿到雷克雅未克的航班上，邻座左边是个美国老太太，右边是个印度小哥。老太太和三个朋友计划到冰岛旅行一星期，一路上神采飞扬的样子。她是个妇产科的护士，特别热情而耐心地跟我俩唠嗑，那种与生俱来的亲切感让人觉得特别温馨。我小睡的时候座椅靠背一直是打直的，她在一旁轻轻敲我的胳膊，告诉我可以试着把靠背放下去一点，说罢还自嘲老是像个母亲般唠叨。我跟她说我第一次出来开会，要做个海报展示，她听后连忙鼓励我说一定没问题，生怕我紧张。这些自然的反应，真是慈爱的天性。右手侧靠窗的印度博士，在斯德哥尔摩当生物研究员，刚在波士顿开完一周会，坐飞机赶回瑞典的家里：一位当药剂师的妻子和两岁的女儿在等他。他说早年很幸运到意大利交换，然后又在瑞典完成了博士学位，之后就选择在瑞典继续工作了下来。他恰巧和我完全同一趟航班，飞机到达冰岛又晚点了一小时，下趟的起飞时间有些赶，于是就有了我俩一路小跑带插队的入境找登机口的经历。奋斗在海外的印度人，跟我们中国人是多么相像。下飞机的时候，老太太在后面连声吆喝：“有人要赶飞机啦，麻烦前面的各位让一让！”看我俩往前挤到几乎看不见，又补上一句“祝你们好运”。到了登机口，平抚了下呼吸，印度小哥不禁赞叹怎么会有这么友善的女士。是啊，这么美妙的事。 到达瑞典是清晨，小雨初霁，大地如新。坐着火车18分钟就到了Uppsala，路上广袤的草场，时不时的牛群和马群，还在个桥洞口见识到了一辆真正的马车。凭着手机仅剩的10%的电，辨识着不认识的瑞典文字，八点摸到了下榻的酒店。来的太早，先前的房客还没退房，空屋子都没收拾出来。俊朗的瑞典哥们大手一挥：“咱这儿有早点，坐着喝杯咖啡上上网，过一阵再来问。”饿了一晚上饥肠辘辘的我，就这么厚脸皮地吃起了瑞典宾馆里的丰盛早餐。 单人间着实小，却是什么都不缺。困顿的我倒头就睡，醒来已是周日的下午五点半。窗外的这阳光灿烂得，就像三四点的安娜堡。出去逛逛，补上一餐。这20万人的小城，走出去十分钟就让我碰上一间写着中文的中国餐馆。服务生一听就是个北京口音，坐下思忖半天点上一盘孜然牛肉和一份蛋炒面，那滋味比之国内都不逞多让。\n为什么我觉得乌普萨拉如此亲切？可能是Hannes Alfvén的缘故。这位等离子体届迄今为止唯一的诺贝尔奖获得者，就是在这里学艺成长的。从镇上一路走到学校，跨过车站，越过小河，有种林间漫步的童话感。学校在山上，而小镇在山下，这种层次感很容易产生高山仰止之意。\nMOP外磁层会议期间的一天晚上，在我们白天开会的阶梯教室里有一场面向公众的科普论坛。瑞典民众的科学素养之高令我叹服，问出的问题都是基于基本理性和逻辑思考的。Fran的耐心解答和手舞足蹈般的演示也让我看到业内顶级科学家把复杂问题简单化的功力。讲解木星的电流片时，那个经典的芭蕾舞裙䙓动作令我印象深刻。作为行业内的女性科学家三巨头之一，Fran在两年后得到了AGU的终身成就奖，也是当之无愧。\n周四的晚上，在城堡里举行的晚宴。这是我第一次切身走近欧洲的古堡，作为曾经乌普萨拉领主俯瞰领地的至高点，真有一览众山小之感。毕竟是我第一次参加学术会议的晚宴，在城堡门口等待的时候我既兴奋又紧张。在楼梯间便开始供应香槟，可能是酒会的常规开胃酒。进入正厅，五排长桌依次排开，嘉宾们依序入座，服务员列着队入场，为宾客们收起香槟的小高脚杯，斟起白葡萄酒并端来了前菜。大概记得是海鲜配一些蔬菜，味道一般。换至主菜，又给每人配了一支新杯子，倒了红葡萄酒，配上牛排，本就不大的桌子上一时间已然摆满了各式玻璃杯。然而，这还没完，点心环节竟然还有类似XO一样的洋酒，让我对于Banquet大大增涨了见识。Camilla, Yash和我坐在一起，附近还有一位泰国女生和英国女生，这样有跨度的组合借着酒兴让交流变得更有意思。原来Yash毕业于印度一家私立的理工学校，外公曾是一州的省长，父母如今都在新加坡工作。他来到美国读航天工程硕士前曾经在印度的航空公司实习过，对公司里的摸鱼文化深恶痛绝。\nUppsala真就是一个很小的地方，估计从城市一头走到另一头也用不了一个小时。学校在山上，城镇在山脚下，还有条护城河一路延伸过来。教堂、市集、车站、居民区，分得很是清楚。每天从车站旁的酒店走到空间研究所，穿过车站广场，走过商业街，跨国河转角走入公园，然后沿着足球场旁山径的小道穿梭十分钟就到了大楼前；亦或者步履沉重的时候，坐着公交车盘旋上下，约莫十五分钟就能从车站直到楼前。这里的风貌总让人产生时空交隔的错觉，一瞬间你在十六世纪，下个瞬间又来到了二十一世纪。在芬兰博后期间遇到了Andreas，正是在这里学习、成长，如今又回到了那个地方。从各个角度Uppsala都称不上繁华，但四处都有着生机和活力。\n会议周三的下午有个集体出游的活动，驱车半小时来到附近一处古代战争遗迹，但我瞧了半天也没看出什么大阵仗。Tamas他们这群老家伙们显然也不是奔着旅游来的，而是为了那鲜扎啤酒。彼时我还未能领会酒的重大意义：这世界三大饮品，咖啡、茶与酒，贯穿了多少的人生一世。\n\n\nYash的首次演讲，以及德国老学者完全听不懂的问题；\n校外首次海报展示，以及贾老师“宿敌”的礼貌问候；\n旁边一位做Titan研究的美国小哥。"
  },
  {
    "objectID": "posts/sweden/index.html#uppsala",
    "href": "posts/sweden/index.html#uppsala",
    "title": "瑞典游记",
    "section": "",
    "text": "瑞典，北境上的富庶王国。第一次踏上欧洲的领土，竟然是飞越了大西洋，途径冰岛，来到了波罗的海之旁。 波士顿到雷克雅未克的航班上，邻座左边是个美国老太太，右边是个印度小哥。老太太和三个朋友计划到冰岛旅行一星期，一路上神采飞扬的样子。她是个妇产科的护士，特别热情而耐心地跟我俩唠嗑，那种与生俱来的亲切感让人觉得特别温馨。我小睡的时候座椅靠背一直是打直的，她在一旁轻轻敲我的胳膊，告诉我可以试着把靠背放下去一点，说罢还自嘲老是像个母亲般唠叨。我跟她说我第一次出来开会，要做个海报展示，她听后连忙鼓励我说一定没问题，生怕我紧张。这些自然的反应，真是慈爱的天性。右手侧靠窗的印度博士，在斯德哥尔摩当生物研究员，刚在波士顿开完一周会，坐飞机赶回瑞典的家里：一位当药剂师的妻子和两岁的女儿在等他。他说早年很幸运到意大利交换，然后又在瑞典完成了博士学位，之后就选择在瑞典继续工作了下来。他恰巧和我完全同一趟航班，飞机到达冰岛又晚点了一小时，下趟的起飞时间有些赶，于是就有了我俩一路小跑带插队的入境找登机口的经历。奋斗在海外的印度人，跟我们中国人是多么相像。下飞机的时候，老太太在后面连声吆喝：“有人要赶飞机啦，麻烦前面的各位让一让！”看我俩往前挤到几乎看不见，又补上一句“祝你们好运”。到了登机口，平抚了下呼吸，印度小哥不禁赞叹怎么会有这么友善的女士。是啊，这么美妙的事。 到达瑞典是清晨，小雨初霁，大地如新。坐着火车18分钟就到了Uppsala，路上广袤的草场，时不时的牛群和马群，还在个桥洞口见识到了一辆真正的马车。凭着手机仅剩的10%的电，辨识着不认识的瑞典文字，八点摸到了下榻的酒店。来的太早，先前的房客还没退房，空屋子都没收拾出来。俊朗的瑞典哥们大手一挥：“咱这儿有早点，坐着喝杯咖啡上上网，过一阵再来问。”饿了一晚上饥肠辘辘的我，就这么厚脸皮地吃起了瑞典宾馆里的丰盛早餐。 单人间着实小，却是什么都不缺。困顿的我倒头就睡，醒来已是周日的下午五点半。窗外的这阳光灿烂得，就像三四点的安娜堡。出去逛逛，补上一餐。这20万人的小城，走出去十分钟就让我碰上一间写着中文的中国餐馆。服务生一听就是个北京口音，坐下思忖半天点上一盘孜然牛肉和一份蛋炒面，那滋味比之国内都不逞多让。\n为什么我觉得乌普萨拉如此亲切？可能是Hannes Alfvén的缘故。这位等离子体届迄今为止唯一的诺贝尔奖获得者，就是在这里学艺成长的。从镇上一路走到学校，跨过车站，越过小河，有种林间漫步的童话感。学校在山上，而小镇在山下，这种层次感很容易产生高山仰止之意。\nMOP外磁层会议期间的一天晚上，在我们白天开会的阶梯教室里有一场面向公众的科普论坛。瑞典民众的科学素养之高令我叹服，问出的问题都是基于基本理性和逻辑思考的。Fran的耐心解答和手舞足蹈般的演示也让我看到业内顶级科学家把复杂问题简单化的功力。讲解木星的电流片时，那个经典的芭蕾舞裙䙓动作令我印象深刻。作为行业内的女性科学家三巨头之一，Fran在两年后得到了AGU的终身成就奖，也是当之无愧。\n周四的晚上，在城堡里举行的晚宴。这是我第一次切身走近欧洲的古堡，作为曾经乌普萨拉领主俯瞰领地的至高点，真有一览众山小之感。毕竟是我第一次参加学术会议的晚宴，在城堡门口等待的时候我既兴奋又紧张。在楼梯间便开始供应香槟，可能是酒会的常规开胃酒。进入正厅，五排长桌依次排开，嘉宾们依序入座，服务员列着队入场，为宾客们收起香槟的小高脚杯，斟起白葡萄酒并端来了前菜。大概记得是海鲜配一些蔬菜，味道一般。换至主菜，又给每人配了一支新杯子，倒了红葡萄酒，配上牛排，本就不大的桌子上一时间已然摆满了各式玻璃杯。然而，这还没完，点心环节竟然还有类似XO一样的洋酒，让我对于Banquet大大增涨了见识。Camilla, Yash和我坐在一起，附近还有一位泰国女生和英国女生，这样有跨度的组合借着酒兴让交流变得更有意思。原来Yash毕业于印度一家私立的理工学校，外公曾是一州的省长，父母如今都在新加坡工作。他来到美国读航天工程硕士前曾经在印度的航空公司实习过，对公司里的摸鱼文化深恶痛绝。\nUppsala真就是一个很小的地方，估计从城市一头走到另一头也用不了一个小时。学校在山上，城镇在山脚下，还有条护城河一路延伸过来。教堂、市集、车站、居民区，分得很是清楚。每天从车站旁的酒店走到空间研究所，穿过车站广场，走过商业街，跨国河转角走入公园，然后沿着足球场旁山径的小道穿梭十分钟就到了大楼前；亦或者步履沉重的时候，坐着公交车盘旋上下，约莫十五分钟就能从车站直到楼前。这里的风貌总让人产生时空交隔的错觉，一瞬间你在十六世纪，下个瞬间又来到了二十一世纪。在芬兰博后期间遇到了Andreas，正是在这里学习、成长，如今又回到了那个地方。从各个角度Uppsala都称不上繁华，但四处都有着生机和活力。\n会议周三的下午有个集体出游的活动，驱车半小时来到附近一处古代战争遗迹，但我瞧了半天也没看出什么大阵仗。Tamas他们这群老家伙们显然也不是奔着旅游来的，而是为了那鲜扎啤酒。彼时我还未能领会酒的重大意义：这世界三大饮品，咖啡、茶与酒，贯穿了多少的人生一世。\n\n\nYash的首次演讲，以及德国老学者完全听不懂的问题；\n校外首次海报展示，以及贾老师“宿敌”的礼貌问候；\n旁边一位做Titan研究的美国小哥。"
  },
  {
    "objectID": "posts/sweden/index.html#stockholm",
    "href": "posts/sweden/index.html#stockholm",
    "title": "瑞典游记",
    "section": "Stockholm",
    "text": "Stockholm\n有幸参与一个在斯德哥尔摩举行的有关波动的系列讲座，同时第一次踏进世界名城斯德哥尔摩。关于这座城市，我知道些什么？斯德哥尔摩综合征、诺贝尔奖、北欧最大城市、寥寥几点。疫情一波一波，斯德哥尔摩却几乎一切如常。\n在各种层次上，斯德哥尔摩都是一座大城市：发达的公共交通，百万加的人口，标志性的建筑群，享誉世界的学府。在赫尔辛基待了一年走进斯德哥尔摩，如我所料般，想是走入了一个大号的赫尔辛基。然而瑞典王国的历史更加悠长，祖上阔过，两次世界大战也几乎没有波及瑞典领土，所以有众多流传至今的古迹。查了下资料才知道，我原先对于瑞典高校的认知存在一些偏差。各大榜单上瑞典的头牌都是一所坐落于城市西北角的医学院，其次是一所不在斯德哥尔摩反倒是紧挨着哥本哈根的学校Lund；我很早就知道的KTH排名上还不及Uppsala大学和Stockholm大学，但是在城市北边占了很大一块地，地铁站中唯一一个瑞典语的大学，指的就是KTH。\n斯德哥尔摩有一些微妙的不协调感。我在城市里穿梭了三天，发觉了些蛛丝马迹：虽然公路交通遵循右行规则，但是地铁却是左行的；虽然瑞典人的英文普遍非常好，但是街上的标识几乎看不见英文。\n绕着老城走了一圈，暗夜寒风，果然还是把我吹病了。疫情下的这个时间游客很少，但大多的纪念品商店、餐厅和酒吧依旧开着门。很遗憾没有时间去参观这数量众多的博物馆，但匆匆扫一眼便知这是我一定会专程再来旅游的地方。\n\nNordita Winter School\n讲座主办方Nordita坚持办了一个线下的讲座，我也没做多想跨过一湾海峡来到了瑞典。Nordita是一个理论物理研究所，由北欧国家共同资助。十几年前的时候Nordita还在哥本哈根，后来才搬到了斯德哥尔摩。这主要是个研究机构，只有很少的博士生，其余都是各个理论物理方向的博后和研究员。他们一直挂靠在Stockholm University的校园里，去年搬进了新的办公楼，占了整整两层，还有很多空阔的地方。玻璃隔间的办公室，宽敞的公共休息区，四处摆弄的拼图和小玩具，以及几乎每一面墙上都有的白板。这些白板可不是摆设，我目之所及上面都写满了公式推导，一看即知是真的在讨论理论问题的，而非敷衍忽悠大众的。如果说妙笔能够生花，那么现如今的数理研究工作就更应该像这样让人们能自由地探索思想。交流和碰撞，我很好奇有多少发现是在横的纸上做出的，又有多少是在竖的板上完成的。\n在由于疫情取消了去年的冬季讲座后，今年他们坚持办了一个线下的讲座，请到了来自CMU天文系的Tina教授来讲重力波，和来自MIT核工程系Nuno副教授来讲磁流体波动。Nuno说是来讲波动，讲着讲着决定把话题扯到不可压磁流体理论中的湍流和磁重联，虽不是我直接来的目的，但也是打开了一类研究的新窗口。\n每天午餐都在学校的餐厅吃自助，我感觉瑞典比芬兰懂美食，但是这各式混杂东西混搭，一度让我以为真是相当国际化的食物。 Nordita周三办了个特邀晚宴，是个很标准的西式晚餐，就在平日吃午餐的地方。学校新开不久的餐厅，Nordita身先士卒来包场，订了四桌二十人。前菜主菜甜品，意料之外的好吃，尤其那份甜点，是画龙点睛的一笔。每桌准备了一瓶白葡萄酒一瓶红葡萄酒，我们从七点一路吃到十点打洋，在几位东道主老学者的带领下几乎喝空了瓶。他们也是好久没有这样一群人坐下来畅饮聊天了，所以无论是所长、首席研究员Yxel，资深学者Dubra，还是Tina，比这帮前来的年轻学生们兴致更高。Nuno显然是最克制的那个人，比较安静，也没留到最后就先走了。学术界也有各式各样的人，Nuno可能更接近我原先想象的科学家的样子吧。\n\n\n中餐\n这里的中餐馆并没有我想象般多，选择余地跟北美大城市相比也少了个量级，但几天下来还是有些发现。除了周三的晚宴，其余每晚我都找了家中餐馆，借着公款吃喝的名头，一个人点两道菜。头天下午刚到，没吃午饭，在酒店附近瞅到一家亚洲馆子，我一开始以为是韩餐或是日料、结果是个东北大妈开的店——回头一看，店名是个“白马”的拼音。要了份炒面，好家伙，份量惊人，让我一度担心吃完晚饭是否都能省了。结果到了晚上还是坚持出去觅食，对比下就近选了附近居民区里的东北馆子。店名带“羊”，我想着定是主打羊肉，于是点了小葱拌豆腐和孜然羊肉。夫妻店加上女儿做些瑞典语翻译，聊了阵后才得知他们为了移民才举家出来，如今不过在瑞典待了三年，标准的新移民。瑞典的移民政策最近在收紧，但是相比其他国家依旧非常宽松，到了工作年限以后甚至连语言要求都没有。他们一家有亲戚在纽约，本来想着先去美国看看，结果办旅游签的时候直接被领馆以“有移民倾向”为由拒了。最终辗转来了瑞典，言语中仍透露出摆脱国内阶层固化的渴望和面对外国异类眼光的担忧。聊得虽开心，但这菜式出品一个比一个咸，结果老板娘跟我解释道瑞典人有时候吃这些个还要蘸酱油，我真是目瞪口呆——纯粹只是他们自己家口重罢了。吃罢小葱拌豆腐得到的经验，就是豆腐和葱为表，而里则是盐加味精。 第二个晚上的乡月餐厅正好在Stockholm University和酒店之间，傍晚结束讨论后就徒步走到了餐馆。一个不太常见的搭配蒜泥茄子，和一份别出心裁的将糖醋汁凝结成糖衣裹成的糖醋排骨，免费续的白饭，吃得有点撑；也亏我还能走回酒店。 第三个晚上在城市另一头的川菜小窝Little China，当之无愧本周中餐最佳。川北凉粉加牛肉面，非常地道，价格公允。与我年纪相近的夫妻俩在台前，两位身着统一厨师服的师傅在幕后，餐厅并不显眼，味道却着实令人惊喜。旁边两步路有一家华为的售后服务门店，想必他们也会时常光顾这里吧。 第五晚，在车站旁做完抗原检测，跨过桥向西来到香港餐厅。老板娘和服务员一看都是广东人，可菜单上却未必看得出来——也不知何时香港做起了北京烤鸭？通篇看下来并没有找到一眼能认出的广东料理，索性点了份拼盘咖喱饭，但也着实不便宜。老板娘想催命似的在我跟前晃来晃去，仿佛生怕我不点菜跑了一样。 第六晚，结束全部课程后来到老城区逛逛，在旅游经典附近找到一家号称从1968年开到现在的中餐Formosa。不查不知道，这个词来源于葡萄牙语，本意是“美丽”的意思，十六世纪葡萄牙人航海前往日本途中发现了台湾，船员惊呼“福尔摩沙”，于是大航海时代的欧洲习惯称呼台湾为Formosa。由此，这家店祖上肯定是台湾一代的，也难怪菜单里会出现温州拌面这道我在国内没去过温州就没听过的菜式。这拌面就是醋、蒜和面，一点都不好吃；毛家红烧肉做得倒是中规中矩，配的三份佐菜黑木耳、腌萝卜和花生米倒是十分出彩。"
  },
  {
    "objectID": "posts/cappella/index.html",
    "href": "posts/cappella/index.html",
    "title": "Cappella",
    "section": "",
    "text": "如果当时   \n再见"
  },
  {
    "objectID": "posts/arm/index.html",
    "href": "posts/arm/index.html",
    "title": "ARM-64 Architecture",
    "section": "",
    "text": "There is probably a ongoing trend of adopting arm chips to commercial and even high performance computing world. I got a chance to try out the new Raspberry Pi 4 with 64-bit quad core processor running at 1.5 GHz and 8 GB of memory. The base frequency is 0.6 GHz, and when running tasks, it will reach 1.5 GHz. The baseline temperature at 0.6 GHz is 41 degrees Celcius. Earlier this year they launched a true 64-bit Linux distribution for arm. Now it’s time to get a first-hand feeling about it.\nJulia has an official distribution for the 64-bit arm system. Running my unit test for the Batsrus.jl package takes 33.2 seconds, while on my MacBookPro 2016 it’s around 9.5 seconds. So it’s about 3.5x slower on a single core. It is possible to overclock to about 2.05 GHz. At this clock rate, the test finishes in 27.4 seconds, with highest temperature reaching 47.7 degrees Celcius.\nI tried to test my plotting package in Julia, but had no luck in a successful installation.\nAs for the multi-core performance, I tried my version of BATSRUS. When I compiled for the first time, it complained to me during linking phase:\nFaceGradient.f90:(.text+0x3bb4): relocation truncated to fit: R_AARCH64_TLSLE_ADD_TPREL_HI12 against symbol `__facegradient_MOD_dcoorddxyz_ddfd' defined in .tbss section in Tmp_/FaceGradient.o\nSearching on the web leads me to an error related to 32/64 bit system. According to the suggestion, adding -fPIC flag solved the problem.\nThen for the shocktube test, compiled with gfortran -O3, the results are shown in the following table:\n\n\n\nPlatform\n# of MPI\n# of threads\nTimings [s]\n\n\n\n\nPi ARM 1.5 GHz\n1\n1\n2.97\n\n\nPi ARM 1.5 GHz\n1\n2\n1.85\n\n\nPi ARM 1.5 GHz\n1\n4\n1.55\n\n\nPi ARM 1.5 GHz\n2\n1\n2.12\n\n\nPi ARM 1.5 GHz\n4\n1\n2.27\n\n\nPi ARM 2.05 GHz\n1\n1\n2.20\n\n\nPi ARM 2.05 GHz\n1\n2\n2.40\n\n\nPi ARM 2.05 GHz\n1\n4\n2.82\n\n\nPi ARM 2.05 GHz\n2\n1\n1.75\n\n\nPi ARM 2.05 GHz\n4\n1\n2.06\n\n\nMac i7 2.2 GHz\n1\n1\n1.18\n\n\nMac i7 2.2 GHz\n1\n2\n0.85\n\n\nMac i7 2.2 GHz\n1\n4\n0.67\n\n\nMac i7 2.2 GHz\n2\n1\n0.82\n\n\nMac i7 2.2 GHz\n4\n1\n0.68\n\n\nx86 Cascade Lake 2.7 GHz\n1\n1\n1.19\n\n\nx86 Cascade Lake 2.7 GHz\n1\n2\n0.88\n\n\nx86 Cascade Lake 2.7 GHz\n1\n4\n0.72\n\n\nx86 Cascade Lake 2.7 GHz\n2\n1\n1.22\n\n\nx86 Cascade Lake 2.7 GHz\n4\n1\n0.75\n\n\n\nSo it’s about 2.5x slower on both single core and multi-cores compared to MacBookPro and one of the top supercomputers. Still reasonable. No idea why the overclock performance degrades for parallel runs. With 4 MPI processes, the highest temperature reaches about 58 degrees Celcius. With 4 threads, the highest temperature reaches 50 degrees, and it’s about 30% slower than 4 MPI. What’s puzzling me is that the parallel performance is in general really bad.\nHowever, I was told the other day that a Monte Carlo code that is using random number generators gives about 1% difference in the result of a very accurate molecular dynamics simulation compared to AMD and Intel CPUs. This is a big warning flag if you want to dive deep into ARM.\nUntil now, I still don’t understand why a presumably multi-core program like MPI written in C/C++ or Fortran will trigger the fan while Julia ones don’t."
  },
  {
    "objectID": "posts/memory/index.html",
    "href": "posts/memory/index.html",
    "title": "Linux Memory",
    "section": "",
    "text": "Since I started working with Vlasiator, I have encountered many issues related to memory usage. Now it’s a good time to go over some basics in Linux’s memory management."
  },
  {
    "objectID": "posts/memory/index.html#pages",
    "href": "posts/memory/index.html#pages",
    "title": "Linux Memory",
    "section": "Pages",
    "text": "Pages\nFrom Anticipating Your Memory Needs: &gt; The Linux kernel organizes physical memory in units of pages of a certain size called base pages. For example, the default base page size when running on Intel processors is 4KB. These pages are allocated to user and kernel tasks as they need memory. When processing large amounts of data from slower disk devices, the Linux kernel uses a page cache to cache contents, like disk blocks, to speed up access to frequently accessed data. The kernel allocates all the memory not currently in use to the page cache. As the kernel needs to allocate more memory for other tasks, it can reclaim pages from the page cache since the contents in the page cache can be restored from disk blocks when the need arises. Reclamation happens as the kernel starts to run low on free memory pages.\nFrom my experience on Ubuntu 18 with 16 GB of memory, the Linux kernel usually leaves ~ 1 GB free memory. So if I understand it correctly, all the other available memory not actually in use is in page cache. I believe this number is configurable as a percentage of the total available memory."
  },
  {
    "objectID": "posts/memory/index.html#watermarks",
    "href": "posts/memory/index.html#watermarks",
    "title": "Linux Memory",
    "section": "Watermarks",
    "text": "Watermarks\nThere are three watermarks that trigger various actions for free memory management: high, low, and min. These represent the remaining free memory of the current system.\n\nHigh: when there is more than high in the remaining memory, the system thinks that the current memory usage pressure is not big.\nLow: when the remaining memory is low, the system will think that the memory is insufficient, and will trigger kswapd kernel thread to recycle the memory\nmin: when the remaining memory is less than min, the system memory pressure is very large. Generally, the memory less than min will not be allocated. By default, the memory less than min is reserved for special use. It belongs to reserved page box and is used for atomic memory request operation.\n\nYou can find a similar introduction to zone watermarks in Chapter 2 Describing Physical Memory for the Linux kernel."
  },
  {
    "objectID": "posts/memory/index.html#memory-consumption-patterns",
    "href": "posts/memory/index.html#memory-consumption-patterns",
    "title": "Linux Memory",
    "section": "Memory Consumption Patterns",
    "text": "Memory Consumption Patterns\n\nDifferent workloads have different memory consumption patterns. Some workloads allocate and free memory at a steady rate like a media streaming program that is reading disk blocks, rendering the media, freeing up already rendered data and fetching more data to render. Other workloads like scientific modeling might allocate a large number of pages over a period of time to read in data from disk, then they perform data computation on this accumulated data while allocating smaller amounts of memory and finally they may release all the memory holding data before starting next modeling run. Still some workloads like transaction processing have periodic spikes of memory allocation requests that keep recurring over long periods of times."
  },
  {
    "objectID": "posts/ole/index.html",
    "href": "posts/ole/index.html",
    "title": "Ole Solskjaer Returning to MU",
    "section": "",
    "text": "今天我看着曼联的新闻，两眼嗔满了泪水。我认识了你已经十几年，我看到你教练的新闻已经近五年。我知道你会回来的；一定会的。但这样回来，没有比这样回来更好的情景了。\n点滴之中开始的复兴之路，第一步，就是统一战线。不知多久之后，曼联的球员们又开始同坐一辆大巴赶赴下榻的宾馆了。\n最近每点开一个相关新闻，眼里总是浮现着泪花。奥莱，你承载着一代曼联球迷的记忆。就像某位球迷说的，希望这东西，总是在最绝望的时候到来。当所有的工作人员都面带笑意，所有的球迷都竭力呼喊时，你知道，一切在向好的方向进发。\n七连胜，这是我喜欢的曼联。"
  },
  {
    "objectID": "posts/ole/index.html#section",
    "href": "posts/ole/index.html#section",
    "title": "Ole Solskjaer Returning to MU",
    "section": "2019/10/27",
    "text": "2019/10/27\n胜的时候我在，负的时候我也在。球队的困境不是哪个教练突然就能化腐朽为神奇的，不破不立，没有耐心什么都等不到。从莫耶斯、范加尔、穆里尼奥到索尔斯克亚，球迷一个劲儿的指责，却似乎总也等不来让他们满意的人选。树挪死人挪活，勇士当年换帅科尔的故事还历历在目，而那前提是全面支持的管理层和架构清晰的球队布置。如今的曼联和勇士，都面临着缅怀往日荣光的念想，然而自然规律周而复始，做正确的决断，才能由时间和实践给出答案。"
  },
  {
    "objectID": "posts/ole/index.html#section-1",
    "href": "posts/ole/index.html#section-1",
    "title": "Ole Solskjaer Returning to MU",
    "section": "2020/10/11",
    "text": "2020/10/11\n绝不因一场比赛就推翻所有的认知。胜的时候我在，负的时候我也在。"
  },
  {
    "objectID": "posts/ole/index.html#section-2",
    "href": "posts/ole/index.html#section-2",
    "title": "Ole Solskjaer Returning to MU",
    "section": "2024/06/28",
    "text": "2024/06/28\n曲终人散，总有落幕时。曼联尾大不掉，非奥莱一人得以拯救。一切祝好。"
  },
  {
    "objectID": "posts/profiling/index.html",
    "href": "posts/profiling/index.html",
    "title": "Profiling",
    "section": "",
    "text": "The Intel profiler VTune and Trace Analyzer are now bundled in the OneAPI toolkit. It works best for C/C++ codes, and decent for Fortran. I have some good time using the GUI interface for submitting parallel jobs, but sometimes it may be faster to utilize the command line interface."
  },
  {
    "objectID": "posts/profiling/index.html#installation",
    "href": "posts/profiling/index.html#installation",
    "title": "Profiling",
    "section": "Installation",
    "text": "Installation\nFor large systems like Frontera, it is as easy as\nmodule load oneapi\nmodule load vtune"
  },
  {
    "objectID": "posts/profiling/index.html#collecting-vtune-data",
    "href": "posts/profiling/index.html#collecting-vtune-data",
    "title": "Profiling",
    "section": "Collecting VTune Data",
    "text": "Collecting VTune Data\nibrun -n 4 vtune -c hotspots -r hotspots_base -- ./heart_demo.base -m ../mesh_mid -s ../setup_mid.txt -t 10 -i\nibrun -n 4 vtune -c hpc-performance -r hpcperf_base -- ./heart_demo.base -m ../mesh_mid -s ../setup_mid.txt -t 10 -i\nibrun -n 4 vtune -c threading -r threading_base -- ./heart_demo.base -m ../mesh_mid -s ../setup_mid.txt -t 10 -i\nNote that in able to trigger backtracing to source codes, typically -g or debugging mode is required. Stack tracing should be enabled."
  },
  {
    "objectID": "posts/profiling/index.html#analyzing-vtune-data",
    "href": "posts/profiling/index.html#analyzing-vtune-data",
    "title": "Profiling",
    "section": "Analyzing VTune Data",
    "text": "Analyzing VTune Data\nVTune has a nice GUI that is typically named vtune-gui. We can open the generated profiling reports inside the GUI and check all kinds of metrics."
  },
  {
    "objectID": "posts/profiling/index.html#trace-analyzer",
    "href": "posts/profiling/index.html#trace-analyzer",
    "title": "Profiling",
    "section": "Trace Analyzer",
    "text": "Trace Analyzer\nThis is Intel’s tool for improving MPI efficiency.\n\nCollecting Data\nIf we use Intel’s MPI library,\nmpirun -n 16 -trace program.exe\nFor other MPI libraries, the corresponding dynamic library must be loaded. Note that OpenMPI is not compatible with Trace Analyzer.\n\n\nAnalyzing Tracer Data\nTrace Analyzer also has a nice GUI.\ntraceanalyzer"
  },
  {
    "objectID": "posts/madison/index.html",
    "href": "posts/madison/index.html",
    "title": "麦迪逊游记",
    "section": "",
    "text": "Madison离Ann Arbor不近也不远，六个多小时车程，除了在Chicago恼人的堵车之外，其他的行程还是惬意的。我原以为她就在密歇根湖边，实际上在湖边的是密尔沃基，而麦迪逊坐落于密尔沃基正西约一个半小时车程的地方。她市里面有两个湖，大到曾让我看着地图以为是五大湖。UW的校园正处于两湖之间，一片空阔，风景绝美的地方。相比于安村，他们还是Wisconsin州的首府，所以商业气息更加浓郁：到了周末的晚上，成群的行人、游窜的酒鬼、时不时的音乐和喧嚣，显示出城市的一抹温情。Downtown中就有一家Kongfu Tea，墙上贴满了各式各样的便利贴，奇奇怪怪的内容和小广告，就快成美帝留学移民一条龙了。和往常一样，我们并没有住在离学校近的地方，比赛主办方找了家合作酒店，就是图个便宜。一起下榻的还有其他两三支球队，早上一起吃早餐的情景，也是似曾相识。Harry在周六晚上还到我们的酒店走访了一趟，我们一车人找了个借口故意躲开了，可想而知不得人心这事儿早不是一天两天了。\n麦迪逊的体育也很好，篮球橄榄球都和密歇根有的一拼。可是他们这橄榄球场，相比于密歇根的Big House来说，略显寒碜了些。在橄榄球场旁边有一个室内田径场， 只是400米跑道中间的不是足球场，而是四个篮球场。如果说整个学校加起来就这么点运动场地，还是显得单薄了一点。不过我忽然想起来第一天晚上刚到的时候伟煜的同学 和我们一起吃饭前刚打完羽毛球，可那个室内运动场并没有羽毛球场，所以由此推断应该还有其他的运动场。周六中午我们在体育馆外寒风凌烈地吃着Burrito，我在他们学校 的体育纪念墙前看了好久，一个个扫过那些镀了金的名字，体味着Big Ten联盟中的悠久底蕴。将体育变成文化的一部分，欧美做得非常好。\n我们初到的时候，在学校附近的一处小湖边散了会儿步。威斯康辛的僻静，在这傍晚宁静的湖水边一览无余。当年差了一点就来了这里，仅凭这一点也感觉有些亲切。比赛么没什么好说的，一顿操作猛如虎，该赢的赢了一场，该输的也都输了，马奎特大学的一个接近两米的大哥个人能力冠绝整个比赛，可惜队友实在不太给力；UIUC的八人组着实很强，他们是明显的实战派，平时的训练就是一起打野球，走的就是时下流行的炮轰路线。输给他们心悦诚服，队里的女生球技也比我们队中的一些男生要强。去年他们能拿下野狼杯的冠军，实力无需置疑。\n之前跟冠儒以及炜煜的女朋友草莓姐都不是很熟，这一路聊过来也知晓了不少有意思的事情。冠儒原来在沈阳的外国语学习日语，从小走的就是不一般的道路，还有过在芝加哥home stay的经历；草莓姐给我们讲湾区的生活和见闻，以及为什么不愿意再回到五大湖区生活的原因。我们谈论教育，谈论家庭，谈论孩子，骤然觉得这趟旅行很值，有了一些未曾相见的际遇。\n回来的路上经过芝加哥的一家日本超市，看到了许多平日少见的日本产品。在经过零食区的时候，冠儒向我们一一推荐了好吃的东西，最后提到了日本近些年还有个Pocky Day，是年轻情侣们借着一款叫Pocky的甜食来一起度过的情人节。我也是在这里第一次见识了M Lady，了解了这时尚前沿的蛋糕品牌如何打动了中国女生的心。当然还有芝加哥唐人街的撸串儿，这辈子吃过的最贵的烧烤，而且竟然还觉得没有饱腹。队友们忽地染上了修图瘾，虽然这次只拿了第四，但团队的氛围很好，为今后的进步奠定了基础。"
  },
  {
    "objectID": "posts/amrex/index.html",
    "href": "posts/amrex/index.html",
    "title": "Learning AMReX",
    "section": "",
    "text": "AMReX examples are organized in separate folders. This looks nice to me, similar to the building blocks of OpenFOAM.\nThe Fortran interface looks really nice.\nA key thing in a good parallel mesh library is to hide MPI communications.\nA notion of IO processor and non-IO processor is established.\nI can tell they are experts. Quotes:\n\nAMReX has a Fortran module, amrex_mempool_module that can be used to allocate memory for Fortran pointers. The reason that such a module exists in AMReX is that memory allocation is often very slow in multi-threaded OpenMP parallel regions. AMReX amrex_mempool_module provides a much faster alternative approach, in which each thread has its own memory pool.\n\nAMReX has built-in multigrid solver. FLEKS is using the multi-block GMRES solver in SWMF, but I also ported that part into pure C++ implementation. It is actually a good chance to see if the MG solver works here. However, note that multigrid is usually for solving elliptic problems (e.g. Poisson’s equation), which is often the most time-consuming part that we try to avoid.\nAMReX, because it is built upon C++, differs type copies and references. For example, BoxArray is a key type in AMR for storing all boxes on the same level. Doing things like\nba[3].coarsen(2);  // DO NOT DO THIS!  Doesn't do what one might expect.\nwill only modify a copy instead of the original array.\nThe distribution of boxes in the domain involves the math of space filling curves. This is perhaps the most interesting question in load balancing.\nFunctions written in the C++ header files are mostly either inline functions or template functions, for example, the diffusion update kernel in the HeatConduction example.\nAMReX uses a subset of cores to do parallel I/O. If all processors attempt to access the disk directly, they will all end up waiting."
  },
  {
    "objectID": "posts/amrex/index.html#first-impression",
    "href": "posts/amrex/index.html#first-impression",
    "title": "Learning AMReX",
    "section": "",
    "text": "AMReX examples are organized in separate folders. This looks nice to me, similar to the building blocks of OpenFOAM.\nThe Fortran interface looks really nice.\nA key thing in a good parallel mesh library is to hide MPI communications.\nA notion of IO processor and non-IO processor is established.\nI can tell they are experts. Quotes:\n\nAMReX has a Fortran module, amrex_mempool_module that can be used to allocate memory for Fortran pointers. The reason that such a module exists in AMReX is that memory allocation is often very slow in multi-threaded OpenMP parallel regions. AMReX amrex_mempool_module provides a much faster alternative approach, in which each thread has its own memory pool.\n\nAMReX has built-in multigrid solver. FLEKS is using the multi-block GMRES solver in SWMF, but I also ported that part into pure C++ implementation. It is actually a good chance to see if the MG solver works here. However, note that multigrid is usually for solving elliptic problems (e.g. Poisson’s equation), which is often the most time-consuming part that we try to avoid.\nAMReX, because it is built upon C++, differs type copies and references. For example, BoxArray is a key type in AMR for storing all boxes on the same level. Doing things like\nba[3].coarsen(2);  // DO NOT DO THIS!  Doesn't do what one might expect.\nwill only modify a copy instead of the original array.\nThe distribution of boxes in the domain involves the math of space filling curves. This is perhaps the most interesting question in load balancing.\nFunctions written in the C++ header files are mostly either inline functions or template functions, for example, the diffusion update kernel in the HeatConduction example.\nAMReX uses a subset of cores to do parallel I/O. If all processors attempt to access the disk directly, they will all end up waiting."
  },
  {
    "objectID": "posts/amrex/index.html#notes",
    "href": "posts/amrex/index.html#notes",
    "title": "Learning AMReX",
    "section": "Notes",
    "text": "Notes\nAnn Almgren from Lawrence-Berkeley gave a presentation on AMR with some application introduction to AMReX.\n\n\n\nHands-on\nHands-on training materials including\n\nSpinning fluid\nSpinning particles\nPachinko\n\nExample codes for ATPESC\nhttps://xsdk-project.github.io/MathPackagesTraining/lessons/amrex/\n\n\nCompilation\nAMReX supports both GNU Make and CMake.\n\n\nMain Components\n\nAMReX.H for the top level definitions.\nAMReX_Print.H for printing.\nAMReX_ParmParse.H for parsing input parameters.\nAMReX_PlotFileUtil.H for plotting.\nAMReX_MultiFab.H for MultiFab support.\nAMReX_MFParallelFor.H for newer loop syntax over MultiFabs.\nAMReX_MultiFabUtil.H\nAMReX_Particles.H\nAMReX_ParticleMesh.H\n\nIt is a common practice to import the amrex namespace:\nusing namespace amrex\nThere are many predefined macros and constant defined in amrex, e.g. BL_SPACEDIM, AMREX_SPACEDIM and AMREX_D_DECL.\n\n\nHello World\nKey points: 1. Wrap everything within Initialize and Finalize for deterministic behaviors.\n#include &lt;AMReX.H&gt;\n#include &lt;AMReX_Print.H&gt;\n\nint main(int argc, char* argv[])\n{\n    amrex::Initialize(argc,argv);\n    {\n        amrex::Print() &lt;&lt; \"Hello world from AMReX version \" &lt;&lt; amrex::Version() &lt;&lt; \"\\n\";\n    }\n    amrex::Finalize();\n}\nRefs: * HelloWorld with GNU Make * https://github.com/atmyers/ecp-tutorials/tree/main/01_HelloWorld\n\n\nParsing Parameters\nGiven an input file\nan_int_scalar = 2\na_bool_scalar = true\na_real_array = 1. 2. 3. 4.\n\na_prefix.a_real_scalar = 99.0\na_prefix.a_string = \"option\"\na_prefix.an_int_array = 4 5 6\n#include &lt;AMReX.H&gt;\n#include &lt;AMReX_ParmParse.H&gt;\n#include &lt;AMReX_Print.H&gt;\n\nvoid test_parameters ();\n\nint main(int argc, char* argv[])\n{\n    amrex::Initialize(argc, argv);\n\n    test_parameters();\n\n    amrex::Finalize();\n}\n\nvoid test_parameters ()\n{\n    {\n        amrex::ParmParse pp;\n        int i;\n        bool b;\n        std::vector&lt;amrex::Real&gt; ra;\n        pp.get(\"an_int_scalar\", i);\n        pp.get(\"a_bool_scalar\",b);\n        pp.getarr(\"a_real_array\", ra);\n        amrex::Print() &lt;&lt; \"an_int_scalar = \" &lt;&lt; i &lt;&lt; \"\\n\"\n                       &lt;&lt; \"a_bool_scalar = \" &lt;&lt; b &lt;&lt; \"\\n\";\n        amrex::Print() &lt;&lt; \"a_real_array = \";\n        for (auto x : ra) {\n            amrex::Print() &lt;&lt; x &lt;&lt; \" \";\n        }\n        amrex::Print() &lt;&lt; \"\\n\";\n    }\n\n    {\n        amrex::ParmParse pp(\"a_prefix\");\n        std::vector&lt;int&gt; ia;\n        amrex::Real r;\n        std::string s;\n        pp.getarr(\"an_int_array\", ia);\n        pp.get(\"a_real_scalar\", r);\n        pp.get(\"a_string\", s);\n        amrex::Print() &lt;&lt; \"an_int_array = \";\n        for (auto x : ia) {\n            amrex::Print() &lt;&lt; x &lt;&lt; \" \";\n        }\n        amrex::Print() &lt;&lt; \"\\n\";\n        amrex::Print() &lt;&lt; \"a_prefix.a_real_scalar = \" &lt;&lt; r &lt;&lt; \"\\n\"\n                       &lt;&lt; \"a_prefix.a_string = \" &lt;&lt; s &lt;&lt; \"\\n\";\n    }\n}\n\n\nMultiFab\nA MultiFab is a C++ class in AMReX (from AMReX_MultiFab.H) the stores and operates on multidimensional arrays in parallel. It contains:\n\nGrid information in the form of a BoxArray that contains one or more components (scalar values) for a single level of the mesh.\nA distribution map, that allows for parallel processing of data in the MultiFab.\nGhost cells that facilitate a variety of mesh refinement, boundary conditions, and particle algorithms.\n\n#include &lt;AMReX.H&gt;\n#include &lt;AMReX_Print.H&gt;\n#include &lt;AMReX_MultiFab.H&gt; //For the method most common at time of writing\n#include &lt;AMReX_MFParallelFor.H&gt; //For the second newer method\n#include &lt;AMReX_PlotFileUtil.H&gt; //For ploting the MultiFab\n\n\nint main(int argc, char* argv[])\n{\n    amrex::Initialize(argc,argv);\n    {\n        amrex::Print() &lt;&lt; \"Hello world from AMReX version \" &lt;&lt; amrex::Version() &lt;&lt; \"\\n\";\n        // Goals:\n        // Define a MultiFab\n        // Fill a MultiFab with data\n        // Plot it\n\n        // Parameters\n\n        // Number of data components at each grid point in the MultiFab\n        int ncomp = 1;\n        // how many grid cells in each direction over the problem domain\n        int n_cell = 32;\n        // how many grid cells are allowed in each direction over each box\n        int max_grid_size = 16;\n\n        //BoxArray -- Abstract Domain Setup\n\n\n        // integer vector indicating the lower coordindate bounds\n        amrex::IntVect dom_lo(0,0,0);\n        // integer vector indicating the upper coordindate bounds\n        amrex::IntVect dom_hi(n_cell-1, n_cell-1, n_cell-1);\n        // box containing the coordinates of this domain\n        amrex::Box domain(dom_lo, dom_hi);\n\n\n        // will contain a list of boxes describing the problem domain\n        amrex::BoxArray ba(domain);\n\n        // chop the single grid into many small boxes\n        ba.maxSize(max_grid_size);\n\n        // Distribution Mapping\n        amrex::DistributionMapping dm(ba);\n\n        //Define MuliFab\n        amrex::MultiFab mf(ba, dm, ncomp, 0);\n\n        //Geometry -- Physical Properties for data on our domain\n        amrex::RealBox real_box ({0., 0., 0.}, {1. , 1., 1.});\n\n        amrex::Geometry geom(domain, &real_box);\n\n\n        //Calculate Cell Sizes\n        amrex::GpuArray&lt;amrex::Real,3&gt; dx = geom.CellSizeArray();  //dx[0] = dx dx[1] = dy dx[2] = dz\n\n\n        //Fill a MultiFab with Data\n        //At the time of writing this is still the most commonly seen method.\n        for(amrex::MFIter mfi(mf); mfi.isValid(); ++mfi){\n            const amrex::Box& bx = mfi.validbox();\n            const amrex::Array4&lt;amrex::Real&gt;& mf_array = mf.array(mfi);\n\n            amrex::ParallelFor(bx, [=] AMREX_GPU_DEVICE(int i, int j, int k){\n\n                amrex::Real x = (i+0.5) * dx[0];\n                amrex::Real y = (j+0.5) * dx[1];\n                amrex::Real z = (k+0.5) * dx[2];\n\n                amrex::Real r_squared = ((x-0.5)*(x-0.5)+(y-0.5)*(y-0.5)+(z-0.5)*(z-0.5))/0.01;\n\n                mf_array(i,j,k) = 1.0 + std::exp(-r_squared);\n\n            });\n         }\n\n        //A second newer method\n        //In this approach the same functionality is contained in a\n        //single ParallelFor function.\n\n        /*\n        const amrex::MultiArray4&lt;amrex::Real&gt;& mf_arrs = mf.arrays();\n        const amrex::IntVect ngs(ngrow);\n\n        amrex::ParallelFor(mf, ngs, [=] AMREX_GPU_DEVICE( int nbx, int i, int j, int k) noexcept {\n\n            amrex::Real x = (i+0.5) * dx[0];\n            amrex::Real y = (j+0.5) * dx[1];\n            amrex::Real z = (k+0.5) * dx[2];\n\n            amrex::Real r_squared = ((x-0.5)*(x-0.5)+(y-0.5)*(y-0.5)+(z-0.5)*(z-0.5))/0.01;\n\n            mf_arrs[nbx](i,j,k) = 1.0 + std::exp(-r_squared);\n\n        });\n        */\n\n        //Plot MultiFab Data\n        WriteSingleLevelPlotfile(\"plt001\", mf, {\"comp0\"}, geom, 0., 0);\n\n\n\n    }\n    amrex::Finalize();\n}\nI think the newer looping syntax is better for GPU.\n\n\nHeat Equation\nIn this Heat Equation example we use two MultiFabs to hold the current and previous values of Phi. Since each MultiFab is distributed separately among parallel processes, this approach can be easily extended for AMR.\nWhile loading the output from 03HeatEquation with n_cell = 128, the output variable lives on a 3D uniform mesh of size 128^3. When I tried to load the data into ParaView 5.13.0, it showed the correct number of cells (128^3 = 1,907,152), and the Extents is from 0 to 64 with 65 points in each dimension.\n#include &lt;AMReX.H&gt;\n#include &lt;AMReX_PlotFileUtil.H&gt;\n#include &lt;AMReX_ParmParse.H&gt;\n\n\nint main (int argc, char* argv[])\n{\n    amrex::Initialize(argc,argv);\n    {\n\n    // **********************************\n    // DECLARE SIMULATION PARAMETERS\n    // **********************************\n\n    // number of cells on each side of the domain\n    int n_cell;\n\n    // size of each box (or grid)\n    int max_grid_size;\n\n    // total steps in simulation\n    int nsteps;\n\n    // how often to write a plotfile\n    int plot_int;\n\n    // time step\n    amrex::Real dt;\n\n    // **********************************\n    // READ PARAMETER VALUES FROM INPUT DATA\n    // **********************************\n    // inputs parameters\n    {\n        // ParmParse is way of reading inputs from the inputs file\n        // pp.get means we require the inputs file to have it\n        // pp.query means we optionally need the inputs file to have it - but we must supply a default here\n        amrex::ParmParse pp;\n\n        // We need to get n_cell from the inputs file - this is the number of cells on each side of\n        //   a square (or cubic) domain.\n        pp.get(\"n_cell\",n_cell);\n\n        // The domain is broken into boxes of size max_grid_size\n        pp.get(\"max_grid_size\",max_grid_size);\n\n        // Default nsteps to 10, allow us to set it to something else in the inputs file\n        nsteps = 10;\n        pp.query(\"nsteps\",nsteps);\n\n        // Default plot_int to -1, allow us to set it to something else in the inputs file\n        //  If plot_int &lt; 0 then no plot files will be written\n        plot_int = -1;\n        pp.query(\"plot_int\",plot_int);\n\n        // time step\n        pp.get(\"dt\",dt);\n    }\n\n    // **********************************\n    // DEFINE SIMULATION SETUP AND GEOMETRY\n    // **********************************\n\n    // make BoxArray and Geometry\n    // ba will contain a list of boxes that cover the domain\n    // geom contains information such as the physical domain size,\n    // number of points in the domain, and periodicity\n    amrex::BoxArray ba;\n    amrex::Geometry geom;\n\n    // define lower and upper indices\n    amrex::IntVect dom_lo(0,0,0);\n    amrex::IntVect dom_hi(n_cell-1, n_cell-1, n_cell-1);\n\n    // Make a single box that is the entire domain\n    amrex::Box domain(dom_lo, dom_hi);\n\n    // Initialize the boxarray \"ba\" from the single box \"domain\"\n    // Note that one can either initialize ba at the time of declaration,\n    // or define the domain as here after the declaration.\n    ba.define(domain);\n\n    // Break up boxarray \"ba\" into chunks no larger than \"max_grid_size\" along a direction\n    ba.maxSize(max_grid_size);\n\n    // Define the physical box, [0,1] in each direction.\n    amrex::RealBox real_box({ 0., 0., 0.}, { 1., 1., 1.});\n\n    // periodic in all direction\n    amrex::Array&lt;int,3&gt; is_periodic{1,1,1};\n\n    // Define a Geometry object\n    // Same as the boxarray, a geometry object can be defined afterwards.\n    geom.define(domain, real_box, amrex::CoordSys::cartesian, is_periodic);\n\n    // extract dx from the geometry object\n    amrex::GpuArray&lt;amrex::Real,3&gt; dx = geom.CellSizeArray();\n\n    // Nghost = number of ghost cells for each array\n    int Nghost = 1;\n\n    // Ncomp = number of components for each array\n    int Ncomp = 1;\n\n    // How Boxes are distrubuted among MPI processes\n    amrex::DistributionMapping dm(ba);\n\n    // we allocate two phi multifabs; one will store the old state, the other the new.\n    amrex::MultiFab phi_old(ba, dm, Ncomp, Nghost);\n    amrex::MultiFab phi_new(ba, dm, Ncomp, Nghost);\n\n    // time = starting time in the simulation\n    amrex::Real time = 0.0;\n\n    // **********************************\n    // INITIALIZE DATA LOOP\n    // **********************************\n\n    // loop over boxes\n    for (amrex::MFIter mfi(phi_old); mfi.isValid(); ++mfi)\n    {\n        const amrex::Box& bx = mfi.validbox();\n\n        const amrex::Array4&lt;amrex::Real&gt;& phiOld = phi_old.array(mfi);\n\n        // set phi = 1 + e^(-(r-0.5)^2)\n        amrex::ParallelFor(bx, [=] AMREX_GPU_DEVICE(int i, int j, int k)\n        {\n\n            // **********************************\n            // SET VALUES FOR EACH CELL\n            // **********************************\n\n            amrex::Real x = (i+0.5) * dx[0];\n            amrex::Real y = (j+0.5) * dx[1];\n            amrex::Real z = (k+0.5) * dx[2];\n            amrex::Real rsquared = ((x-0.5)*(x-0.5)+(y-0.5)*(y-0.5)+(z-0.5)*(z-0.5))/0.01;\n            phiOld(i,j,k) = 1. + std::exp(-rsquared);\n        });\n    }\n\n    // **********************************\n    // WRITE INITIAL PLOT FILE\n    // **********************************\n\n    // Write a plotfile of the initial data if plot_int &gt; 0\n    if (plot_int &gt; 0)\n    {\n        int step = 0;\n        const std::string& pltfile = amrex::Concatenate(\"plt\",step,5);\n        WriteSingleLevelPlotfile(pltfile, phi_old, {\"phi\"}, geom, time, 0);\n    }\n\n\n    // **********************************\n    // MAIN TIME EVOLUTION LOOP\n    // **********************************\n\n    for (int step = 1; step &lt;= nsteps; ++step)\n    {\n        // fill periodic ghost cells\n        phi_old.FillBoundary(geom.periodicity());\n\n        // new_phi = old_phi + dt * Laplacian(old_phi)\n        // loop over boxes\n        for ( amrex::MFIter mfi(phi_old); mfi.isValid(); ++mfi )\n        {\n            const amrex::Box& bx = mfi.validbox();\n\n            const amrex::Array4&lt;amrex::Real&gt;& phiOld = phi_old.array(mfi);\n            const amrex::Array4&lt;amrex::Real&gt;& phiNew = phi_new.array(mfi);\n\n            // advance the data by dt\n            amrex::ParallelFor(bx, [=] AMREX_GPU_DEVICE (int i, int j, int k)\n            {\n\n                // **********************************\n                // EVOLVE VALUES FOR EACH CELL\n                // **********************************\n\n                phiNew(i,j,k) = phiOld(i,j,k) + dt *\n                    ( (phiOld(i+1,j,k) - 2.*phiOld(i,j,k) + phiOld(i-1,j,k)) / (dx[0]*dx[0])\n                     +(phiOld(i,j+1,k) - 2.*phiOld(i,j,k) + phiOld(i,j-1,k)) / (dx[1]*dx[1])\n                     +(phiOld(i,j,k+1) - 2.*phiOld(i,j,k) + phiOld(i,j,k-1)) / (dx[2]*dx[2])\n                        );\n            });\n        }\n\n        // **********************************\n        // INCREMENT\n        // **********************************\n\n        // update time\n        time = time + dt;\n\n        // copy new solution into old solution\n        amrex::MultiFab::Copy(phi_old, phi_new, 0, 0, 1, 0);\n\n        // Tell the I/O Processor to write out which step we're doing\n        amrex::Print() &lt;&lt; \"Advanced step \" &lt;&lt; step &lt;&lt; \"\\n\";\n\n\n        // **********************************\n        // WRITE PLOTFILE AT GIVEN INTERVAL\n        // **********************************\n\n        // Write a plotfile of the current data (plot_int was defined in the inputs file)\n        if (plot_int &gt; 0 && step%plot_int == 0)\n        {\n            const std::string& pltfile = amrex::Concatenate(\"plt\",step,5);\n            WriteSingleLevelPlotfile(pltfile, phi_new, {\"phi\"}, geom, time, step);\n        }\n    }\n\n\n    }\n    amrex::Finalize();\n    return 0;\n}\n\n\nParticleMesh\nProvided the input file:\n# Domain size\n\nnx = 128 # number of grid points along the x axis\nny = 128 # number of grid points along the y axis \nnz = 128 # number of grid points along the z axis\n\n# Maximum allowable size of each subdomain in the problem domain; \n#    this is used to decompose the domain for parallel calculations.\nmax_grid_size = 32\n\n# Number of particles per cell\nnppc = 10\n\n# Verbosity\nverbose = true   # set to true to get more verbosity\n#include &lt;iostream&gt;\n\n#include &lt;AMReX.H&gt;\n#include &lt;AMReX_MultiFab.H&gt;\n#include &lt;AMReX_MultiFabUtil.H&gt;\n#include &lt;AMReX_Particles.H&gt;\n#include &lt;AMReX_PlotFileUtil.H&gt;\n#include &lt;AMReX_ParticleMesh.H&gt;\n\nusing namespace amrex;\n\nstruct TestParams {\n  int nx;\n  int ny;\n  int nz;\n  int max_grid_size;\n  int nppc;\n  bool verbose;\n};\n\nvoid testParticleMesh(TestParams& parms)\n{\n  RealBox real_box;\n  for (int n = 0; n &lt; BL_SPACEDIM; n++) {\n    real_box.setLo(n, 0.0);\n    real_box.setHi(n, 1.0);\n  }\n\n  IntVect domain_lo(AMREX_D_DECL(0, 0, 0));\n  IntVect domain_hi(AMREX_D_DECL(parms.nx - 1, parms.ny - 1, parms.nz-1));\n  const Box domain(domain_lo, domain_hi);\n\n  // This sets the boundary conditions to be doubly or triply periodic\n  int is_per[BL_SPACEDIM];\n  for (int i = 0; i &lt; BL_SPACEDIM; i++)\n    is_per[i] = 1;\n  Geometry geom(domain, &real_box, CoordSys::cartesian, is_per);\n\n  BoxArray ba(domain);\n  ba.maxSize(parms.max_grid_size);\n  if (parms.verbose && ParallelDescriptor::IOProcessor()) {\n    std::cout &lt;&lt; \"Number of boxes              : \" &lt;&lt; ba.size() &lt;&lt; '\\n';\n    std::cout &lt;&lt; \"Box sizes                    : \" &lt;&lt; ba[0].size() &lt;&lt; '\\n';\n  }\n\n  DistributionMapping dmap(ba);\n\n  MultiFab partMF(ba, dmap, 1 + BL_SPACEDIM, 1);\n  partMF.setVal(0.0);\n\n  typedef ParticleContainer&lt;1 + 2*BL_SPACEDIM&gt; MyParticleContainer;\n  MyParticleContainer myPC(geom, dmap, ba);\n  myPC.SetVerbose(false);\n\n  int num_particles = parms.nppc * parms.nx * parms.ny * parms.nz;\n  if (ParallelDescriptor::IOProcessor())\n    std::cout &lt;&lt; \"Total number of particles    : \" &lt;&lt; num_particles &lt;&lt; '\\n' &lt;&lt; '\\n';\n\n  bool serialize = true;\n  int iseed = 451;\n  Real mass = 10.0;\n\n  MyParticleContainer::ParticleInitData pdata = {mass, AMREX_D_DECL(1.0, 2.0, 3.0), AMREX_D_DECL(0.0, 0.0, 0.0)};\n  myPC.InitRandom(num_particles, iseed, pdata, serialize);\n\n  int nc = 1 + BL_SPACEDIM;\n  const auto plo = geom.ProbLoArray();\n  const auto dxi = geom.InvCellSizeArray();\n  amrex::ParticleToMesh(myPC, partMF, 0,\n      [=] AMREX_GPU_DEVICE (const MyParticleContainer::ParticleType& p,\n                            amrex::Array4&lt;amrex::Real&gt; const& rho)\n      {\n          amrex::Real lx = (p.pos(0) - plo[0]) * dxi[0] + 0.5;\n          amrex::Real ly = (p.pos(1) - plo[1]) * dxi[1] + 0.5;\n          amrex::Real lz = (p.pos(2) - plo[2]) * dxi[2] + 0.5;\n\n          int i = amrex::Math::floor(lx);\n          int j = amrex::Math::floor(ly);\n          int k = amrex::Math::floor(lz);\n\n          amrex::Real xint = lx - i;\n          amrex::Real yint = ly - j;\n          amrex::Real zint = lz - k;\n\n          amrex::Real sx[] = {1.-xint, xint};\n          amrex::Real sy[] = {1.-yint, yint};\n          amrex::Real sz[] = {1.-zint, zint};\n\n          for (int kk = 0; kk &lt;= 1; ++kk) {\n              for (int jj = 0; jj &lt;= 1; ++jj) {\n                  for (int ii = 0; ii &lt;= 1; ++ii) {\n                      amrex::Gpu::Atomic::AddNoRet(&rho(i+ii-1, j+jj-1, k+kk-1, 0),\n                                              sx[ii]*sy[jj]*sz[kk]*p.rdata(0));\n                  }\n              }\n          }\n\n          for (int comp=1; comp &lt; nc; ++comp) {\n             for (int kk = 0; kk &lt;= 1; ++kk) {\n                  for (int jj = 0; jj &lt;= 1; ++jj) {\n                      for (int ii = 0; ii &lt;= 1; ++ii) {\n                          amrex::Gpu::Atomic::AddNoRet(&rho(i+ii-1, j+jj-1, k+kk-1, comp),\n                                                  sx[ii]*sy[jj]*sz[kk]*p.rdata(0)*p.rdata(comp));\n                      }\n                  }\n              }\n          }\n      });\n\n  MultiFab acceleration(ba, dmap, BL_SPACEDIM, 1);\n  acceleration.setVal(5.0);\n\n  nc = BL_SPACEDIM;\n  amrex::MeshToParticle(myPC, acceleration, 0,\n      [=] AMREX_GPU_DEVICE (MyParticleContainer::ParticleType& p,\n                            amrex::Array4&lt;const amrex::Real&gt; const& acc)\n      {\n          amrex::Real lx = (p.pos(0) - plo[0]) * dxi[0] + 0.5;\n          amrex::Real ly = (p.pos(1) - plo[1]) * dxi[1] + 0.5;\n          amrex::Real lz = (p.pos(2) - plo[2]) * dxi[2] + 0.5;\n\n          int i = amrex::Math::floor(lx);\n          int j = amrex::Math::floor(ly);\n          int k = amrex::Math::floor(lz);\n\n          amrex::Real xint = lx - i;\n          amrex::Real yint = ly - j;\n          amrex::Real zint = lz - k;\n\n          amrex::Real sx[] = {1.-xint, xint};\n          amrex::Real sy[] = {1.-yint, yint};\n          amrex::Real sz[] = {1.-zint, zint};\n\n          for (int comp=0; comp &lt; nc; ++comp) {\n              for (int kk = 0; kk &lt;= 1; ++kk) {\n                  for (int jj = 0; jj &lt;= 1; ++jj) {\n                      for (int ii = 0; ii &lt;= 1; ++ii) {\n                          p.rdata(4+comp) += sx[ii]*sy[jj]*sz[kk]*acc(i+ii-1,j+jj-1,k+kk-1,comp);\n                      }\n                  }\n              }\n          }\n      });\n\n  WriteSingleLevelPlotfile(\"plot\", partMF,\n                           {\"density\", \"vx\", \"vy\", \"vz\"},\n                           geom, 0.0, 0);\n\n  myPC.Checkpoint(\"plot\", \"particle0\");\n}\n\nint main(int argc, char* argv[])\n{\n  amrex::Initialize(argc,argv);\n\n  ParmParse pp;\n\n  TestParams parms;\n\n  pp.get(\"nx\", parms.nx);\n  pp.get(\"ny\", parms.ny);\n  pp.get(\"nz\", parms.nz);\n  pp.get(\"max_grid_size\", parms.max_grid_size);\n  pp.get(\"nppc\", parms.nppc);\n  if (parms.nppc &lt; 1 && ParallelDescriptor::IOProcessor())\n    amrex::Abort(\"Must specify at least one particle per cell\");\n\n  parms.verbose = false;\n  pp.query(\"verbose\", parms.verbose);\n\n  if (parms.verbose && ParallelDescriptor::IOProcessor()) {\n    std::cout &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Number of particles per cell : \";\n    std::cout &lt;&lt; parms.nppc  &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Size of domain               : \";\n    std::cout &lt;&lt; parms.nx &lt;&lt; \" \" &lt;&lt; parms.ny &lt;&lt; \" \" &lt;&lt; parms.nz &lt;&lt; std::endl;\n  }\n\n  testParticleMesh(parms);\n\n  amrex::Finalize();\n}"
  },
  {
    "objectID": "posts/amrex/index.html#warpx",
    "href": "posts/amrex/index.html#warpx",
    "title": "Learning AMReX",
    "section": "WarpX",
    "text": "WarpX"
  },
  {
    "objectID": "posts/amrex/index.html#thoughts",
    "href": "posts/amrex/index.html#thoughts",
    "title": "Learning AMReX",
    "section": "Thoughts",
    "text": "Thoughts\nAMR is, from my experience, easier said than done.\nIt would be a pain to build your work upon something that is not easily understandable. I think AMReX beats BATL in every aspect. It has nice documentation, clear syntax, and neat interfaces. I can tell that while BATL is designed by smart scientists, AMReX is motivated by scientific projects and carefully designed by expert programmers. Let us go back a few years and think about history. BATL was written in 2011-2012 before MHD-PIC coulping, which, in my point of view, is clearly motivated by the coupling project. That was actually a really nice time spot when the whole group can switch to OOP and design a general mesh library. Unfortunately, being biased towards pure functional programming and only BATSRUS in mind, we missed that great opportunity. Thus it results in today’s BATL, being fully integrated only for BATSRUS, and not suitable for even multithreads control, let along GPU. AMReX is publicly release in 2017, as a descendant for GUMBO. It was born at a time when all the mainstream massively parallel techiques becomes mature and ready for use. It covers almost all the possibilities in physics simulation using structured grid, which will eventually make it shining over other competitors. I would also say that its developers are really appreciated for making it open source. This is how work done in one group can benefit all other groups and raise fame and honor in the community. Science is not a stand-alone project. With really good fundations we can easily find collaborators and make amazing work.\nAMReX has so many things mentioned in the doc. I will go over the doc first before digging into FLEKS, and try to work on FLEKS later."
  },
  {
    "objectID": "posts/amrex/index.html#julia-wrapper",
    "href": "posts/amrex/index.html#julia-wrapper",
    "title": "Learning AMReX",
    "section": "Julia wrapper",
    "text": "Julia wrapper\nI really want a Julia wrapper over AMReX. There is an experimental project of a Python wrapper, and I also see a shared binary in the Julia registry. But neither of them is functional."
  },
  {
    "objectID": "posts/amrex/index.html#envisions",
    "href": "posts/amrex/index.html#envisions",
    "title": "Learning AMReX",
    "section": "Envisions",
    "text": "Envisions\n\nGo through the tutorials\nThink about how to map the functionalities of BATL to AMReX\nUnderstand the source code structure\nWrite a Julia wrapper for AMReX.\nWrite a new code in the form of a mixture of BATSRUS kernel and AMReX."
  },
  {
    "objectID": "posts/japan/index.html",
    "href": "posts/japan/index.html",
    "title": "仙台之行",
    "section": "",
    "text": "借着到日本开会的机会，我第一次真正走进了这个神奇的国度。在讯息发达和文化融合的今天，称得上陌生的东西不多，但可以思考和观赏的地方也不少。\n会议是由日本东北大学承办的，坐落于东京以北300公里的仙台市。东北大学起家于当年鲁迅先生求学的仙台医学院，而我们前四天的会址就离鲁迅曾经读书的地方相距不过百米。如今的仙台已不是百年前先生读书时的小镇模样，而是更接近一座现代化的中型城市，有百万人口，两线地铁，和成熟的规划。从东京车站乘新干线不过一个半小时，观赏着沿路和中国几分相似的风景，便来到了日本北方的重镇。这里的车牌都是四位数加一个假名，起初我还惊讶于可能的汽车保有量至少；直到我后来意识到假名有50个且车牌颜色也有区别，其实也是足够了。\n日本有三种文字：表音的平假名和片假名，表形的汉字，以及源起于注音的罗马字。假名据说最初是由传入的汉字取其发音简化而来，也是对国人来说最难以理解的部分之一，看得我眼花缭乱。但许多场合都会混着使用汉字，所以连蒙带猜也能估摸出许多指示牌的意思。但另一个令国人头疼的问题，是日文人名地名的汉字与罗马字的对应关系——对于不熟悉日文发音的我们，把表音的罗马字和表意的汉字对应起来又多了一层额外的负担。我曾经问过一个日本友人他们在什么时候会使用对应的文字，他只是笼统地向我描述了一下，并表示这大多只是历史习惯，其实多数时候都可以互相替换。在网上也缺少明确的答案，许多人的回答只是让我笼统地感觉到假名的地位在逐渐升高，而汉字则趋向于成为古典文学一类。有天晚上我在酒店里看电视，一个闯关的娱乐节目里一群人在组队挑战汉字的书写，可见对于全民基本教育世界领先的日本人来说写对汉字也不是件寻常轻松的事。\n传闻中的日本高度发达，老龄化严重，我的直观感受却没有那么深切。倒是从羽田机场出来后问路寻求帮助都受到了极其热情的帮助，给人的第一印象极其舒服。一到东京车站，人来人往车水马龙，即便是周日，穿着西装制服的人们也是络绎不绝，让我切身体会到一丝隐藏的压力。在仙台的周五也赶了一次早高峰，摩肩接踵的地铁和疾行的人流，像极了国内的熟悉场景。不过还是很容易分辨这是日本：所有的通行跟国内都是镜像的，因为他们沿用了英式的习惯；扶手电梯里不会反复播出“靠右站稳，左侧通行”的广播，多年的教化已经在社会中形成了约定俗成的准则。\n高度发达的现代社会有几个标志性的事物，而提起日本，就不得不提便利店这一现代城市的产物。即便在仙台这样大概规模排名第十的日本城市，哆啦A梦里面刚田家的杂货铺也已不复存在，取而代之的便是无处不在的便利商店。传说中的三大巨头7-11，Lawson和Family Mart，在我的视觉上反映出的可能更是7-11一家独大的态势。这些24小时营业的便利店，对成长在深圳的我来说熟悉又陌生，又切实地解决了开会期间早餐和夜宵的问题，想起来也是极其满意的。那些熟悉的面包卷、三文治和泡面的味道，可以说是这座城市的温情，亦或者解读成都市淡漠的人情。我的确没有见到早餐铺上飘来的阵阵香气，也不见任何小贩沿街的吆喝叫卖声。那都是古老的记忆，已不再属于现在的仙台。但对我来说，比之美式的“荒漠”，这里已足够欣喜。\n绕不过的话题当然是吃。我满载期待而来，兴尽之余满足之情仍溢于言表。从小我便喜欢日本料理；即便到了美国，约莫每两周总有一顿仍是日料。国内的日料总体要优于美国的日料，也不存在植根于美国的本土化衍生产品酱汤和姜丝沙拉。但真到了日本，我算是见识了什么是真正的日料。如果用一个字概括，那毫无疑问，就是“鲜”。第一顿午餐，东北大学的餐厅，日式的食堂有着便宜而精致的风味。到晚上，吃到了可能是目前为止我品尝过的最浓郁的豚骨拉面。一碗不到1000yen，虽然只有两片猪肉，但是汤底、豆芽、葱绿和主料的拉面，都是顶级的口感。汤底中加上了咸蛋黄，有近一步促进浓郁的效果。据张公子转述日本拉面的汤底无外乎是昆布和鱼，加上猪骨一类；但要论对品质的把控，果然还是日本人最为重视。就譬如再次造访东北大学的食堂时，那生鲜的番茄，整颗置于一小碟中，只片四份，真是令人回味无穷。在日本蔬菜是精贵的东西，政府为了保护本国农业，大大拉高了进口蔬菜的关税，直接或间接扶持了相当部分的本国农产品。小而精，说日本农业，一点也不过誉。就凭这偶然碰到的大学食堂里的番茄，洗净生食；在很多地方，哪有这样的魄力和自信，把食物就这么简单地端到食客的面前？更不要提在松岛町品尝的牛舌定食，那真是神仙滋味。如果问我此行珍馐之最，这家海边的牛舌小店当之无愧，也不枉我步行15分钟等候半个小时。当然，有对比才有层次感：同样是牛舌，在安娜堡Seoul Garden的风味远远不及，在主办方当地闹市区的晚宴中呈上的大盘亦是远远不及。那顿晚宴唯一的亮点在于清酒烧酒梅酒的百花齐放，若是论菜品质量，估计店里的伙计也没见识过这么大的阵仗，一通手忙脚乱之下连牛舌也煎得老气横秋。\n最后一晚，我们密歇根几人相聚一地下居酒屋（Isakaya），体验了把地道的日式聚餐。食物中除了大家都不甚能接受的纳豆，其余都是水准之上。那款纳豆被包裹在豆腐里炸制，味道诡异却在我看来远不如臭豆腐的香。Abby强推的毛豆制品Zunda（毛豆沙糕）也是惊喜之作，无论是与大福相伴或是与巧克力相融，都能呈现出圆润的滋味。令人颇为惊奇的是居酒屋内竟然允许吸烟，日本人的聚会场所果然还是要允许一些奔放的东西存在。\n整洁、干净，这一点无论在东京、横滨还是仙台都是如一的。我没有在街上见过环卫工人，不知道他们到底是如何保持街道的整洁的；但那日在地铁站出口注意到一位拿着吸尘器一丝不苟地清理角落里的灰尘的大叔，至少印证了日本人对干净的极致追求。在松岛町的神社附近散步时，无论是山腰的墓碑还是居民住房前后的街道，那种规整和干净，是现代人类文明的杰出代表。人不是为了活着而活着，而是为了某种追求而活着。那些房屋也谈不上多精致漂亮，但是干练、素雅。而如果上升到了某些信仰上的追求，体现在瑞严寺内的装潢遍可见一斑。这是松岛町内日本国宝级的寺庙，古松参天，主体建筑全悉木制，入寺须拖鞋，踩在一块块木板上只呀作响，却似不落纤尘。那房梁上的雕花，室内屏风纸门的版画，每一小块，估计都要花费一位精湛工匠少则数十日多则半年记的时光。寺庙各处皆是活动的板门，透气通光，随处即是养心修禅的良所。还有室外石窟下的佛像和展览室里的墨宝，所有的一切汇聚在一起，与国内众多烧香求佛的沸腾之地拉开了境界上的差距。此心安处是吾乡，切切实实、肌肤之感。\n很多小方面也体现出日本的特色。譬如那无处不在的雨伞架，以及众多空置的雨伞，可能是人们遗忘的，也可能是故意剩下的；众多换汇、卖票的结算场所都有老式的计算器，纵使再先进的电脑似乎用起来也不如这简单的计算器顺手。他们会把计算器面朝着顾客，然后在你面前飞速地敲击键盘——这阵仗，我是又惊又怵，其实无论她敲出什么数字估计我都认账。还有东京随处可见的乌鸦，日本国鸟级的待遇，集祥瑞与恐惧于一身，神秘莫测。最后，也是我此行最费解和不满的地方，就是现金。都已经2019年了，到处还是仅收现金，作为发达国家，真是不及格的方面。离开日本前有几个小时的时间，到达东京后本想就近到国立艺术馆或是科技馆逛一逛，可哪知堂堂国立的展览馆竟然仅收现金，让拖着行李箱绕着日本皇居走了半个小时而来的我气得直跳脚。早知如此，我还不如到车站北边不远处的东京大学走一遭呢。社会的发展总有不尽如人意的地方，而在思考中改变和提高，是世界范围内不变的主题。\n于是乎，我结束了为期一周的日本行，又坐着加拿大航空的头牌航线返回了美国。那些惊艳与遗憾，都留待着日后重新发掘。我没有接着玩，其实也是有原因的。希望下次，能与你一同前来。"
  },
  {
    "objectID": "posts/oop/index.html",
    "href": "posts/oop/index.html",
    "title": "Object Oriented Programming",
    "section": "",
    "text": "Since the 1990s, the idea of object oriented programming is prevailing in the science community. Scientists had started to code in Fortran in the 1960s, and later in C, and later in C++.\nThe requirements for a general physics code can be summarized as follows:\n\nCapability to accurately model the physical phenomena of interest.\nExtensibility and reusability for adding new models or modifying existing models.\nEncapsulation of algorithms to localize the impact of code modifications.\nEfficiency of algorithms and architecture, including optimization of speed and storage.\nFatal error trapping to prevent user-induced crashes, including unstable regimes of operation.\nError trapping or warning for simulation regimes characterized by inaccuracy.\n\nThere are some common drawbacks with the legacy structured codes:\n\nOveruse of the error-prone and low-efficiency global variables.\nLimited capability of including new schemes and extending the current model.\n\nI am not a fanatical suitor of the C++ style class type OOP. One thing that is often annoying to me is when someone provide a very complicated class and say “hey, take a look at this fancy world I’ve built for you”. Yes, indeed, it may be powerful, but the learning curves are deep and there are many functionalities that I don’t necessarily need. It would be so much better if someone can provide me with a clean implementation of the definition of the object, and let me play with it without bothering the intrinsic provided methods.\nWe all need the idea of OOP to a certain degree. For example, a PIC code nowadays is often considered well-organized if there are objects of particles, fields; a visualization toolkit should have basic triangles and tetrahedrons defined to start with. However, as a “hacker” to other’s code without knowing the complete picture, is it possible for me to simply take the part I need and run?\nThis is hard in C++, but relatively easy in Julia. There are several reasons behind:\n\nC++ codes are typically huge, with the information one wants buried in the tens of thousands of lines.\nThe polymorphism and dependency of the C++ class sometimes make it hard to quickly get something to work, especially for the outsiders.\nTypically C++ classes methods are more difficult to interpret than the equivalent functions.\nYou may even fail to compile the C++ code in the first place. Contrarily, you can see the results and errors on-the-go with Julia.\n\nOne key feature of Julia is multiple dispatch. Instead of focusing on objects, we can focus on methods, or operations. In other words, instead of focusing on nouns, we can focus on verbs. I can easily imagine the AMReX or VTK library being rewritten in Julia, without too much headache, for someone in the future to sneak out with the part of interest and reuse in his or her own code."
  },
  {
    "objectID": "posts/oop/index.html#thoughts-about-oop",
    "href": "posts/oop/index.html#thoughts-about-oop",
    "title": "Object Oriented Programming",
    "section": "",
    "text": "Since the 1990s, the idea of object oriented programming is prevailing in the science community. Scientists had started to code in Fortran in the 1960s, and later in C, and later in C++.\nThe requirements for a general physics code can be summarized as follows:\n\nCapability to accurately model the physical phenomena of interest.\nExtensibility and reusability for adding new models or modifying existing models.\nEncapsulation of algorithms to localize the impact of code modifications.\nEfficiency of algorithms and architecture, including optimization of speed and storage.\nFatal error trapping to prevent user-induced crashes, including unstable regimes of operation.\nError trapping or warning for simulation regimes characterized by inaccuracy.\n\nThere are some common drawbacks with the legacy structured codes:\n\nOveruse of the error-prone and low-efficiency global variables.\nLimited capability of including new schemes and extending the current model.\n\nI am not a fanatical suitor of the C++ style class type OOP. One thing that is often annoying to me is when someone provide a very complicated class and say “hey, take a look at this fancy world I’ve built for you”. Yes, indeed, it may be powerful, but the learning curves are deep and there are many functionalities that I don’t necessarily need. It would be so much better if someone can provide me with a clean implementation of the definition of the object, and let me play with it without bothering the intrinsic provided methods.\nWe all need the idea of OOP to a certain degree. For example, a PIC code nowadays is often considered well-organized if there are objects of particles, fields; a visualization toolkit should have basic triangles and tetrahedrons defined to start with. However, as a “hacker” to other’s code without knowing the complete picture, is it possible for me to simply take the part I need and run?\nThis is hard in C++, but relatively easy in Julia. There are several reasons behind:\n\nC++ codes are typically huge, with the information one wants buried in the tens of thousands of lines.\nThe polymorphism and dependency of the C++ class sometimes make it hard to quickly get something to work, especially for the outsiders.\nTypically C++ classes methods are more difficult to interpret than the equivalent functions.\nYou may even fail to compile the C++ code in the first place. Contrarily, you can see the results and errors on-the-go with Julia.\n\nOne key feature of Julia is multiple dispatch. Instead of focusing on objects, we can focus on methods, or operations. In other words, instead of focusing on nouns, we can focus on verbs. I can easily imagine the AMReX or VTK library being rewritten in Julia, without too much headache, for someone in the future to sneak out with the part of interest and reuse in his or her own code."
  },
  {
    "objectID": "posts/oop/index.html#section",
    "href": "posts/oop/index.html#section",
    "title": "Object Oriented Programming",
    "section": "",
    "text": "More thoughts about OOP in the region of CFD. Generality requires:\n\nnumerical schemes, as an individual module, works for most but not all grid structure\ndifferent grid structures, including structured, unstructured, 1D/2D/3D, curved boundary\nuniform treatment of source terms\nIO formats\ndifferent paradigms of parallelization\n\nUltimately, what you want is whenever you see an equation with generic terms like several derivatives, cross product, etc., you can quickly solve it numerically in the region you want."
  },
  {
    "objectID": "posts/oop/index.html#section-1",
    "href": "posts/oop/index.html#section-1",
    "title": "Object Oriented Programming",
    "section": "",
    "text": "One specific reason I don’t like the design of BATSRUS, a module-based Fortran code, is that most functions are not pure. This means that more often than not a key function call involves modifying variables not being passed as arguments. This may be ok for writing the code, but bad for reading. To a certain degree, C++ class functions have the similar behavior, but you know everything is at least within a class object, as contrary to module usage in Fortran where you can literally dump one module into another without even noticing."
  },
  {
    "objectID": "posts/oop/index.html#closing-remarks",
    "href": "posts/oop/index.html#closing-remarks",
    "title": "Object Oriented Programming",
    "section": "Closing Remarks",
    "text": "Closing Remarks\nLearn from the past and step forward."
  },
  {
    "objectID": "posts/data-transfer/index.html",
    "href": "posts/data-transfer/index.html",
    "title": "Data Transfer",
    "section": "",
    "text": "scp: fast, straightforward, speed shown by default.\nrsync: good for avoiding duplicate file transfer, or in other words, transferring files on-the-go.\n\n-z: compress/uncompress file data before/after transferring.\n-a: archive mode, which allows copying files recursively and it also preserves symbolic links, file permissions, user & group ownerships, and timestamps. This is important when you try to synchronize the data, as timestamp difference is also taken into account.\n-v: verbose\n\nrclone: good for cloud service, or transfer data between storage and compute nodes."
  },
  {
    "objectID": "posts/mac-setup/index.html",
    "href": "posts/mac-setup/index.html",
    "title": "Mac Setup",
    "section": "",
    "text": "Part of this post originates from Dan Welling’s article Your Mac as a Linux Box."
  },
  {
    "objectID": "posts/mac-setup/index.html#background",
    "href": "posts/mac-setup/index.html#background",
    "title": "Mac Setup",
    "section": "Background",
    "text": "Background\nIn the late 90s, MacOS - the operating system used on Macintosh computers - had become a bloated, clumsy mess. Apple’s solution was to turn to Unix-based technology developed by the NeXT company (founded by Steve Jobs during his “sabatical” from Apple). The result was the now widely used OS X, the most widely used operating system outside of Microsoft’s Windows platforms. Because OS X is, at its core, a Unix system, it was quickly adopted by (amongst others) scientists who need both the open-source and command line capabilities of Unix/Linux systems, but also need access to popular point-and-click programs such as MS Office, MATLAB, and others. OS X is therefore the “best-of-both-worlds” for scientists.\nThe move from a traditional Linux systems to OS X comes at a price, however. Apple insists on several non-standard implementations of languages (e.g., python), window managers, and file system layouts. This means that to unlock the full Unix/Linux-like capability of your Mac, you need to do a bit more setup work. This guide attempts to get you set up so that you can start coding like a Linux pro!\nNote that this process will take time. Getting software, installing packages, and getting up-and-running requires plenty of time to download and compile libraries and packages. Make sure you’re ready before you start."
  },
  {
    "objectID": "posts/mac-setup/index.html#accessing-the-terminal",
    "href": "posts/mac-setup/index.html#accessing-the-terminal",
    "title": "Mac Setup",
    "section": "Accessing the Terminal",
    "text": "Accessing the Terminal\nFor some historical reason (ok, it’s just IDL…), my group at Michigan prefers X11 on Mac, or more precisely XQuartz, for accessing GUIs from the command line locally and remotely. I have suffered from it for years and glad to see that it is not necessary anymore for many newer programs and machines. Given the fact that the default shell on latest Mac now is zsh, just ignore the other options."
  },
  {
    "objectID": "posts/mac-setup/index.html#editing-the-configuration-file",
    "href": "posts/mac-setup/index.html#editing-the-configuration-file",
    "title": "Mac Setup",
    "section": "Editing the Configuration File",
    "text": "Editing the Configuration File\nStart from the popular recommendation and build your own upon it. Be careful about the PATHs: many newcomer issues happen when searching paths are not set appropriately!"
  },
  {
    "objectID": "posts/mac-setup/index.html#sudo-access",
    "href": "posts/mac-setup/index.html#sudo-access",
    "title": "Mac Setup",
    "section": "Sudo Access",
    "text": "Sudo Access\nSince this is in the Unix world, you need to eventually become familiar with sudo access. Checkout the many useful tutorials online, or just start with sudo -h."
  },
  {
    "objectID": "posts/mac-setup/index.html#package-management",
    "href": "posts/mac-setup/index.html#package-management",
    "title": "Mac Setup",
    "section": "Package Management",
    "text": "Package Management\nSoftware installation is, in general, a pain. On a Mac, typically, people recommend MacPorts and HomeBrew for installing depedencies. Also note that the MPI library and other possible dependencies must also be compatible with your choice of installation.\nFor example, at some point you may need to install the “real” gcc compilers (not the wrapper over clang) on you Mac. For sure you can download the source code and do a native installation, but it is just, hard. Package management tools are your best friends here. I will only talk about MacPorts, as I have little experience with HomeBrew. It’s easy to install gcc on Mac with MacPorts:\nsudo port selfupdate\nsudo port install gcc10\nsudo port install openmpi-gcc10\nIf you don’t want the old versions, simply uninstall them:\nport contents openmpi-gcc9\nsudo port uninstall openmpi-gcc9\nAfter everything looks good, you need also remember to set the correct link in /opt/local/bin:\nsudo ln -s gfortran-mp-10 gfortran\nsudo ln -s gcc-mp-10 gcc\nsudo ln -s g++-mp-10 g++\nFind the tools that suit your needs. If you find something better, then just use it. For instance, my advisor recommended tkdiff for comparing the differences between two files: honestly it is pretty good, but I have abandoned it because the built-in text comparing tool in VSCode is simply better. However, some tools like latexdiff (which is written in Perl) is amazingly good and I have not seen any competitors for the job."
  },
  {
    "objectID": "posts/mac-setup/index.html#epilogue",
    "href": "posts/mac-setup/index.html#epilogue",
    "title": "Mac Setup",
    "section": "Epilogue",
    "text": "Epilogue\nWorking from the command line is immensely powerful and becomes second nature the more you use it. It’s not without its issues, though, so be ready for more challenges. The trend I have seen for the recent years being that every popular platforms adopt their way to connect to the Linux world, including Windows with the Windows SubLinux system (WSL2). It seems more likely that people in the future will code with remote access to the actual machines, so then you won’t even bother with the tedious configurations with every new machine. In the end, it is an excellent way to get science done as efficiently as possible."
  },
  {
    "objectID": "posts/passing-arguments/index.html",
    "href": "posts/passing-arguments/index.html",
    "title": "Passing Arguments",
    "section": "",
    "text": "The design of high level program structures is very challenging. One common headache for me is how to pass arguments between function efficiently."
  },
  {
    "objectID": "posts/passing-arguments/index.html#case-1",
    "href": "posts/passing-arguments/index.html#case-1",
    "title": "Passing Arguments",
    "section": "Case 1",
    "text": "Case 1\nSay you are implementing a module for handling boundary conditions for a CFD code. As the code becomes more and more complicated, you will need to select between a bunch of available methods. From the user side, he or she only needs to write down the wanted BC in the input file as a string, and the code should automatically select the right BC. However, since most users will only use a limited amount of BCs, we as programmers should avoid any variables from one BC being set or used if it is not called by the user. On a high level, we implement this unified API:\nset_boundary(arguments)\nand on the lower level, we need to call different functions for different BCs based on the input arguments:\nif arguments[1] = 'a'\n   set_bc_1()\nelseif arguments[1] = 'b'\n   set_bc_2()\nend\nThen here comes the problem: if there is one BC that needs a special input argument, e.g. time, how do you pass it? The simplest solution would be pass all the special argument through the top level function one-by-one. But if as you have more and more complicated BCs, the list of input arguments will just go crazy.\nAn OOP solution would be: on the high level API, there is only one argument that determines which class of methods to use; inside the low level function, you set all the required variables as needed. In other words, instead of passing needed variables, we seek global variables as needed. The general BC can be defined as an abstract class, and each specific BC can be defined as derived/extended class."
  },
  {
    "objectID": "posts/rust/index.html",
    "href": "posts/rust/index.html",
    "title": "Rust",
    "section": "",
    "text": "Rust是我一直想了解的语言；唯一的障碍可能就是即使会了一些Rust，短期内看不到哪里能够实际用上。然而学习一门新东西，并不总能立刻看到用途的。"
  },
  {
    "objectID": "posts/rust/index.html#入门",
    "href": "posts/rust/index.html#入门",
    "title": "Rust",
    "section": "入门",
    "text": "入门\n官方的一本书和一套练习册足够好，不需要再去找第三方资料了。\n\n安装和运行\n\n异常丝滑，这是传统C/C++生态圈无法比拟的。\nHello world可执行文件只有几兆，匹敌所有编译语言。\n所有依赖统一由Cargo管理，不存在找不到的问题。\nCargo自带了编译和运行功能，相当于集成了Make。\n\n\n\nCore features\n\nRust has a strong, static type system. However, it also has type inference. Every type must be known at compile time.\nRust allows shadowing of variables.\nOwnership is a key concept to the language.\n\nEach value in Rust has a variable that’s called its owner.\nThere can only be one owner at a time.\nWhen the owner goes out of scope, the value will be dropped.\n\nZero-based indexing.\nIn function signatures, you must declare the type of each parameter.\nDistinguished expression and statement.\nRust will never automatically create “deep” copies of data.\nReferences (&) refer to some value without taking ownership of it.\n\nAt any given time, you can have either one mutable reference or any number of immutable references.\nReferences must always be valid.\n\nRust deliberately avoids the concept of null for safety.\nTraits are Rust’s way of doing generic programming.\nMatches are exhaustive: we must exhaust every last possibility in order for that code to be valid.\nIterators\nClosures\nAutomatic referencing and dereferencing, so the equivalent of -&gt; operator in C++ is not needed.\nLifetimes\n\nElision rules:\n\nEach parameter that is a reference gets its own lifetime parameter.\nIf there is exactly one input lifetime parameters, that lifetime is assigned to all output lifetime parameters.\nIf there are multiple input lifetime parameters, but one of them is &self or &mut self because this is a method, the lifetime of self is assgiend to all output lifetime parameters.\n\n\n\n\n\nRecommended convention\n\nAll whitespaces, no tags.\nWhitespace between curly braces.\nOpening curly brace on the same line.\nAll uppercase with underscores between words for constants.\nSnake case for function and variable names.\nSpecify the parent module when calling the function to make it clear that the function isn’t locally defined.\nSpecify the full path when bringing in structs, enums, and other items with use.\nCamelCase for types."
  },
  {
    "objectID": "posts/rust/index.html#项目",
    "href": "posts/rust/index.html#项目",
    "title": "Rust",
    "section": "项目",
    "text": "项目\n项目和语言之间是相辅相成的关系：快速搭建的、成熟的项目框架是语言成熟落地的标志。\n\nplotters\n官方绘图库，自己吹得天花乱坠，仍在开发阶段。但值得关注。\n\n\nTauri\n这几年采用网络技术开发桌面应用的Electron项目很火，包括我经常使用的Visual Studio Code在内很多大项目都是基于Electron框架开发的。而基于Rust从零开始开发的跨平台竞品Tauri，能把Linux版本的installer大小砍到1/12，内存使用砍到1/2.5，启动时间砍到1/2。所有的新东西诞生的目的就是为了弥补前一代的缺陷，包括Rust本身也一样。基于一个基本想法，带领一个技术潮流。我愿意看到更多Rust项目挑战存在几十年的C++生态圈。"
  },
  {
    "objectID": "posts/rust/index.html#个人体验",
    "href": "posts/rust/index.html#个人体验",
    "title": "Rust",
    "section": "个人体验",
    "text": "个人体验\n这套关于堆上面的拥有和变量借贷的逻辑一开始需要一段时间适应，但适应了以后会觉得事情本该如此。回想多少次因为莫名其妙的内存问题导致的segmentation fault，Rust诞生的初衷，就是再也不想在运行时看到这些错误了。\nRust的type inference和Julia的师出同门，和C++的auto也类似。而更进一步，Rust中绝大部分时候变量的lifetime也是inferred,而Julia中是garbage collected，C++中则全是程序员的责任。在某些情况下，Rust compiler需要程序员帮忙才能分析出输入输出的lifetime，这就引入了大部分别的语言没有的lifetime annotations。\n我扫了一眼Rust的2021中文年度报告，至少在工业界，Rust的普及程度远高于Julia，并且思考下来目前为止由于缺乏静态编译能力，Julia没有任何可能超越Rust。坦诚地说，如果我同时精通二者，我会选择Rust作为核心库的创建基础，而Julia作为前端封装的部分替代Python的功能。\n从Python和JIT技术的一路演化中我们了解到，目前的编译器对于底层和上层的接口处的优化几乎是无能为力的——这也是为什么Chris曾经花了很大篇幅试图说明为什么Numba注定会是个失败的项目。我看到了一种未来的可能性，就是在编译器的IR部分打通语言之间的界限，让跨语言的优化成为可能。\n张汉东,2021年Rust年度报告的作者，写道： &gt; Rust的出现并不是要你去用它重写一切，而是希望你可以用它创造新的未来。 &gt; We choose to use Rust, not because it is easy, but because it is hard, because that goal will serve to organize and measure the best of our energies and skills, because that challenge is one that we are willing to accept, one we are unwilling to postpone, and one which we intend to win, and the others, too."
  },
  {
    "objectID": "posts/debugger/index.html",
    "href": "posts/debugger/index.html",
    "title": "Debugger",
    "section": "",
    "text": "One way of debugging segmentation fault is using GDB. It is such a deep learning curve that no one ever claims he or she fully understands the complete usages. Here is just my experience of debugging a C++ code with GDB."
  },
  {
    "objectID": "posts/debugger/index.html#compilation",
    "href": "posts/debugger/index.html#compilation",
    "title": "Debugger",
    "section": "Compilation",
    "text": "Compilation\nThe most important compilation flag is -g: this enables the program to store information that can be used when backtracing. Nowadays often you don’t need to turn off many compilation flags. For safety, use -O0; if you want to give it a try, use -O2."
  },
  {
    "objectID": "posts/debugger/index.html#debugging",
    "href": "posts/debugger/index.html#debugging",
    "title": "Debugger",
    "section": "Debugging",
    "text": "Debugging\nIf you set ulimit -c unlimited, the program is allowed to use all the available resources in the current platform. Therefore Core dump files can be generated at runtime. Core files are created when a program encounters a run-time error. It is an image of the memory used by the program, and debuggers such as gdb can access it to find out the state of the program at the time of the error.\nThen we can enter GDB REPL by\ngdb executable core\nand type bt or backtrace to see the lines of codes that crash. Note that line numbers display is a magic, and I rarely get the luck to see it. However, there is a higher chance that you can see the variable or function name instead of question marks or hexacodes."
  },
  {
    "objectID": "posts/debugger/index.html#parallel-debugging",
    "href": "posts/debugger/index.html#parallel-debugging",
    "title": "Debugger",
    "section": "Parallel Debugging",
    "text": "Parallel Debugging\nAt least Intel MPI libraries allow\nmpirun &lt;mpi options&gt; -gdb program.exe"
  },
  {
    "objectID": "posts/debugger/index.html#remarks",
    "href": "posts/debugger/index.html#remarks",
    "title": "Debugger",
    "section": "Remarks",
    "text": "Remarks\nIt is relatively easy to deal with memory errors in simple codes. However, for more complicated codes, you can easily get lost in the data structures and pointers. Read the code if you can to learn the basic ideas. Then use a development tool such as VTune to do a systematic check if you have time.\nIf you run gdb directly at runtime, you may encounter many false-positives in memory issues, and the real problem will be buried underneath. This is not ideal for debugging."
  },
  {
    "objectID": "posts/debugger/index.html#other-resources",
    "href": "posts/debugger/index.html#other-resources",
    "title": "Debugger",
    "section": "Other Resources",
    "text": "Other Resources\nCheck out other tutorials on this topic!"
  },
  {
    "objectID": "posts/modern-cpu/index.html",
    "href": "posts/modern-cpu/index.html",
    "title": "The Effectiveness of Modern CPUs",
    "section": "",
    "text": "While watching this Cppcon 2021 video\nI learned many things from a low-level hardware perspective."
  },
  {
    "objectID": "posts/modern-cpu/index.html#loop-unrolling",
    "href": "posts/modern-cpu/index.html#loop-unrolling",
    "title": "The Effectiveness of Modern CPUs",
    "section": "Loop Unrolling",
    "text": "Loop Unrolling\nI realized why loop unrolling is a trick in speeding up the performance. Modern CPUs are extremely efficient in arithmetic instructions, that even register operations cannot compete, let along the levels of memory caches. This means that in practice in a loop like\nfor(i=0; i&lt;N; i++){\n   a1[i] += b1[i] + b2[i]\n   a2[i] += b1[i] - b2[i]\n}\ncosts nothing for an extra line as long as the required data has been fetched into the register.\n\nHardware Loop Unrolling\nBe careful of the difference between compiler unrolling and hardware unrolling. Even after the machine code has been generated, it may still not show any unrolling. However, the next stage of the pipeline can still run even if the registers are still in use. Here is where the concepts of physical registers and conceptual registers come into play, and the result is hardware loop unrolling, also potentially out-of-order execution."
  },
  {
    "objectID": "posts/modern-cpu/index.html#branch-prediction",
    "href": "posts/modern-cpu/index.html#branch-prediction",
    "title": "The Effectiveness of Modern CPUs",
    "section": "Branch Prediction",
    "text": "Branch Prediction\nCPUs try to predict the future from the past for branches. If most predictions are true, then great, you save a lot of time checking the dead-end part. However, if a certain amount of predictions are wrong, you pay for a price, sometimes even more than normal checking. The analogy is like while in a game you try to be smart to take the risk, but it turns out that all your previous effort goes to the trash can.\nHere are some practical ratios. An efficient branch predictor usually has less than 1% of branch-misses; when this ratio increases to 10%, it slows down the code quite a bit (6x in the presenter’s demo case!).\nOne funny story that happened in the past was one of the CPU vendors once had a branch predictor worked exactly the opposite as to what one expected. For this particular CPU, you could increase the performance by an order of magnitude if you act in a way to shut down the predictor.\nDo not try to be smarter than the predictor. It can learn complex patterns that are difficult for humans to detect, especially that nowadays machine learning techiques have been adapted to these architectures.\nAlmost all ways to remove branches end up in more computations, so there is a trade-off. One trick that is commonly seen in Python/MATLAB/Julia is to use booleans as indexes. This improves performance if\n\nextra computations are small\nbranch is poorly predicted\n\nAnd the most important take-away message: always measure your performance with the powerful profilers before blindly trusting your judgement!"
  },
  {
    "objectID": "posts/programming-evolution/index.html",
    "href": "posts/programming-evolution/index.html",
    "title": "Evolution of Programming",
    "section": "",
    "text": "In the 20th century as a programmer, you have to learn and write machine code. In the 21st century, it is no longer the case.\nNow you need to learn how to write do loops; in the future you may only need map and reduce."
  },
  {
    "objectID": "posts/programming-evolution/index.html#automating-resource-management",
    "href": "posts/programming-evolution/index.html#automating-resource-management",
    "title": "Evolution of Programming",
    "section": "Automating Resource Management",
    "text": "Automating Resource Management\nQuoted from Guy L. Steele Jr.’s talk at Strange Loop in 2011.\nKeep adding levels of abstractions:\n\nCoding in octal or decimal\n\nOriginal form, write strings\n\nAssemblers\n\nNames for instructions\nNo longer care about the actual numerical values\n\nRelocating assemblers and linkers\n\nCompiler is allowed to move instructions within memory and link them together\nNo longer care about where in the memory the program is placed\n\nExpression compilation\n\nNo longer care about the order of in which instructions are coded\n\nRegister allocation\n\nAutomated by the compiler\n\nStack management of local data\n\nAutomated by the compiler\n\nHeap management\n\nNo longer care about where my data is at\n\nVirtual memory / address remapping"
  },
  {
    "objectID": "posts/programming-evolution/index.html#next-level-of-parallel-programming",
    "href": "posts/programming-evolution/index.html#next-level-of-parallel-programming",
    "title": "Evolution of Programming",
    "section": "Next Level of Parallel Programming",
    "text": "Next Level of Parallel Programming\n\nThe best way to write parallel applications is not to have to think about parallelism.\n\nNeed for separation of concerns\n\nThe issue is not so much parallelism as independence.\nAccumulators are BAD. Divide-and-conquer is GOOD.\nCertain algebraic properties are very important.\n\nAssociative: grouping doesn’t matter\nCommutative: order doesn’t matter\nIdempotent: duplicates don’t matter\nIdentity: this value doesn’t matter\nZero: other values don’t matter\n\nFor debugging, reproduceability is extremely important.\n\nWorth sacrificing performance for\n\n\nWe need a different mindset for parallel prgramming:\n\nGood sequential code minimizes total number of operations.\nGood parallel code often performs redundant operations to reduce communications.\nGood sequential algorithms minimizes space usage.\nGood parallel code often requires extra space to permit temporal decoupling.\nSequential idioms stress linear problem decomposition, i.e. process one thing at a time and accumulate results.\nGood parallel code usually requires multiway problem docomposition and multiway aggregation of results.\n\nThink about map, reduce in the last bullet point.\nGuy proposed a language level parallel paradigm where\n\nprogrammers define your data structures and methods;\nprogrammer ensure to the compiler that your data structures and methods maintains certain properties like associativity and commutativity;\nthe compiler decides if it is possible to apply a parallel execution given the available resources on the fly.\n\nInvariants give the implementation wiggle room, i.e. the freedom to exploit alternate representations and implementations. In particular, associativity gives implementations the necessary wiggle room to use parallelism—or not—as resources dictate.\nSo, in general, he envisioned an automated parallelism management. Brilliant!"
  },
  {
    "objectID": "posts/version-control/index.html",
    "href": "posts/version-control/index.html",
    "title": "Git Version Control",
    "section": "",
    "text": "I haven’t considered myself a programmer until very recent years. As a proof of that, 2017/08/28 is the first day I use Git. My experience of using a version control system started with CVS, a centralized management tool. Before mid 2019, our research group were using CVS for version control. The adopted concept is that there is one and only one branch on the server, and everyone commits to that. This is good for maintainence within a few people. Back in 2005, Linus Torvalds, the creator of Linux, created Git in a very special scanerio: the Linux kernel community could no longer use their revision control system BitKeeper and no other Source Control Management (SCMs) met their needs for a distributed system. Linus took the challenge into his own hands and disappeared over the weekend to emerge the following week with Git. In the same year, he made a interval talk at Google to explain his motivation.\nTime proves Linus was right. Nowadays, Git the go-to option for revision control. Quoted from his own word: &gt; I think that many others had been frustrated by all the same issues that made me hate SCM’s, and while there have been many projects that tried to fix one or two small corner cases that drove people wild, there really hadn’t been anything like git that really ended up taking on the big problems head on. Even when people don’t realize how important that “distributed” part was (and a lot of people were fighting it), once they figure out that it allows those easy and reliable backups, and allows people to make their own private test repositories without having to worry about the politics of having write access to some central repository, they’ll never go back.\nI happen to know somebody who is strongly against Git but have to give up the fight and use it instead. However, if your workflow philosophy does not change, you won’t touch the true power of git. So, what is wrong with CVS? By far the cleanest explanation I find is from Zack Brown: &gt; There were many complaints about CVS though. One was that it tracked changes on a per-file basis and didn’t recognize a larger patch as a single revision, which made it hard to interpret the past contributions of other developers. There also were some hard-to-fix bugs, like race conditions when two conflicting patches were submitted at the same time.\nCVS is really terrible when I want to reorganize the whole directory or the Internet connection is off. Besides, I have some other opinions. The key concept behind Git is its distributed storage. I’ll make a bet that if you are a truly open-source person, you will love this idea.\nSo now when you go back and revisit this story of Git, you can feel the importance of vision for the future. New things are born because we are tired of the old ones. The popularity of Git and its workflow has a reason.\nBy the way, for a serious project, NEVER push directly to the master branch. There are all kinds of tool to do automated testing before you are confident about the changes.\nWith all that being said, git is still not perfect. Recently I was confused about the usage of git rebase, so I did a search on the topic. Both merge and rebase are used for merging branches, but the differences are summarized here. Based on my current understanding, rebase is better than merge for local unpublished commits; rebase may create a disaster in conflicts if being used on commits that are already pushed/shared on a remote repository!1"
  },
  {
    "objectID": "posts/version-control/index.html#adding",
    "href": "posts/version-control/index.html#adding",
    "title": "Git Version Control",
    "section": "Adding",
    "text": "Adding\nThe first principle of commits is one thing at a time. For instance, if you have two independent changes in a file, the basic git -add file will list both changes togther. A more advanced way is git add -p file: this allows you to go through all the changes and decide whether they belong to the same topic!"
  },
  {
    "objectID": "posts/version-control/index.html#renaming",
    "href": "posts/version-control/index.html#renaming",
    "title": "Git Version Control",
    "section": "Renaming",
    "text": "Renaming\nOften git may get confused about renaming files. Check this StackOverflow discussion and the trick of using git log --follow in Follow the History of renamed files.\nThe important thing to know is that internally git does not have the concept of renaming: it only knows deleting and adding. A more thorough explanation can be found here. In most common cases, when you try to reorganizing your code, consider separate the renaming stage and content modification stage."
  },
  {
    "objectID": "posts/version-control/index.html#squashing",
    "href": "posts/version-control/index.html#squashing",
    "title": "Git Version Control",
    "section": "Squashing",
    "text": "Squashing\nGenerally it is better to squeeze small commits before merging, especially in a PR. Take a look at this post Combining multiple commits before pushing."
  },
  {
    "objectID": "posts/version-control/index.html#finding-regression",
    "href": "posts/version-control/index.html#finding-regression",
    "title": "Git Version Control",
    "section": "Finding regression",
    "text": "Finding regression\ngit bisect is a great tool for finding regression. Check how to use git bisect."
  },
  {
    "objectID": "posts/version-control/index.html#blaming",
    "href": "posts/version-control/index.html#blaming",
    "title": "Git Version Control",
    "section": "Blaming",
    "text": "Blaming\ngit blame shows the modification history of a file. There are now built-in GUI supports on GitHub and GitLab."
  },
  {
    "objectID": "posts/version-control/index.html#deleting-a-branch",
    "href": "posts/version-control/index.html#deleting-a-branch",
    "title": "Git Version Control",
    "section": "Deleting a branch",
    "text": "Deleting a branch\nHow to delete a branch"
  },
  {
    "objectID": "posts/version-control/index.html#resolving-conflicts",
    "href": "posts/version-control/index.html#resolving-conflicts",
    "title": "Git Version Control",
    "section": "Resolving conflicts",
    "text": "Resolving conflicts\n\nWhen does conflicts may occur\n\ngit merge\ngit rebase\ngit pull\ngit cherry-pick\ngit stash apply\n\n\n\nHow to undo a conflict and start over\nYou can always undo and start fresh!\ngit merge --abort\ngit rebase --abort\n\n\nHow to solve a conflict\nSimply clean up the file!\ngit mergetool"
  },
  {
    "objectID": "posts/version-control/index.html#removing-from-history",
    "href": "posts/version-control/index.html#removing-from-history",
    "title": "Git Version Control",
    "section": "Removing from history",
    "text": "Removing from history\nRemoving a file completely from Git history requires extra care, which is described in Removing sensitive data from a repository.\nRemember to tell your collaborators working on their local branches to rebase from origin/master by git pull --rebase instead of git pull. Otherwise one merge commit could reintroduce some or all of the tainted history that you just went to the trouble of purging!\nSometimes you may want to remove file from the repository but keep it locally. This can be achieved by\ngit rm --cached -r somedir\nWill stage the deletion of the directory, but doesn’t touch anything on disk. This works also for a file, like:\ngit rm --cached somefile.ext\nAfterwards you may want to add somedir/ or somefile.txt to your .gitignore file so that git doesn’t try to add it back."
  },
  {
    "objectID": "posts/version-control/index.html#workflow-within-a-group",
    "href": "posts/version-control/index.html#workflow-within-a-group",
    "title": "Git Version Control",
    "section": "Workflow within a group",
    "text": "Workflow within a group\nIt is easy to use git if you are the only person who commits. It becomes tricky if you are working with a group of people.\nI originally made some mistakes in the git workflow when I started working in a new group on GitHub. The team chooses to merge every new feature and bug fixes into the dev branch instead of the master branch. So everytime you fork the repository, commit some changes, and then submit a pull request to the main dev branch. At first I was not used to working on new feature branches. I followed my old CVS way of dumping everything I did into my forked branch, and gradually it became a huge change. This is not good for reviewing. What made it worse was that others were submitting pull requests also. Once their commits are merged into the latest dev branch, my huge branch will have many commits ahead and also several commits behind, which is likely to lead to conflicts that must be resolved manually. Here is a good chance to emphasize the usage of rebase: if any commits have been made to the upstream master branch, you should rebase your development branch so that merging it will be a simple fast-forward that won’t require any conflict resolution work. It is also useful in the situation where you are developing two new feature branches A and B, and B is depending on A. You submit your PR of A while working on B. Later you receive feedbacks on A, making changes, and rebase B on top of that. If you don’t use rebase, you have to resolve the conflicts everytime you modify A, and eventually at the time you submit PR of B, it will become a huge mess. Similar situation is being described here. Learn from yours and others’ mistakes!\nHere is the suggested workflow. “Working off a branch” usually means you\n\nclone a repository, e.g. git clone http://repository\ncheck out the branch you’re interested in git checkout awesome-branchname,\nand create a new branch based of that git checkout -b new-even-more-awesome-branch-name\n\nBeyond that, you also need to\n\nconfigure the remote for your fork\nsync your fork\nrebase your development branch\n\nAdditionally, it would be better if you squeeze your small commits into large ones with concise messages, and push to remote like this:\ngit checkout my_branch\ngit reset --soft HEAD~4\ngit commit\ngit push --force origin my_branch\nSometimes rebase will become a tedious option if you jump between branches. In this case, cherry-pick may be an easy alternative. Check out [How to Cherry Pick Commits]https://stackoverflow.com/questions/1670970/how-to-cherry-pick-multiple-commits) for more.\nAs with many peer review projects, pull requests take a long time in the queue waiting to be merged. Handle the situation wisely to save your time and effort!\nHere is an excellent guidance for what to do on GitHub."
  },
  {
    "objectID": "posts/version-control/index.html#github",
    "href": "posts/version-control/index.html#github",
    "title": "Git Version Control",
    "section": "GitHub",
    "text": "GitHub\nIn Fall 2021, GitHub disabled direct command line push through HTTPS even if you are the owner. They introduced a new authentication key which only shows up once and has a limited available time. Now the recommended way to connect to GitHub is through SSH. Follow the steps in Q&A to setup the SSH connection to GitHub."
  },
  {
    "objectID": "posts/version-control/index.html#resources",
    "href": "posts/version-control/index.html#resources",
    "title": "Git Version Control",
    "section": "Resources",
    "text": "Resources\nThere is a summary of Git best practices. Even after I scanned through it, I still made all kinds of mistakes. That’s fine. This is how you improve.\nNever or less, happy coding!"
  },
  {
    "objectID": "posts/version-control/index.html#footnotes",
    "href": "posts/version-control/index.html#footnotes",
    "title": "Git Version Control",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPractically Gabor’s forced usage of rebase only works if you have a single branch to work on. Do not make it the default synchronizing behavior!↩︎"
  },
  {
    "objectID": "posts/cnn/index.html",
    "href": "posts/cnn/index.html",
    "title": "Introduction to CNN",
    "section": "",
    "text": "You can watch the video for a nice walk-through. Here is just some notes from that video. A nice interactive playground based on tensorflow can be found here. An introduction based on PyTorch can be found here.\nDeciding is hard for computers, because traditional algorithms are literal. Tricky cases * translation * scaling * rotation * weight\nCNN matches features, which are just pieces of an image."
  },
  {
    "objectID": "posts/cnn/index.html#steps",
    "href": "posts/cnn/index.html#steps",
    "title": "Introduction to CNN",
    "section": "Steps",
    "text": "Steps\nFiltering\n\nLine up the feature and the image patch\nMultiply each image pixel by the corresponding feature pixel\nAdd them up\nDivide by the total number of pixels in the feature\n\nPooling: shrinking the image stack\n\nPick a window size (usually 3)\nPick a stride (usually 2)\nWalk your window across your filtered images\nFrom each window, take the maximum value\n\nPooling layer: a stack of images becomes a stack of smaller images to reduce the number of features\nNormalization\nKeep the math from breaking by tweaking each of the values just a little bit; change everything negative to zero.\nRectified linear units (ReLUs)\nNormalization layer: a stack of images with no negative values\nLayers get stacked: the output of one becomes the input of the next. Convolution –&gt; ReLU –&gt; Pooling Deep stacking: layers can be repeated many times.\nFinal layer in the toolbox is called fully connected layer. Here, every value gets a vote. Vote depends on how strongly a value predicts the results. A nice cool thing about this is that it can also be stacked: sometimes these are called hidden units in neural network.\nPutting it all together, a set of pixels becomes a set of votes.\nThe key parts of neural network, weights and features, come from backward propagation. All these are learned!\nError = right answer - actual answer\nThese error signals drive the process called gradient descent: for each pixel and voting weight, adjust it up and down and see how the error changes."
  },
  {
    "objectID": "posts/cnn/index.html#hyperparameters",
    "href": "posts/cnn/index.html#hyperparameters",
    "title": "Introduction to CNN",
    "section": "Hyperparameters",
    "text": "Hyperparameters\n\nConvolution\n\nNumber of features\nSize of features\n\nPooling\n\nWindow size\nWindow stride\n\nFully-connected\n\nNumber of Neurons"
  },
  {
    "objectID": "posts/cnn/index.html#not-just-images",
    "href": "posts/cnn/index.html#not-just-images",
    "title": "Introduction to CNN",
    "section": "Not just images",
    "text": "Not just images\nCNN works for 2D/3D data. Things closer together are more closely related than things far away. For example, for sound data, the rows represent intensity in each frequency band, and the columns represent different time steps; for text data, the position in the sentence becomes column, and row is word in dictionary. In the text case, it is hard to argue whether order matters: the trick is to pick a window that spans the entire column top to bottom, and then slide it left to right. In that way it capture all of the words, but it only captures a few positions at a time."
  },
  {
    "objectID": "posts/cnn/index.html#limitations",
    "href": "posts/cnn/index.html#limitations",
    "title": "Introduction to CNN",
    "section": "Limitations",
    "text": "Limitations\nCNN is only designed for capturing local “spatial” patterns in data. (“Spatial” in the sense that things close to each other matter.) If the data can’t be made to look like an “image”, CNN is not as useful. For instance, customer data (one row for one customer, one column for an item like name, address, etc.)\nRule of thumb: if your data is just as useful after swapping any of your columns with each other, then you can’t use convolutional neural networks."
  },
  {
    "objectID": "posts/cnn/index.html#conclusion",
    "href": "posts/cnn/index.html#conclusion",
    "title": "Introduction to CNN",
    "section": "Conclusion",
    "text": "Conclusion\nCNN is great at finding patterns and using them to classify images."
  },
  {
    "objectID": "posts/colormap/index.html",
    "href": "posts/colormap/index.html",
    "title": "Colormaps",
    "section": "",
    "text": "A colormap is matrix of values between 0 and 1 that define the colors for graphics objects such as surface, image, and patch objects. Colormap is extremely important in conveying messages from raw data.\nThere are usually three types of colormaps:\n\nSequential: one variation of a unique color, used for quantitative data varying from low to high.\nDiverging: variation from one color to another, used to highlight deviation from a median value.\nQualitative: rapid variation of colors, used mainly for discrete or categorical data.\n\nThe scientific community has suffered a lot from the traditional colormaps:\n\njet is an example of the rainbow colormap. A rainbow colormap is based on the order of colors in the spectrum of visible light.\n\nIt turns out that some people have been writing about problems with rainbow colormaps for years. Here’s a summary of the main criticisms:\n\nRainbow colormaps confuse viewers because there is no natural perceptual ordering of the spectral colors. In addition to causing visual confusion (such as whether oscillations are in-phase or out-of-phase), the lack of perceptual ordering can slow down tasks because viewers have to refer to the color key more often in order to interpret the data.\nRainbow colormaps obscure small details in the data. The primary reason is that the green and especially the cyan sections of the rainbow colormap are perceptually indistinct, which makes the data in the corresponding ranges appear to be uniform or flat.\nRainbow colormaps mislead viewers by suggesting data features that are not really there. These “phantom features” often take the form of false boundaries. This effect, in combination with perceptually indistinct green or cyan regions, can falsely segment the data.\nRainbow colormaps lose critical information about high and low data values when displayed or printed on a gray-scale device.\nRainbow colormaps can be difficult to interpret for some color-impaired viewers.\n\n\nNew colormaps have been proposed to replace the old ones:\n\nViridis, the default colormap in Python Matplotlib for quite a while., is a linear color map that is generally recommended when false color is needed because it is pleasant to the eye and it fixes most issues with Jet. \nViridis has a linear lightness curve.\nInferno has the same linear properties of Viridis, but is higher contrast, making it better for picking out detail. \nInferno has a linear lightness curve with a higher slope in a wider range.\nParula has replaced jet as the default colormap in MATLAB R2014b. \nTurbo, is an improved rainbow colormap for visualization. \nTurbo has a low-high-low lightness curve. Thus when rendered in grayscale, the coloration will be ambiguous, since some of the lower values will look identical to higher values. Consequently, Turbo is inappropriate for grayscale printing and for people with the rare case of achromatopsia. In principle Turbo can also be used as a diverging colormap. However, there are better options especially using white as the zero background.\nThe turbo colormap is available since Matplotlib v3.3.1+. To check Matplotlib version, print matplotlib.__version__.\nDesaturated rainbow. This is the one I found in ParaView which is especially good at showing the details for sequential data. \nRdBu is the one I prefer in diverging colormaps. \n\n\n合理地运用色表可以舒缓情绪。正如某位同侪阿昆所言，当你某天看到女朋友的照片，觉得很美，心想：为什么不能把她画到论文插图里去呢？于是，"
  },
  {
    "objectID": "posts/singapore/index.html",
    "href": "posts/singapore/index.html",
    "title": "新加坡之行",
    "section": "",
    "text": "这次出行似乎有点仓促，什么功课都没做就直接收拾行李上了飞机。可能对于语言没有障碍且大不到哪里去的地区没有什么心理负担吧。但我也真的心大，仿佛回到了几十年前人们出行的方式。飞机预计早上六点多降落，七点钟从机场出来，会场也不知道叫啥，酒店也不知道叫啥。会议的议程手册压根儿没看，指甲刀和临时寄物柜的英文也不知道怎么说。这2G网看来要带我走天下了。\n飞机上也是一波三折，先是发现之前打球裂开过的指甲处又不明缘由地掉了一块，后来又发现睡着后眼镜不见了。我做梦的时候还想着这眼镜不见了可就糟了，谁料到还真的不见了。幸好它没有掉在走道上被踩了而是落在了座椅的夹缝里，要不然谁知道还会整出什么事。作为我做过的最长时间的单程飞机，15个小时，黑了一整个航程，难吃的联航飞机餐，在南海空域还有不少扰动，留点小波折也算是再加深一层印象。\n时差的问题还没想过，希望身体这次争气点。走之前想要提交的工作还没完成，忙里偷闲看看能不能做一点。八点到了酒店，寄存了行李箱后径直杀到了会场，第一印象已然有点失望。这个会场跟楼下的商场直接相通，而且AOGS只包了一层，同时还有好几个其他的珠宝、邮票、地产展览在布置，给人的感觉非常地混乱。三天在会场下来就发现一个Juno的分会场坐满了人，其他的说实在乏善可陈。就会议而言，这次的惊喜在于看见国内云南天文台有人在做晶格玻尔兹曼（LBM），而且看起来无论理论还是技术实现上都非常复杂，值得花时间好好研究。汪毓明老师又消瘦了不少，但是报告非常出色，虽然英语口语没有那么好，但是思路清晰，条理分明，表意通畅。开个会，所有人来了，讲完就走，对别人的工作大都不感兴趣。开个会没有一个同学，寂寞应如是。真是羡慕汪老师和贾老师的关系。\n新加坡好吃的很多，但不等于说什么都好吃。随意在酒店附近找的评分最高的中餐，干炒牛河，正宗粤菜惊世骇俗，非多年功力不能及。我在广东这么多年，做成这样的牛河也是非常少见。路边的蛋挞也是相当不错，热情的阿姨送的豆浆和芝士包也还行。周三晚上专程慕名而去的坐落于中国城的了凡，号称全世界最便宜的米其林一星餐厅，招牌油鸡饭只要5新币，那一勺豉汁和油鸡，入口难忘，名副其实。相比起来，酒店旁边的海南鸡餐厅做的咖喱鸡套餐4.2新币，差了至少一个档次；而IT硕士法学博士老板开的街边杂乱中餐，那碗牛肉面就一言难尽了。后来问了俊实，得知新加坡在90年代有过一批大裁员，于是诞生了不少高学历的出租车司机和餐厅老板。诚如是。\n新加坡的政治真的让人欣赏。今天看到一则关于某个电子支付平台广告一人扮演四大种族用户涉嫌侮辱华人的新闻，政府第一时间站了出来，强制要求撤下有违种族和谐的宣传，并且强烈谴责在公开媒体渠道进行的种族歧视。这个印度裔的政府官员面露愠色，直接道出政府“零容忍”的原则。新加坡到处有四种语言，多民族国际化程度非常高，而政府对于社会运行的责任更是当仁不让的态度，跟诸多西方国家形成鲜明反差。对比近日香港的动乱，同为城邦政治的新加坡，更令人刮目相看。 世界城邦国家的典范，新加坡当之无愧。这个历史仅能大略追溯到14世纪的国家，平静地经历了葡萄牙、荷兰和英国的殖民，在二战期间连同整个马来半岛沦陷于日本之手，二战结束后没多久便裹挟入席卷全球的反殖民浪潮，与马来西亚做了两年露水情人，最终还是在李光耀的人民行动党领导下脱离马来西亚城邦，成立了独立的港口国家。这个地方的人民和领导者们最精明的地方，在于时刻认清自身的现实处境、实事求是地寻找最优的发展路径。在统一的管理下，众多的难题都迎刃而解：住房、经济发展、工人阶级利益保障、城市规划、人口控制、以及国际合作。这是活生生的发生在弹丸之地的奇迹，东西方政治交汇下最令人瞩目的作品。无论是书本上、还是现实中，我都佩服得五体投地。\n由出色的城镇规划衍生而来的，是新加坡世界领先的的建筑设计。走在市中心，总能看到一栋栋令人惊艳的空中楼阁，称一句巧夺天工绝不过分。为了适应热带的气候，在很多地方楼与楼之间都有梁桥连接，完全可以不晒到太阳通勤漫步。众多的购物中心都彼此相连，若是愿意的话在里面消磨一天都可以毫不在意。\n作为运输业发达的代表，不光是船舶远洋运输，新加坡航空也已经蝉联了多年的世界综合评分第一。新加坡的空港飞机起飞频率，实测估计肯定小于1分钟。\n返程飞机经过南海上空时，总能看见白色的点阵，我第一反应是海上的浮标。不过这显然经不起推敲，因为数量实在是太多了。同样的道理不可能是轮船，而经过排除，最有可能的物质是：垃圾。虽然不愿意相信，但这可能就是活生生的现实。只希望不是。\n鉴于最近持续的香港游行活动，新加坡和香港之间的对比更加引起了我的兴趣。李光耀过世之际，三联曾经出过专题讲述新加坡的腾飞和今后的展望。 中国古话“治大国如烹小鲜”，但新加坡的城邦治理模式有多少能照搬多少需因地制宜，仍是千年学不完的课题。"
  },
  {
    "objectID": "posts/mpm-cg/index.html",
    "href": "posts/mpm-cg/index.html",
    "title": "MPM与CG特效",
    "section": "",
    "text": "MPM与CG特效\n读了些年轻人们想实现简易的计算机模拟图形学的进展，与其说是自叹弗如，还不如说是很兴奋。正如这个年轻的作者说的，完成一个项目的最后一棒，这是一代一代人积累下来才能做到的“简单”，而不是一个天才一夜之间拍脑袋做出来的成果。\nMPM和PIC非常相似，我可以多了解一下。本来优美的模拟就是我的目标，懂的越多，就离我的目标更近了一步。入门的话可以参考这位同学写的88行C++实现，非常有代表性。话说这种对于极简代码的追求，Jeff Bezanson在搞Julia之前就是从1000行实现Lisp开始的，谢华生在他的《计算等离子体》中也无处不体现极简MATLAB代码的风格。我相信这就是这类人的特质，对于追求极简优美的顽固和执着。\n大致看下来这个用C++和LLVM实现的新语言Taichi以后，我迅速联想到了Julia和她的创造者们。MIT和清华这些顶级的计算机学校出来的学生都有这种野心，想创造一些属于自己的东西；而开源时代让学生们再也不用从头开始造轮子，大家需要做的是真的在添砖加瓦以及糊水泥。传统的C/C++，Fortran这些编译语言的共同问题都是编译的过程太长且受到平台和编译器的影响，想在没有详细指导的情况下编译运行成功几乎就是万幸。新一代的语言每个都有自己的野心和长处，群雄逐鹿的时代，看谁能够摸透人心笑到最后。大家的互相借鉴和模仿其实是好事，只有在不断的交流中，技术和科学才能持续进步。一次次地从错误的方向中汲取经验教训，才会逐步摸索出一条可行的路。\n我也要努力，把手头的事情做好，再准备着未来想做的事情。我喜欢物理引擎，体育和流体。如何把这些结合起来结合起来，做一些有意思的项目，是我需要认真思考的。\n暑期清华的老师有一门Conformal mapping和计算图形学的课程，可惜我只看了两节就没有跟下去了。"
  },
  {
    "objectID": "posts/green-function/index.html",
    "href": "posts/green-function/index.html",
    "title": "Green’s Function",
    "section": "",
    "text": "最早在数理方程的时候接触到格林函数，但一直是懵懵懂懂的。在实际的演算中几乎用不到，于是一直也没真明白。稍微回顾一下。\nFirst of all， Green’s function is used for solving ODEs with the form \\[\nLy(x) = f(x)\n\\] where y is the unknown variable, f is the applied force/source function, and L is a linear operator.\nLinearity is the crux of the idea: if we can decompose the solution into some kind of element solutions, then by combining them together we can get the final solution. Dirac function \\(\\delta(x)\\) is the “strange” function we define for representing the elemental solutions, usually in the form of \\(\\delta(x-\\xi)\\), where \\(\\xi\\) is the location of the source and x is the location of influence.\nThe solution \\[\ny(x) = \\int f(\\xi) G(x;\\xi) d\\xi\n\\] only applies for homogenous initial/boundary conditions, i.e. each \\(G(x;\\xi)\\) must satisfy the same initial/boundary condition. This is the key reason why solving an ODE with Green’s function cannot be applied to general problems."
  },
  {
    "objectID": "posts/make/index.html",
    "href": "posts/make/index.html",
    "title": "Make for a Better World",
    "section": "",
    "text": "There are many different types of make system, among which the most famous one is GNU make. make is a tool designed for compiling programs into executables, but it also can be used for executing consecutive commands which have internal dependencies. The essense of make is dependency: it aims at figuring out the dependencies in your workflow with minimal effort. To some extent, I usually think of it as shell scripts with dependency control.\nTo take advantage of this powerful tool, we need a basic understanding of the wildcard and the dependency logic. When you first start with Makefiles, you would tend to explicit state every task as do on command line. However, this is exactly the redundancy make wants to free you from. Take a look at Makefile in Practice, which is a great introduction to most commonly used features.\n\n\n\nBy default make looks for the makefile in the current level of the directory. You can use -C to specify the location of the target makefile."
  },
  {
    "objectID": "posts/make/index.html#gnu-make",
    "href": "posts/make/index.html#gnu-make",
    "title": "Make for a Better World",
    "section": "",
    "text": "There are many different types of make system, among which the most famous one is GNU make. make is a tool designed for compiling programs into executables, but it also can be used for executing consecutive commands which have internal dependencies. The essense of make is dependency: it aims at figuring out the dependencies in your workflow with minimal effort. To some extent, I usually think of it as shell scripts with dependency control.\nTo take advantage of this powerful tool, we need a basic understanding of the wildcard and the dependency logic. When you first start with Makefiles, you would tend to explicit state every task as do on command line. However, this is exactly the redundancy make wants to free you from. Take a look at Makefile in Practice, which is a great introduction to most commonly used features.\n\n\n\nBy default make looks for the makefile in the current level of the directory. You can use -C to specify the location of the target makefile."
  },
  {
    "objectID": "posts/make/index.html#cmake",
    "href": "posts/make/index.html#cmake",
    "title": "Make for a Better World",
    "section": "CMake",
    "text": "CMake\nAlthough make has been very popular for compiling programs on a Unix-like system, it certainly cannot do everything alone. People who write code on multiple different platforms became annoyed by the fact that they need to create different Makefiles for different platforms, given it Linux, Mac, or Windows. 1 This is where Kitware’s CMake comes into play. In essence, cmake is a cross-platform tool for generating Makefiles. It also adds the capability of testing and deploying which may often be better than the make equivalence. When you automate multiple things together, magic can happen. Someone even says that using cmake force you to build better modular project. I would tend to use this for my next large C++ project.\nBasic tutorials on CMake can be found: Hello-World-CMake and Modern Simple CMake.2 For some latest features, it would be better to check the official website. For installing cmake, checkout modern cmake.\nHere I list my conceptual understanding of cmake.\n\nThe top level CMakeLists.txt is the configuration file where we specify everything globally.\n-S specifies where to find the CMakeLists.txt source file\n-B specifies where to store the generated makefile, together with some other generated configuration files.\nMust-have in the CMakeLists.txt\n\ncmake_minimum_required(VERSION x.xx.x);\nproject(MYCOOLPROJECT);\nadd_executable(${PROJECT_NAME} main.cpp): executable name and source codes.\n\nSimilar to the makefiles, CMakeLists.txt can be hierarchy, meaning that for each component/library, you can have a separate CMakeLists.txt. At the upper level, use add_subdirectory(SUBDIR) to specify where the underlying CMakeLists.txt is, targe_include_directories(${PROJECT_NAME} PUBLIC MYLIB) to specify the library headers, target_link_directories(${PROJECT_NAME} MYLIB) to locate the library objects, and target_link_libraries(${PROJECT_NAME} MYLIB) to specify the linking stage. At the lower level, the most important command to compile an object file is add_library(MYLIB lib.cpp lib.h).\ncmake has this industry standard trick to add code version into the executable. Check this video for a quick demo.3"
  },
  {
    "objectID": "posts/make/index.html#meson",
    "href": "posts/make/index.html#meson",
    "title": "Make for a Better World",
    "section": "Meson",
    "text": "Meson\nThere are even newer build systems, e.g. Meson. Meson is written in Python, targeting at a simpler, faster CMake.\n\n“Simpler”, thanks for the robustness and cleaness in Python.\n“Faster”, thanks for the underlying low-level assembler Ninja.\n\nMeson only depends on core Python libraries. It is recommended to install Meson through pip."
  },
  {
    "objectID": "posts/make/index.html#footnotes",
    "href": "posts/make/index.html#footnotes",
    "title": "Make for a Better World",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI remember when I first arrived at Michigan, Gabor told me that our Fortran code BATSRUS is only available on Linux and Mac. Well, that’s because we are using only make!↩︎\nEven better than the official tutorial!↩︎\nIn early 2020, Gabor implemented something like this in SWMF by himself. Vlasiator also has similar stuff, but is more brute-force like.↩︎"
  },
  {
    "objectID": "posts/ai/index.html",
    "href": "posts/ai/index.html",
    "title": "Machine Learning Overview and Examples",
    "section": "",
    "text": "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E. – Tom M. Mitchell, 1997"
  },
  {
    "objectID": "posts/ai/index.html#感悟",
    "href": "posts/ai/index.html#感悟",
    "title": "Machine Learning Overview and Examples",
    "section": "感悟",
    "text": "感悟\n无监督聚类的核心思路有两种，一是距离，而是密度。"
  },
  {
    "objectID": "posts/ai/index.html#references",
    "href": "posts/ai/index.html#references",
    "title": "Machine Learning Overview and Examples",
    "section": "References",
    "text": "References\n\nAI by Doing"
  },
  {
    "objectID": "posts/smash-bros/index.html",
    "href": "posts/smash-bros/index.html",
    "title": "任天堂大乱斗",
    "section": "",
    "text": "任天堂大乱斗是一款神奇的游戏。2018年底上市的Switch游戏，多达三位数的基础人物、地图场景和总时长28小时的游戏音乐；大小地图分列的单人模式；不同于以往的格斗模式创新——一款有野心，也有完成度的任天堂作品。\n樱井政博，同时也是心之卡比系列的制作人，看得出在此次的大乱斗中融入了自己的诸多思考。本身乱斗模式对于动漫游戏玩家的吸引力就是极高，带来的第一个难点便是如何权衡人物的多样性的操作的简易性。这里所谓的创新并不意味彻底改变以往格斗游戏的“轻拳、重拳、跳跃、格挡、必杀”的基本思路，而是选择“砍”，充分利用Switch的已有键位，不再追求以复杂的组合键释放绝招。格斗游戏的另一个重点，是胜利机制。本作大胆地抛弃了血条系统，胜利的唯一条件是把对手击出场景地图。显而易见，樱井受到了龙珠里天下第一武道会规则的启发，去掉了10秒倒地而保留了出场规则，使得大乱斗立刻变得和以往的格斗游戏区别开来。血条简化为伤害百分比，受到伤害越高，被同样的招式击飞的距离就越远。与之相伴的是游戏对于空间概念的拓展：格斗再也不用仅仅限制于地面，对于空间的利用率比以往的格斗游戏高出很多。\n那么，大乱斗是如何平衡娱乐向和竞技向的需求的呢？ 1. 招式的华丽程度和伤害完全不成正比：即使是新手玩家也能很容易打出绚丽的招式，但未必能容易达成胜利条件； 2. 道具的创意：基于角色的道具使用，增加运气成分； 3. 场景的变化性，同样也是增加不确定性； 4. 画风的协调：可爱与帅气并存，且减少违和感。\n对于细节的用心，游戏硬件机能能够实现的极限，他们的野心也体现在诸如马里奥的背带裤材质这样的地方。制作人对于每一个角色都拥有绝对的设计权，这是游戏博而不杂的前提。\n每个月新玩儿十个游戏，这是樱井对于行业发展的把握。\n\n我听说这款游戏已经有些时日，但前几天才真正上手体验了几把。游戏本身的制作无话可说，若要挑毛病，那只能说NDS的摇杆还需要进一步提高。 以上内容有参考Gamker攻壳的游戏点评。希望他们有朝一日能从评论走向实干，做出博采众长独树一帜的作品。\n任何游戏和产品最终都躲不过面向对象的问题。如何满足市场的需求，采用何种方式，决定了怎么样的东西能够生存下来。二十年前的五笔输入法在国内是如此流行，而今却已无人问津，根源就在于速度上的收益远远不及上手难度。一款一开始并没有明显先进理念的产品，可能因为其不经意间的兼容性吸引了各式群体的目光，并以集体的智慧达成后来居上的态势。有心者在任何领域提出一种新想法，周全的考虑意味着不能仅仅盯着自己能看见的优势，也必须看出弊端，并权衡左右。"
  },
  {
    "objectID": "posts/biblatex/index.html",
    "href": "posts/biblatex/index.html",
    "title": "Behaviour of BibLaTeX",
    "section": "",
    "text": "biblatex will display author’s first name to distinguish different authors with the same last name. You may accidentally have the same author but different spelling, however it will still appears as two authors to biblatex.\nbiblatex also tracks all the authors in the list, not just the first author.\nAnother interesting question is how biblatex distinguish different paper reference by the same author in the same year?\nQuote from StackOverFlow: &gt; This is almost certainly to do with using the uniquename and uniquelist options which are enabled by default in most bundled styles. These options mean that biber automatically disambiguates names by using initials or full names, depending on which other names are cited. See the biblatex manual which explains this with some comprehensive examples. If you set uniquename=false and uniquelist=false I’ll warrant that the “strange” behaviour you see stops."
  },
  {
    "objectID": "posts/ssh/index.html",
    "href": "posts/ssh/index.html",
    "title": "Remote Access through SSH",
    "section": "",
    "text": "Tutorial on proxy jump"
  },
  {
    "objectID": "posts/ssh/index.html#proxy-jump",
    "href": "posts/ssh/index.html#proxy-jump",
    "title": "Remote Access through SSH",
    "section": "",
    "text": "Tutorial on proxy jump"
  },
  {
    "objectID": "posts/ssh/index.html#ci-workflow",
    "href": "posts/ssh/index.html#ci-workflow",
    "title": "Remote Access through SSH",
    "section": "CI Workflow",
    "text": "CI Workflow\nIt is very tricky to make SSH connections in CI workflows like GitHub Actions and Gitlab CI. I have suffered from both during the past few month: each spent me about a day to find a magic trick to make it work. The difficulty comes from accessing private servers from a docker machine. You need to setup the private and public keys properly and overcome multiple issues like Host key verification failed when you tries to access to a machine for the first time, proxy jump through another server, etc.\nFor example, I need to turn off ssh host key checking for the first time access on the university server and use a proxy jump to acccess data from the actual machine behind:\nssh -o StrictHostKeyChecking=no hongyang@login.physics.helsinki.fi\nssh -o StrictHostKeyChecking=no -J hongyang@login.physics.helsinki.fi hongyang@turso.cs.helsinki.fi\nscp -r -o 'ProxyCommand ssh hongyang@login.physics.helsinki.fi -W %h:%p' \\\nhongyang@turso.cs.helsinki.fi:proj/reference.tar.gz testpackage/tests/\nThanks to all the people online sharing their experience on all kinds of issues!"
  },
  {
    "objectID": "posts/magic-angle/index.html",
    "href": "posts/magic-angle/index.html",
    "title": "Magic Angle",
    "section": "",
    "text": "What is magic angle, and how does it work??"
  },
  {
    "objectID": "posts/iowa/index.html",
    "href": "posts/iowa/index.html",
    "title": "Des Moines之行",
    "section": "",
    "text": "今年的GEM和CEDAR合并了，在Iowa的首府Des Moines举办。NSF的资金比较紧张，合办能省不少钱。\n首先从Des Moines的发音讲起。这名字一看就不是英语名字，发音时s都被吞掉了，记为/dəˈmɔɪn/。据说城市名源于法语，因流经城市的河流”Rivière des Moines”译做僧侣之河而得名。美国第81大城市，人口不到30万，大农村州政府所在地。第一次来到Iowa，我对Des Moines的城镇规划刮目相看。市里一条河流将城镇作东西两岸，东岸州金顶议会大厦盘踞于地势最高点，四下各式建筑错落有致，新房迭起；西岸市中心办公区，主体建成于50年前至20年前，人烟稀少，但空中连廊遍布，干净整洁，显然是精心设计打理的。河流两岸草地平整，轮滑公园到了晚上热闹非凡。市内支柱产业是保险、农业设备和物流，相关从业人员占据了1/4人口。\n从酒店去机场的路上和Uber司机小哥聊天，他说他们家2018年从加州搬过来定居。他的孩子们喜欢雪，爱荷华四季分明，他们一家很喜欢。查了一下，最冷的一月平均气温-5摄氏度，最热的七月平均气温24摄氏度，每日相对湿度70%左右，各方面都很平衡。\nIowa近些年的人口增长主要来自外来移民，而其中的亚洲移民约占40%，主要来自越南、中国和印度。这一点从市中心的饮食就能看出来，越南粉店不少，越南超市也很近。酒店河对岸有个Asian Garden，实则是中华文化园，有一个牌坊，十二生肖的石刻，刻着“诚信”、“友善”等等传统美德的巨石，以及仿江南水乡庭院的木板桥。习大大四十年前曾经到访爱荷华考察农业，2012年的时候访美又专程回访，也让爱荷华和中国间建立起了一层特殊的缘分。爱荷华是美国农业重镇，产量和出口量均列全美第一，美国粮仓之名毫不为过。从空中俯视，这里土地广袤、沃野千里，自然条件得天独厚，也难怪农业如此发达。\n我们的会场位于城市河流西岸的东北角，一旁连接着篮球、室内足球和冰球的体育馆，另一侧经由希尔顿酒店从空中连廊对接其它的高楼建筑。会场内并无吃饭的地方，每日午晚均需徒步行至南部寻觅食物。开了四天会后于会场的宴会厅里举行了晚宴，和去年的GEM相差不大，但有意思的是期间进行了一个CEDAR-GEM问答对抗赛，由在场的400名科学工作者现场扫码回答7个单选问题，包括你认为最成功的太空计划，你印象最深刻的仰望天空是看到的东西，你在何时准备报告，以及你来开会的目的等等。大家的反应还算热烈，而我更好奇在这样一群人中的认知是否相同。诸如最成功的太空计划，毫无疑问第一名是Voyager，但我非常惊讶MMS竟然能排在第二名。恰巧周四中午还和Brian在讨论这个，我们聊到空调的发明是由于纽约的报社需要在印刷报纸之后保持室内干燥，低因咖啡的发明是由于从非洲运输咖啡豆的船舱里漏水，人们发现海水浸泡下咖啡因竟然被稀释了。这些有意思的东西，包括爱荷华空间科学最出名的Van Allen发现的辐射带，都是带着许多意外色彩的。MMS最大的意外发现是什么？是唯电子重联。我感觉这个旗舰项目最大的成就在于工程，把所有仪器的精度都提高了一个量级以上，并且验证了多卫星重构三维结构的可行性。MMS能排在CLUSTER和诸多其它项目之上，在于群体的视角、当下和过往、以及未来的选择。\n周五虽然还有报告，但我毅然决定出去转转。照着地图扫了一遍，圈定了三个地点：Iowa History Museum，Iowa State Capital，以及Science Center of Iowa。爱荷华的历史也没太多复杂的成分，就是印第安原住民和外来欧洲移民的角力，近现代工农业的发展，美国内战的影响，再到现代军事和电影产业。这座历史博物馆不大，但外形红墙交错，我很喜欢。一楼大厅很空，一侧摆放着由于市里保险公司盖楼从地下挖掘出来的猛犸象骨骼，另一侧挂着当年911事件美国人民和被塔利班劫持的4架飞机之间的奋战。从博物馆出来，沿着山坡的台阶一路向上，就走到了爱荷华议会大楼。这是一座宫殿式的建筑，中间的金顶尤其醒目，内部装饰一股浓厚的罗马风格，大理石的基底，金灿灿的中庭，大气恢弘。一楼左右两侧都是正在使用的政府办公场所，秘书室、州长办公室、小法庭。州长办公室门口摆放着她生平履历，一路从早年的校园篮球队到后来从军从政，以及一路获得的奖章勋章。参众两院的议事厅分立二楼两侧，中央各自摆放着林肯、华盛顿以及当今总统的画像。据说爱荷华是美国唯一把总统像摆放在中间的州。介绍的导游是位声音洪亮的大叔，热情洋溢地讲解着日常议会发生的事情，甚至于高中生为了修学分在参议院里面端茶送水取文件做作业也有提及。二楼中央是一间图书馆，高十余米，非常靓丽恢弘，经典的绿罩灯、螺旋楼梯，可惜如今仅保留了一个壳，已无人在其中修订阅读。从三楼的暗门可以踏上92级台阶到达金顶之下，道路狭小仅容一人通过，在上面人人讲话可以声如洪钟。往下一望，各层地砖纹路迥异，目光直抵一楼，如同近50米深井，令人心头一悸。从窗口向外望去，正前方呈现的是Des Moines中心全景。令人困惑的是门口三座大炮正对山下，走进一看是美西战争时缴获的战利品，不知为何被带到了爱荷华的首府。仅此一处，已让我觉得不虚此行。\n下午吃过午饭后，步行10分钟来到科技馆参观。这里门票17刀，我满怀期待内有乾坤，进入后只觉差强人意。楼道里满是孩子们的喧闹声，大人们几乎无一例外都是陪孩子来的，除了我和组里同事俩闲杂人等。一楼有个乐高中心，哈利法塔、金门大桥、胡佛大坝、埃及金字塔、罗马斗兽场、以及这座科学中心本身，不知是哪些位神人的作品，都不是一般乐高门店里能找到的。旁边一个小朋友的动手乐园，搭电路、做帆船、钻木头、切树桩，如果是小朋友来肯定很兴奋。美国家长也是心大，小学生拿起锯子和电钻挥舞也不带担心的。小时候我也曾经拥有一个科学实验箱，包括声、光、力、电的各色小实验。啥也没特明白，就是学会了自己接电池弄个点灯，躲在被窝里照亮Game Boy打游戏。设想，如果那时候有个科技馆可以让我上手来折腾，我也会非常开心吧。另一侧有个小剧场，一个大学生模样的男生周围站着一圈小朋友，我们半程进去只听见些火焰、辐射之类的词语，也不知多少小脑袋真的在听。楼上三个馆，一个户外馆摆了些当地的动物，包括猫头鹰和蝙蝠的标本和几条活的响尾蛇。一个天气预报演播室，背后一片绿幕，据说每周五真的会有电视台的人来现场拍摄。第二个力学馆，全是互动道具，压力炮、弹力球、齿轮组、一排单摆、一块自制火箭发射台、还有风力驱动的轨道球。其中一台仪器是个大型吹风机，对着天上吹，把塑料球放在中间能在一段时间内保持平衡，利用的是400年前发现的经典的伯努利原理。然而玩儿的过程中我发现，不是所有的初始条件都能让小球抵达平衡点，并且经过一段时间，这种平衡都会被打破。如今的计算机仿真，能否完美重现这些现实中的物理过程？最后一个厅是天文馆，一片巨大的椭圆形巨幕，自选节目，播放的内容从星云到极光，就是朴实无华的视觉震撼。后面的互动展示也还成，微软Kinect捕捉的手搓黑洞，可见光、紫外、和X光频段下的太阳影像，还能让我学点新东西。毫无意外的，三人举起美国第一课人造卫星火箭模型的照片和样品模型陈列在关门口最醒目的位置，内部Van Allen设计的粒子载荷电路还清晰可见。没来爱荷华之前，我是真不了解Van Allen当年一直在University of Iowa工作。现在想想，他的传奇也带来了这所大学空间物理系半个多世纪的繁荣。爱荷华大学位于Iowa City,距离Des Moines一个半小时车程，也是座漂亮精巧的大学城。学校的设施远比我想象得现代化，再次体现出这里的人们在悉心经营着自己工作生活的地方。\n从科技馆里出来已是三点。依体量而言，17刀的门票略显昂贵；周五的下午，满是小朋友和他们的祖辈带来游玩嬉戏。但我还是觉得不亏：走过许许多多的科技馆，每一家都有自己的风格，这种体验感，是不可复制的。SCI刚好构成了爱荷华科技馆首字母的缩写，一个美妙的巧合，也可能预示着这里的人们始终带着对科学的向往。如果让我提一个建议，我会说，让农业单独作为一个展馆，才能体现出爱荷华相较于其他地方最与众不同的特色。\n一趟旅行结束了，我很享受。科学的向往不为经费所扰，我们从事的工作不为挣钱而存在。向老师们请教，是件快乐的事。"
  },
  {
    "objectID": "posts/travel-to-helsinki/index.html",
    "href": "posts/travel-to-helsinki/index.html",
    "title": "启程赫尔辛基",
    "section": "",
    "text": "欧洲人习惯的月日记法和中国一致，但是和美国是反的，估计单这就能闹出不少乱子。咱既然来了欧洲，当然也要入乡随俗了。\n这趟从纽约飞往赫尔辛基的旅程本身四平八稳，但前前后后的经过却是起伏跌宕。在疫情与通航禁令下摸着石头过大西洋，也是一段难得的经历。"
  },
  {
    "objectID": "posts/travel-to-helsinki/index.html#回溯",
    "href": "posts/travel-to-helsinki/index.html#回溯",
    "title": "启程赫尔辛基",
    "section": "回溯",
    "text": "回溯\n一切都要追溯回2020年的4月份。彼时国内疫情封城禁航了2个月，终于得到了控制，而国外的疫情则逐渐抬头。来往全球的航班把病毒带到了世界各地，后知后觉的政府和民众光顾着看中国热闹，等到病毒真来了的时候早就来不及了。为什么2003年SARS时候数字远不如新冠夸张？还是回归数字说话。现在的一些数据表明SARS全球总确诊数目8098例，致死率大致在15%左右。这里的可怕点在于综合15%的高致死率，或者是高于50%的65岁以上致死率。所以当医学上确认这些数字后，即便是没有流行病经验的行政当局也会全力以赴控制疫情。而2020年的新冠，最开始在武汉致死率一度达到了20%，因为并不了解这到底是什么病，只知道症状和当年的SARS很像，传染性更强，并引发了国内尤其是湖北地区的社会性恐慌。而9个月过后，到目前为止新冠全球范围内的致死率在2%左右。作为对比，流感一般的致死率在0.1%附近，比新冠低一个量级，这也是为啥新冠常被成为大号流感的原因。另外一个需要知道的重要数字是传染率，被定义为平均一个患者能感染多少健康人，英文代号R0 value（参阅维基）。显然这个数字不是一个直接能够得到的量，而是一个导出量，所以各家的统计方法得出的结果会有明显区别。目前我看到的数字，新冠的R0值从1.1到6不等，平均可能在2.5左右。当年的SARS呢，则是在0.19到1.08之间。这些数字意味着什么呢？可能从直觉上人们会觉得1和2很接近，但这是不对的。问题出在，传染病的数学模型里面，总是会带有指数函数，而这个1、2的数字，实际上代表的指数项的系数。回头看自中学数学里开始接触的指数以后，你便会意识到这其实是巨大的区别。所以简单来说衡量传染病的基本要素就是两个指标：致死率和传染率。但显然世界范围内众多的政府官员都不能真正理解这些数字的来源和意义，单纯的文科逻辑治国显然是意识不到很多问题的危险程度。比如说，建立在这两个量之上，现在你再归纳出一个新的量用来衡量一种传染病究竟需要什么程度的控制和干预吗？我也尚不知道答案，但显然这是任何决策的出发点。如果不讲究科学，政策都会变成拍脑袋的娱乐，就像现实中发生的，很多国家和地方的措施和政策都走向了荒谬的方向。科学不是说目前的模型就是对的，而是说，基于当前的理性认知，我们能不能做出利益最大化的选择。这次的疫情，正是一个检验全球领袖和民众科学素养的试炼场：没有任何人能够对客观事物真正全面地了解，但是我们依然可以做出出于逻辑和理性的判断。\n总之，当我四月份开始申请芬兰签证时，所有的签证申请都戛然而止了。本来我计划五月份答辩，六月份就奔赴赫尔辛基，一下子全都要打乱重来。日子一晃过得很快，大概六月初修改完文章，月底了结博士期间的所有活儿，七月八月悠哉地过日子折腾点儿代码整理些笔记玩儿游戏跟师兄师姐出游，九月开始实践之前反思中想到的提升模拟效果的方案以及GPU并行化的尝试，十月份有了半成品的OpenACC实现和新模型的结果，并且完成了部分工作的过渡。期间我在密歇根的研究生宿舍白住了两个月，直到八月底被“踢出”宿舍卷铺盖儿来到纽约，中途还在匹兹堡转了一圈儿并享受了回市中心希尔顿的夜晚。九月初通过多方途径得知又可以办理签证了，于是立即联系预约到了月底的面签。之前耽搁了一些是由于一直搞错了领馆和旅游商务签证代理中心的关系，直到直接询问领事馆才明白我不需要通过代理操作。芬兰的纽约领馆在4大道37街的一栋写字楼里，从李堡出发大概一小时，整个面前过程非常顺利，因为实际上也没人在办理签证。面签之后三天，外交部还有人专门发来问询函确认我时间填写错误的问题，回复后立马给了居住证。之后便开始在网上订公寓并确定机票行程，反复比对后发现一开始看见的廉价机票纯属子虚乌有，实际上航线根本没有恢复，但航空公司依旧在销售机票。无奈之下只好选择了汉莎航空经法兰克福到赫尔辛基的15小时行程，一共花了近3000刀，肉疼得不行。芬兰这边的老师知道后很快告诉我愿意帮我报销一部分机票，也是令我喜出望外。\n如今看来这几个月的“空闲”也是福祸参半。我少挣了几个月的工资，又在财富自由上落后了一节；我晚开始了博后的工作，说不定就错过了些出成果的时间；我有了更多的时间完成毕业论文，算是对过去五年一个完整的交代；我有了更多的时间和朋友聊天，人生也多了相伴而行的动力；我有幸和舅舅一家一起生活了两个月，异国他乡的亲人相聚可不容易。我没有埋怨生活的理由，无论好坏。"
  },
  {
    "objectID": "posts/travel-to-helsinki/index.html#航程",
    "href": "posts/travel-to-helsinki/index.html#航程",
    "title": "启程赫尔辛基",
    "section": "航程",
    "text": "航程\n纽约的JFK机场及其空旷，或者说我从没见过这么清闲的机场。整架飞机一共就20名乘客10名空乘飞行员，头一次能体验到在飞机上躺下来的姿势。法兰克福当地时间凌晨5点降落，通过了进欧盟的审查，但由于最终目的地是芬兰换乘所以就是例行公事地看看，很快就过了关从A登机口到了B登机口。中间连接带有一条200米的长廊，一度空留我一人在踱步，每一次的脚步声都异常清楚，就差个月亮和我对影成三人了。在新登机口等候了5个小时，期间差一点昏睡过去。一早上就有一个英文不好的伊斯兰小姐姐过来跟我确认航班，也是转机且人生地不熟吧。法兰克福到赫尔辛基的航班竟然是满员，大大出乎我意料之外；在2小时的航班上结结实实地睡了一觉，掐指一算，这个距离也等同于深圳到合肥、武汉和上海，欧洲一国等同于中国一省，此言不虚。落地后入关倒是意料之外地漫长，等了将近40分钟，结果轮到我递上居住证和护照，啥都不问就进来了。像我这种从“危险”国家过来的要求进行10天的自我隔离，在机场也不能搭乘公共交通，所以只好选择出租：结果还没到大量出租的等候口时就被一名小哥截了胡，用一辆宝马拉走了。我意识不太清醒，只是隐隐觉得这做派和说辞颇像国内机场的黑车，不到正常等候的地方反倒是在出口处提前下手，各种游说无非是说他们是个公司正规且便宜。我事先查过Uber的价格，司机的报价36欧也在那个范围内，我就想大不了被骗一次也没啥，反正宝马嘛。高速上的车流也比我想象得多，和司机有一搭没一搭地讲着话，构建着我对赫尔辛基的第一印象。下了车，发现公寓的办公室正常2点就关门了，幸亏提前告知了我到达的时间，有工作人员在专门等我——即便如此，在寒风中提着3个箱子挣扎了10分钟也是够受的了。\n从纽约到法兰克福同行的中国人有一家三口，从法兰克福到赫尔辛基有两位似乎是转机回国的中国学生和另一位似乎是入欧洲籍的女生，其他均未看到亚洲面孔。在自我隔离期间，估计更是见不到了。但正如上次在斯德哥尔摩的机场一样，中文广告到处都是，只不过之前是华为，这次变成了工商银行的全球换汇。直觉告诉我，这意味着中国和北欧三国之间存在着潜在的合作市场。这个对大多数国人而言都稍显陌生的国家，借由诺基亚、幸福指数、教育、平权和Linux被慢慢认识的地方，可能有着我们需要认真学习的技术和思想。"
  },
  {
    "objectID": "posts/travel-to-helsinki/index.html#尾声",
    "href": "posts/travel-to-helsinki/index.html#尾声",
    "title": "启程赫尔辛基",
    "section": "尾声",
    "text": "尾声\n兜兜转转，在这个特殊的时间节点来到欧洲，也算是圆了一个长久以来的梦想。我们总希望把所有事情都提前规划好，然而生活，本就是不确定的，正如量子力学展现在我们面前的现实一样。人生需要规划，也需要调整。一杯敬故乡，一杯敬远方：眼里有光，心里有方向。"
  },
  {
    "objectID": "posts/tv/index.html",
    "href": "posts/tv/index.html",
    "title": "TV Display Techniques Review",
    "section": "",
    "text": "Plasma 等离子体\n\n比LCD亮度更高，适合户外大屏\n响应快（~ O(μs), compared to O(ms) for LCD）\n显示原理无电磁场介入，抗电磁干扰\n耗电（&gt; 300 W），烧屏\n难以小型化，制造工艺复杂\n\nLCD: Liquid Crystal Display 液晶显示器\n\n偏振片，液晶\n根据电压施加方向细分为VA（施加电压呈垂直螺旋状偏转）、IPS（施加电压呈垂直螺旋状偏转）、TN（施加电压呈垂直旋转）\n\nQLED是在LCD的基础上对背光进行改进，实现更广色域显示。但是QLED仍属于LCD范畴，和OLED完全不同。\nmini-LED也是LCD范畴。所谓mini，指的是分区背光而非整体背光。此类技术在局部亮域从侧面看会有光晕效果。\nLED: Light-Emitting Diode 发光二极管\n\n新的技术研究方向逐渐转向LED\n基础单元为发光二极管，电流强度决定亮度，单色。为显示彩色，每个像素点有红、绿、篮三种灯珠。\n\nOLED: Organic LED\n\n微型LED的一类，对比度极高，无光晕。\n在薄膜电路上涂抹荧光材料，发出三色光。可单独控制每个像素的背光。\n容易实现曲面屏、折叠屏。\n有机材料寿命短，不同颜色材料损耗不同-&gt;烧屏。\nQD-OLED用量子点技术解决不同材料寿命不同的问题。\n\nmicro-LED\n\n无机材料\n灯珠可以做得够小，但巨量转移技术成本较高（把大量灯珠放置在基板上）"
  },
  {
    "objectID": "posts/boulder/index.html",
    "href": "posts/boulder/index.html",
    "title": "科罗拉多杂记",
    "section": "",
    "text": "用一周，了解一座城。\n因为开会的缘由，第一次来到Colorado, Boulder。Denver号称one mile city，因为她恰好在海拔一英里的地方；Boulder在Denver的西北面，离落基山脉更近，海拔也再稍高一些。早上四点半就起床赶早班飞机，飞行三个小时到Denver，当地时间恰好八点。一路顺利地在学校学生宿舍入住，也不过十点前后，但要按美东时间算其实已经正午。脚还没抻利索就被同学约着去吃brunch然后hiking，为了这顿饭，还没登山呢，就走了一个小时有余。一两点钟，顶着今夏Boulder最毒一天的太阳，我们走上了市中心附近的Sanita峰的登山道。这里有一种被裹挟的感觉，若是一个人，绝不会选择在又累又困的时间爬几个小时山路的；但是有一群师弟同学围着，似乎又觉得这劳累算不上什么。我们走走停停，缓步前进，终于在一个半小时登上了最高点。这里能俯视Boulder全市的风景，远远地还能看到我落脚的学生公寓。想着自己几个小时前还在那么远的地方，这么一步一步走到山上，着实是不容易。下山的时候背包里的水也喝完了，受着阳光的炙烤，隐隐感到有些幻觉。最后靠着意志力强撑上师弟的车，冲进麦当劳对着无限续杯的饮料干了三杯醒了醒神。那时已是五点，从我起床算起一经十四个小时了。找了家中餐馆吃了晚饭，回到住处买好洗漱用品，这会都没开始呢就晒得黝黑折腾了一天，也真是年轻时候放浪形骸的生活。\nAbby她们一起去了MOP的招待会，我爬完山下来一身臭汗困饿交加只好婉拒她们通行的邀请。社交是重要的一环，可我总是听不起劲头。人性生来如此，也不必勉强。\nBoulder的城市规模和Ann Arbor很接近，但是风格却大相径庭。它们的房子比安娜堡还要矮，学校主体以西边的红砖房为底，却看上去比密歇根的砖来得更鲜亮活泼。城市四处是自行车道，一看便知是座自在骑行的城市。高海拔使得山上为数不多的乔木以针叶树为主，在其余灌木的覆盖之外便是裸露在外的岩石。在密歇根，你根本见不到这样的风景。\n认识了位研究木星内磁层的日本女生,聊天中得知也是第二次参加MOP，着实惊艳到了我。真的好漂亮，我果然还是更加欣赏东方女性的美。\n连着两天的世界杯半决赛，恰逢开会的午间休息，于是大家就一起在报告厅里看球。贾老师果然真球迷，利索地掏出笔记本，连上VPN，连上网络直播的动作麻利干净。在座的不少英法比利时同胞，不知道有没有克罗地亚的同行。克罗地亚今天加时逆转，结束哨响时，会场里也响起了阵阵掌声，对双方的表现表示敬意。\n从傍晚开始，精彩的生活才要上演。沿着傍溪的路逆流而上，见着人们三五成群地在水花间嬉戏；自行车和跑者络绎不绝，小路两旁的高大树木遮出了斑驳的阴影。路的尽头接上了Boulder的市中心，到处都是下午到晚上畅饮的醒目标识。主街名为珍珠巷，酒吧餐厅书店冷饮、饰品玩具帽子服饰一应俱全。据说市中心源于当年火车通行的地方，哪里有站，哪里才有商业。如今车站早已不见，但一份精致的繁华却保留了下来。我奔着一家叫邹妈妈的小食店而来，品尝完后还是略有些失望：虽然一碗炸酱面还不错，但店内夕晒太热，东南亚裔的店员叫不出我的名字，冰绿茶并不好喝，都让我的评价打了折扣。用晚餐沿着珍珠巷自西向东而行，乡村的吉他、儿童的街舞、老人身着民族服饰脚挂铃铛的木棍舞、还有不明所以举止诡异的欢乐青年，一出一出的，彰显着小城的生机。\n我在一家书店里驻足了许久，一个爸爸带着他的三个女儿也在里面选购书目。孩子们还在看书，真是对当下最大的安慰。我在地下的书柜上翻到了基本编程的数目，既有传统的Win10手册一类，也有面向青少年的java忍者游戏。据说00后都会编程，不知道是否真的如此。粗略翻了一本Stephen Wolfram写的Wolfram语言介绍，大都是一行的例子，应用范围之广完全出乎我的意料。想起跟陈楚争论未来是Matlab还是Mathematica的天下，看来唯有知己知彼，才能有所取舍——站队和信仰，时常是盲目的。\n临近夜色降临，褪去了白天的炎热，鲜艳的红砖在绿色植被的包裹下也显得温暖而可爱。路过物理系的门口，看到一块石板上刻着五位诺奖得主的名字，且都是近二十年的事情。这是一所有朝气的大学。\n周五的时候赶上了一个叫Red Rock的乐队在学校橄榄球场Bolsom Field举办演唱会，平时不知道躲在哪里的人们一下子都冒了出来，两天前路过时还是空空荡荡的街道一下子变得沸腾异常。在场馆外还有卖各种杂物的小摊儿，一时都让人捉摸不透到底是什么活动。提供给普通学生的运动馆径直走五分钟就到了，可由于活动封路，绕道竟花了二十分钟。\n忽的想起Vasylunnas会在晚上举办音乐会，演奏管风琴（organist）。他讲英语我几乎听不懂，年纪大了走起路来也是小踱慢步，可就是实实在在的科学巨擘。我猜他也是崇拜爱因斯坦的吧，把一门古典乐器也练到和专业水平相差无几。\n运动馆每逢周五做活动，所有项目全免费。他们这里的设施非常齐全，甚至比密歇根的都要好一些。从二楼篮球场的落地窗向北望去，一片苍茫的绿色，所有的房子都隐藏在树丛和高山之间，你甚至都以为所在之处便是城市的尽头。七八点钟夕阳斜照，这一框囊括了余晖下的高原美景。\n最后的一天最是闲散。周六虽然仍是七点不到就被朝阳唤醒，但终得以慵懒到九点起床。我又一头扎入了校园，走访了自然历史博物馆和图书馆。这个博物馆，算是同类型里在美国逛的第三了吧，也是最小的一个。一层讲考古发现，一层讲动植物细菌，再一层……就没了。但是，我看出来了每个部分都做得很细心，没有一个坏掉的仪器，着实是难能可贵。出来后紧接走访了图书馆，发现了些很有意思的东西。期间路过了教育学院，看到了他们建院院长的留言：If you still aim for a better world, the best should teach。接着是图书馆西门正上方的告诫：One who only know his own generation remains still a child。正逢暑假的周末中午，图书馆里很空，却不乏像我一般的游客。我随意走着，就扫过了一排中文书架，书目名录着实令我震惊：《资治通鉴》、《明史》、《山海经注》、《四库全书》……他们号称是这附近最大的图书馆，我真的好奇这附近究竟有多大。我突然有兴趣会安娜堡翻翻自家学校图书馆的中文藏品。\n我前前后后在校园里走了三回，已然可以不用地图穿梭自如。纵观我走过的大小校园，Boulder可以实实在在地与任一所争锋。于无声处听惊雷。\n这边的空间方向有两位中国教授，其中一位楚xinzhao老师，在学生口中也快成了段子手的存在。她做的是电离层，传说中自诩精通六大领域，电离层却不在列；手下原来科大学生众多，一训起学生来就是“90后，独生子女，南方人”的标签；时不时要来个学生发顿火，不止一次被好事的大师兄健哥提前准备好录了下来。前一阵出去开会给清雨的老板捧场，结果问出的问题是“你们做这个研究有什么物理意义”……她跟手下学生强调，白天加班，晚上做实验（她们做激光雷达的，常常需要半夜），讨论问题要定量化。昊楠的老板鲁贤算是她的嫡系师弟吧，有个几岁的女儿，调皮捣蛋好动。传说Xinzhao 一次见到这个女娃，给她做了一个实验：看她坐在椅子上能维持几秒不会动。后来结论出来了，7秒。一日她跑到学生的办公室闲聊，说起这个女娃：“她啊，有点神经质，坐不住，最多维持7秒静止……你们看看这照片，是不是跟我还有点像？”那个学生一愣，思忖着是说长得像呢还是神经质的像，忽然醒悟了，连说“像，像，太像了～”这个学生没多久转了方向，去做材料了，走之前跟Xinzhao一阵促膝长谈。彼时Xinzhao心气甚高，怼天怼地，自认诺贝尔奖不在话下，听闻学生要走，不由心头一紧。她从人类的起源讲起，不知怎的就扯到了电离层关乎人类的未来。她苦于身上六大技艺后继无人，若是自己哪天驾鹤西去了便成了人类的损失。这学生一听自己换个领域和老板都扯上全人类的损失了，眼前一黑，赶紧找了个办法结束了谈话。哦对了，据说她当时还念叨着，“你说我这好好的，怎么就得了高血压呢……”\n加上当年出新非线性的脑子和钓鱼、气功、女儿三大神器，这锅，估计得扣在北大的头上。\n最后聊聊饮食。我实在是不敢恭维美国高校的食堂，此处的学生食堂更是把“美食荒漠”发挥到了新的高度。幸好我只是碎碎念，幸好我只用呆一周。期间尝试了三家中餐，也真是各有奇葩：第一家Five Spice台湾老板娘，菜还凑合，但更惊人的她的自信。我们讨论着点哪个豆腐，我问她有没有推荐的或者拿手的，她上来一句“哪个都擅长，哪个都好吃”。我应一句“这么自信”，她马上接着“没有底气这么会来开店”。最终我们一个豆腐菜也没点。那个三杯鸡已让我瞧出了所谓水平，我们也没饿到非要多加个豆腐不可。诚然，她不懂美食。第二家光顾的，是步行街上的小面馆。东西还是地道的，可面朝着猛烈夕晒无动于衷，而且叫不出我的名字的店员，也是美中不足之处。最后这家，中文叫“有名面馆”，在主校园的西边。在这门可罗雀的店面里，我品尝了最没人道的越南米粉，和最冷漠的服务。她明明听着我说话，却要我写字；她明知道我误解了点单的意思，却什么都不说；她看着我5选2的配菜之要了2个，分量却和5个中的2个别无二致；我想着算了吃完吧，刚放下碗筷，一只苍蝇就自觉地降落在筷子上——我毫不犹豫地在谷歌地图给了它们家最低的评分。并非所有的劳动都应得到尊重：有些人，不过是行尸走肉般地活着。\n或许我不该苛责，但世界看在眼里。"
  },
  {
    "objectID": "posts/nushell/index.html",
    "href": "posts/nushell/index.html",
    "title": "Nushell",
    "section": "",
    "text": "I am glad to see the evolving of modern shells. I enjoy using zsh, but now there are even fancier ones: nushell. It highlights three features:"
  },
  {
    "objectID": "posts/nushell/index.html#more-than-a-shell",
    "href": "posts/nushell/index.html#more-than-a-shell",
    "title": "Nushell",
    "section": "More than a shell",
    "text": "More than a shell\nFrom what I can tell by reading the documentation, scripting in nu is like programming in a compiled language. The developers of nu are ambitious: they want to incorporate some parts of data processing into a shell, but the question is, is it worth to rely on a shell language instead of a more powerful language for data analysis?\nAnyway, it already feels like an exciting CLI tool to use. And it is written in Rust!"
  },
  {
    "objectID": "posts/nushell/index.html#prompt",
    "href": "posts/nushell/index.html#prompt",
    "title": "Nushell",
    "section": "Prompt",
    "text": "Prompt\nPrompt is what you see when you type a command. It can show a lot of useful tips, saving your time and making user experience smooth and pleasant. starship is a shell prompt written also in Rust that works smoothly with nushell."
  },
  {
    "objectID": "posts/language/index.html",
    "href": "posts/language/index.html",
    "title": "语言小论",
    "section": "",
    "text": "晚上Maxime谈论起法语中的阴性词和阳性词，我问他这有什么规律可寻吗。他说完全没有，就是说多了一个一个记下来就好；如果你用错了也没关系，反正大家都听得懂。而如果是个外国人讲错了就更无所谓了，他说完全不会由于这个去评价这个人如何。这倒是让我思考起语言中语法规范的严谨性和通俗性。其实现在各个国家的语言，细究起来都难言“规范”，总是存在着各式各样的习惯用法以及不成文的规矩，打破一般性原则的构词、时态语态和词组顺序比比皆是。这里的深层次逻辑是，用的更普遍的，而不是更规范的，才是语言。如果一个词语被当代的大多数人用错，那就将错就错好了，没有必要强行统一到前些时代的意思和用法。此处的逻辑，更多的是体现尊重世风民俗。几十年前曾经有人试图创造一门世界语，最终无人问津，不是由于这语言设计得不好，而是由于没人说。如今世界上最通用的英语，可能我们会以为流行的原因是简单易学，实际上是我们学太久习惯了，其间的各种时态语态变化细究起来规律总有例外，可一点都不简单。\n类比于编程语言，为了实现科学系统性，我们不能像一门日常说的语言一样肆意发挥而无定数，所以有了更加严格的语法和规范。但这并不是说同一个功能实现只有一种表述：在众多的编程语言中，我们或多或少可以在基础语法层面用不同的语句实现同样的功能，而这个度完全取决于这门语言的设计者的个人品味。放之于程序中，你也可以借由写得千奇百怪的过程实现同样的结果，撇开架构不谈，即便仅仅是变量（名词）和函数（动词），就会有不同的选择甚至是随便选择。北欧语言普遍喜欢极长的名词，反映在代码中可能就会是极长的变量和函数名。但我见识过美国人也使用极长的变量和函数名字，所以这绝不是什么孤立现象。相反地，有一些人，尤其是早期写代码的科学家，喜欢极短的如同数学符号一般的名字，比如i,j,k,a,b,c一类的，再往上叠就是ii,jj,kk，看得也是让人一头雾水。这些语言中不起眼的角落，也是最难统一规范的部分，全靠个人的习惯来把握到底多少是冗余多少是过简，什么才是适中的区间。\n在总体上掌握了英语以后，由于没有迫切的需求，很难有充足的动力去学习另一门新的语言。但 如果真学习一门新语言，我的思路跟一开始上课学英语会有很大区别。相对而言，我会非常重视名词和动词，同已知的语言建立映射关系，然后才会去考虑形容词、副词、连词这一类和情感认知相关的部分。类似的对于新的编程语言，无论再如何猎奇，都需要回归基础数理逻辑，或且非加上循环判断递归，辅以和计算机硬件之间的联系，就可以很快上手。在这之上的，比如程序里起个名字或长或短，弄个类型或杂或精，写个循环或快或慢，都是好像文章品味一样的东西，好坏时常难以量化，每个人心里却多少有一个标准。没有人规定鲁迅的文章就是好文章，但我们都喜欢读，就演变成一种美学范式了；某些文章可能佶屈聱牙但也是文章，读是可以读，但就是差那么点意思。\n有些东西我们以前无法度量，现在无法度量，可能以后依然无法度量。世界不总是精确的，反倒是模糊得可爱。"
  },
  {
    "objectID": "posts/python/index.html",
    "href": "posts/python/index.html",
    "title": "Advanced Python",
    "section": "",
    "text": "Good languages stop you from writing stupid codes; bad languages allow you to write more stupid codes. Do not live on ancient code until death! Latest things are not necessarily better: balance between new technology and old experience.\nEven though I think Python is slow, it does not mean that I cannot learn it or learn from it. Now it seems more and more obvious to me that there are some neat advanced tricks you can do in Python.\nNew things are cool. However, they don’t always work. For example, pytorch hasn’t been able to work with Python 12 two months after its release."
  },
  {
    "objectID": "posts/python/index.html#installation",
    "href": "posts/python/index.html#installation",
    "title": "Advanced Python",
    "section": "Installation",
    "text": "Installation\nMore often than not I find myself unsatisfied with the default Python or package version on a target machine. In these cases we may want to install Python ourselves. If any of the following commands require higher privileges, simply add sudo in the front and type your password.\n\nDownload source code:\n\nwget https://www.python.org/ftp/python/3.12.10/Python-3.12.10.tgz\n\nExtract archive:\n\ntar xzvf Python-3.12.10.tgz\n\nConfigure Makefile:\n\n./configure --enable-optimizations --enable-shared\nOr more specifically, assuming you put the source code into /home/hyzhou/bin/Python-3.12.10,\n./configure \\\n    --prefix=/home/hyzhou/bin/Python-3.12.10 \\\n    --enable-shared \\\n    --enable-optimizations \\\n    --enable-ipv6 \\\n    LDFLAGS=-Wl,-rpath=/home/hyzhou/bin/Python-3.12.10/lib,--disable-new-dtags\n--prefix is used to set the custom installation directory.\n--enables-shared is important for external programs calling Python methods and APIs on the binary level (e.g. using PyPlot from Julia).\n\nCompile and install:\n\nmake altinstall\naltinstall is used to prevent replacing the default python binary file /usr/bin/python.\nmake\nmake install\n\nCheck:\n\npython3.11 -V\npython3.11 -m pip --version\nIf on Windows, it would be as simple as downloading the official executable file and follow the installer.\n\nPackage Manager: PIP\nThe default package manager for Python is pip. It can be installed following the guideline or via the installation manager app. It is recommended to use pip as\npython3.11 -m pip install -U matplotlib\ninstead of calling pip alone to prevent mismatch of pip and python version.\n\n\nDependency Manager: Poetry\nPoetry is a dependency manager. I should use poetry over pipenv if possible.\nUse pipx to install poetry for avoiding self update issues.\nOptional dependencies are not installed by default:\nD:\\Computer\\pyvlasiator&gt;poetry install\nInstalling dependencies from lock file\n\nPackage operations: 0 installs, 0 updates, 7 removals\n\n  - Removing contourpy (1.3.1)\n  - Removing cycler (0.12.1)\n  - Removing fonttools (4.55.0)\n  - Removing kiwisolver (1.4.7)\n  - Removing matplotlib (3.9.2)\n  - Removing pillow (11.0.0)\n  - Removing pyparsing (3.2.0)\n\nInstalling the current project: pyvlasiator (0.1.0)\n\nD:\\Computer\\pyvlasiator&gt;poetry install --all-extras\nInstalling dependencies from lock file\n\nPackage operations: 7 installs, 0 updates, 0 removals\n\n  - Installing contourpy (1.3.1)\n  - Installing cycler (0.12.1)\n  - Installing fonttools (4.55.0)\n  - Installing kiwisolver (1.4.7)\n  - Installing pillow (11.0.0)\n  - Installing pyparsing (3.2.0)\n  - Installing matplotlib (3.9.2)\n\nInstalling the current project: pyvlasiator (0.1.0)\nWhile using pytest, any Python scripts with test in their name will be executed.\nWhen a new version of a dependent package is released in PyPI, poetry does not automatically update its cache. To manually synchronize the package version list, first cleanup the cache:\npoetry cache clear --all .\nand then update:\npoetry update\n\n\nDependency Manager: uv\nuv is the most advanced package manager for Python now. It can be used as a direct replacement for almost all the other tools like pip, pipenv, and poetry.\nThere are tools like migrate-to-uv for converting the pyproject.toml to the uv version. Other usages are similar to poetry.\n\nRegistering in PyPI\nFollow this guide.\nOn Windows, put .pypirc under C:\\Users\\YourName\\.pypirc for avoiding typing API-tokens when uploading.\npython -m build\npython -m twine upload dist/*\nInstall from PyPI:\npython -m pip install pyvlasiator\n\n\n\nVirtual Environments\nIt is possible to handle your customized Python packages with Virtual Environment at a lower level. While pipenv is attached to a specific Python version, virtual environments completely isolate the python executable as well as all the required packages. The basic workflow is:\n\nFind a specific Python version\nCreate a directory for your packages, e.g python352\nvirtualenv python352 to start the virtual environment\nsource bin/activate to activate the virtual environment\nmodule load Python/3.8.6-GCCcore-10.2.0\npip install --prefix python352 mypackage to install the required packages\n\nTo leave virtual environments, just say deactivate.\nmodule load Python/3.8.2-GCCcore-9.3.0\nvirtualenv ~/proj/virtual_python3.8.2/\nsource /home/hongyang/proj/virtual_python3.8.2/bin/activate\nHowever, see [Conda][#miniconda] for a better approach.\n\n\nMiniconda\nI found conda, or miniconda a more reliable way to handle packages as a bundle. Even miniconda is pretty large though (claimed to be 300 MB when first installed, but quickly became 3GB+). Miniconda comes with its own Python version and pip tool.\n\n\nvenv\nvenv is available by default in Python 3.3 and later, and installs pip into created virtual environments in Python 3.4 and later (Python versions prior to 3.12 also installed Setuptools)."
  },
  {
    "objectID": "posts/python/index.html#recap-of-the-basics",
    "href": "posts/python/index.html#recap-of-the-basics",
    "title": "Advanced Python",
    "section": "Recap of the basics",
    "text": "Recap of the basics\nLet’s start from some common operations that for non-native Python programmers like me can be easily confused.\nx = [1,2] # in native Python, there is only list type, no array/vector type\ny = [3,4]\nls_sum = x + y # [1,2,3,4], similar to [x;y] in Julia\na = [0] * 2 # equivalent to repeat([0], 2) in Julia \nVariable bindings:\nx = [1,2]\ny = [3,4]\nz = x\nx += y # equivalent to append!(x, y) in Julia, not x = [x;y] because of z\nfor i in range(istart:iend) # equivalent to istart:iend-1 in many other languages\n   ...\nx = [1,2,3,4]\nx[-1] # equivalent to x[end], i.e. the last element\nBy default Python adopts arbitrary precision arithmetic to avoid overflow issues. This is not the case for most languages.\nOk, now we move on to talk about some cool stuffs and tricks in Python."
  },
  {
    "objectID": "posts/python/index.html#type-hint",
    "href": "posts/python/index.html#type-hint",
    "title": "Advanced Python",
    "section": "Type hint",
    "text": "Type hint\nAfter Python 3.5, you can now add type hints to function arguments. This will help you guarantee that the correct argument types have been passed. Besides avoiding bugs, it is also very helpful for automating the translation from Python to other languages.1\nPython从3.5版本以后也支持函数参数的类型指定了。看来MATLAB和Python也都在逐步改进啊。但是这个只是用来做标记的，实际运行的时候不会检查；所以我们需要一个static type checker。在3.8版本以后有专门的原生库支持这项功能。"
  },
  {
    "objectID": "posts/python/index.html#function-arguments",
    "href": "posts/python/index.html#function-arguments",
    "title": "Advanced Python",
    "section": "Function arguments",
    "text": "Function arguments\nThe flexibility of Python can be reflected from the fact how function arguments work. You are allowed to mix position args, keyword args, and varargs all together. Check this video for more!"
  },
  {
    "objectID": "posts/python/index.html#decorators",
    "href": "posts/python/index.html#decorators",
    "title": "Advanced Python",
    "section": "Decorators",
    "text": "Decorators\nThis is really cool stuff. In Julia they are called macros, but essentially the same thing. In computer science, they belong to the category of metaprogramming. Decorator allows you to modify the raw code before the interpreter comes in to “decorate” your code. This applies to, for instance, the implementation of memoization, dataclass after Python 3.7, logging wrapper and many more. I have also seen this in ParaViews’ Python interface.\nTo be a master in Python, you have to use it elegantly.\n@property\n@total_ordering\n@dataclass"
  },
  {
    "objectID": "posts/python/index.html#scripts-vs-methods",
    "href": "posts/python/index.html#scripts-vs-methods",
    "title": "Advanced Python",
    "section": "Scripts VS Methods",
    "text": "Scripts VS Methods\nFor a script, alway add\nIf __name__ == '__main__':\n    main()\nto the end! This is a good practice\n\nTo tell users that this is a script that can actually run, but not a library\nTo avoid accidental global variables\nTo make your script runs faster (because it’s inside a function)"
  },
  {
    "objectID": "posts/python/index.html#fstrings",
    "href": "posts/python/index.html#fstrings",
    "title": "Advanced Python",
    "section": "fstrings",
    "text": "fstrings\nThis is introduced after 3.6, which is a new way to handle string outputs.\nname = \"Eric\"\nage = 74\na = 10.1234\nprint(f\"Hello, {name}. You are {age}.\")\nprint(f\"{2 * 37}\")\nprint(f\"{name.lower()} is funny.\")\nprint(f'{a:.2f}') # '10.12'\n\n# Multiline f-Strings\nname = \"Eric\"\nprofession = \"comedian\"\naffiliation = \"Monty Python\"\nmessage_oneline = (\n    f\"Hi {name}. \"\n    f\"You are a {profession}. \"\n    f\"You were in {affiliation}.\"\n)\n\nmessage_multiline = f\"\"\"\n    Hi {name}. \n    You are a {profession}. \n    You were in {affiliation}.\n\"\"\""
  },
  {
    "objectID": "posts/python/index.html#dataclasses",
    "href": "posts/python/index.html#dataclasses",
    "title": "Advanced Python",
    "section": "DataClasses",
    "text": "DataClasses\nWow, this is a great alternative in many situations to the traditional classes after 3.7! The main advantage is to avoid boilerplate codes.\nfrom dataclasses import dataclass\n\n@dataclass\nclass Person:\n    name: str\n    address: str\n    active: bool = True\n    email_addresses: list[str] = field(default_factory=list)\n\ndef main() -&gt; None:\n    person = Person(name=\"John, address=\"123 Main St\")\n    print(person)\nBonus tip: Python class properties can be read-only by making them immutable.\nfrom dataclasses import dataclass\n\n@dataclass(frozen=True)\nclass Person:\n    name: str\n    address: str"
  },
  {
    "objectID": "posts/python/index.html#special-numbers",
    "href": "posts/python/index.html#special-numbers",
    "title": "Advanced Python",
    "section": "Special Numbers",
    "text": "Special Numbers\nIf I remember correctly, the integers -5-256 are treated differently (hard-coded, i.e. always refer to the same constants):\na = 2\nb = 2\na is b # true\nc = 257\nd = 257\nc is d # false\nNote that this is NOT the case in Julia. (Check with ===.)"
  },
  {
    "objectID": "posts/python/index.html#numpy",
    "href": "posts/python/index.html#numpy",
    "title": "Advanced Python",
    "section": "Numpy",
    "text": "Numpy\nOne lesson I learned about Numpy was that it is very tricky to mix numpy types with intrinsic Python types. To convert a numpy type to an intrinsic numeric type, we need the item() method:\nimport numpy as np\na = (4, 4, 4)\nb = np.prod(a) # &lt;class 'numpy.uint64'&gt;\nc = np.prod(a).item() # &lt;class 'int'&gt;\nA practical application is whether we should use tuples or numpy arrays to store coordinates. Unlike Julia where the compiler can specialize tuples, Python tuples can contain any type of elements which is less efficient in storage. numpy arrays guarantee the consistence of the type of each array, which makes it a better choice for storing coordinates. However, the downside is that numpy arrays are mutable. To overcome this, we can set the WRITEABLE flag for the array to False:\nimport numpy as np\n\na = np.arange(3)\na.flags.writeable = False\n\n# a[0] = 0\n# ValueError: assignment destination is read-only\nThis makes numpy arrays immutable!"
  },
  {
    "objectID": "posts/python/index.html#ellipsis",
    "href": "posts/python/index.html#ellipsis",
    "title": "Advanced Python",
    "section": "Ellipsis",
    "text": "Ellipsis\nPython has a special literal called Ellipsis, or .... It is used for several different purposes:\n\nAs a convenient slice notation, especially with Numpy:\n\nimport numpy as np\n\ndimensions = np.random.randint(1,10)\nitems_per_dimension = 2\nmax_items = items_per_dimension**dimensions\naxes = np.repeat(items_per_dimension, dimensions)\narr = np.arange(max_items).reshape(axes)\nIn this example, you’re creating an array that can have up to ten dimensions. You could use NumPy’s .ndim() to find out how many dimensions arr has. But in a case like this, using ... is a better way:\narr[..., 0]\nCheck out NumPy: Ellipsis (…) for ndarray to discover more use cases for these three little dots.\n\nAs a type hint for homogeneous types or substitute for a list of arguments to a callable:\n\nnumbers: tuple[int, ...] # must be a tuple that contains only integers\n\n# Allowed:\nnumbers = ()\nnumbers = (1,)\nnumbers = (4, 5, 6, 99)\n\n# Not allowed:\nnumbers = (1, \"a\")\nnumbers = [1, 3]\nUsing ... within a tuple type hint means that you expect all items to be of the same type in the tuple.\nfrom typing import Callable\n\ndef add_one(i: int) -&gt; int:\n    return i + 1\n\ndef multiply_with(x: int, y: int) -&gt; int:\n    return x * y\n\ndef as_pixels(i: int) -&gt; str:\n    return f\"{i}px\"\n\ndef calculate(i: int, action: Callable[..., int], *args: int) -&gt; int:\n    return action(i, *args)\n\n# Works:\ncalculate(1, add_one)\ncalculate(1, multiply_with, 3)\n\n# Doesn't work:\ncalculate(1, 3)\ncalculate(1, as_pixels)\nBy using `Callable[…, int]``, you say that you don’t mind how many and which types of arguments the callable accepts. Yet, you’ve specified that it must return an integer.\n\nAs a “nop” placeholder for code that hasn’t been written yet:\n\ndef will_do_something():\n    ..."
  },
  {
    "objectID": "posts/python/index.html#footnotes",
    "href": "posts/python/index.html#footnotes",
    "title": "Advanced Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTranspiler of Python to many other languages↩︎"
  },
  {
    "objectID": "posts/fourier/index.html",
    "href": "posts/fourier/index.html",
    "title": "Fourier Analysis",
    "section": "",
    "text": "I hate it when people make simple things complicated, and complicated things impossible.\nLet’s follow Mark A. Kramer’s short course An Introduction to Field Analysis Techniques: The Power Spectrum and Coherence. I also have a copy in my Google drive."
  },
  {
    "objectID": "posts/fourier/index.html#dc-offset",
    "href": "posts/fourier/index.html#dc-offset",
    "title": "Fourier Analysis",
    "section": "DC Offset",
    "text": "DC Offset\nFor many signals which involve large DC offsets, a raw FFT would often result in a big impulse around frequency 0 Hz, thus masking out the signals of interests with relatively small amplitude.\n\nThere are two methods to remove DC offset from the original signal before performing FFT:\n\nUsing FFT High-Pass Filter\nSubtracting the Mean of Original Signal\n\nAlternatively, you can erase the power in the 0 Hz band after performing FFT."
  },
  {
    "objectID": "posts/fourier/index.html#coherence",
    "href": "posts/fourier/index.html#coherence",
    "title": "Fourier Analysis",
    "section": "Coherence",
    "text": "Coherence\nProblem at hand: brain recordings often consist of multiple sensors, and recent advances in recording technology promise observations of brain activity from many sensors simultaneously. How do we make sense of these large, simultaneous, multivariate recordings?\nFor simplicity, let’s consider time series recorded simultaneously from two sensors during a task. To characterize these data, we compute the coherence. Coherence is a measure of the relationship between x and y at the same frequency. The coherence ranges between 0 and 1, \\( 0 _{xy,j} \\), in which 0 indicates no coherence between signals x and y at frequency index j, and 1 indicates strong coherence between signals x and y at frequency index j.\n\\[ _{xy, j} = \\]\nwhere\n\\[ &lt; S_{xy, j} &gt; = {k=1}^K X{j,k} Y_{j,k}^ \\]\nand \\( X_{j,k} \\) is the Fourier transform coefficient of \\( x_k \\) at frequency with index j. k is the trial index, and K is the total number of trials of data from each sensor.\nWe also call this the coherence in the frequency domain. One step further, we shall consider the coherence in the time-frequency domain, as mentioned below."
  },
  {
    "objectID": "posts/fourier/index.html#time-frequency-coherence",
    "href": "posts/fourier/index.html#time-frequency-coherence",
    "title": "Fourier Analysis",
    "section": "Time-Frequency Coherence",
    "text": "Time-Frequency Coherence\nWhen calculating coherence we assume stationary signals. If the signals are non-stationary, (and therefore not ergodic), the above formulations may not be appropriate. For such signals, the concept of coherence has been extended by using the concept of time-frequency distributions to represent the time-varying spectral variations of non-stationary signals in lieu of traditional spectra.\nThe time-frequency coherence (TFC) is defined to dealing with measuring the properties of nonstationary processes.\n\\[ C_{xy}(t, f) = \\]\nThere are usually two representations of the analysis in time-frequency domain:\n\nanalytic signal resulting from Hilbert transform\nwavelets\n\nHere we talk about the analytic signal approach.\n\nThe analytic signal\nThe analytic signal representation of time-series x has the form \\( z = x + iy \\), where y is the Hilbert transform of x. z is a complex signal in the time domain with the same sampling rate as the original signal. By applying a filter bank to the signal, that is, a series of band-pass filters centered at successive frequencies f, and by computing the Hilbert transform for each filtered signal, we obtain the analytic signal in the time-frequency domain, that is, for all points \\( z_{t,f} = x_{t,f} + i y_{t,f} \\) in the time-frequency plane.\n\nBivariate Measures in the Frequency and Time-Frequency Domain\nBivariate means between two variables, or two time-series. Two popular measures are coherence and phase-coherence (also known as phase-locking value).\nFor any analytic signal \\( z=x+iy \\) at a time-frequency point or region, the auto-spectrum\n\\[ C = z z^= x^2 + y^2 \\]\nis a real quantity providing the squared amplitude (power) of the signal, i.e. the time-frequency domain equivalent of the signal variance, which is a natural measure of the signal energy. Given two analytic signals \\( z_1 \\) and \\( z_2 \\) in the time-frequency region, the cross-spectrum between them is the time-frequencyy domain equivalent of their covariance and is given by\n\\[ C_{12} = z_1 z_2^. \\]\nThe coherence measure is defined as\n\\[ = , \\]\nwhich is the equivalent of Pearson’s correlation in the time-frequency domain, taken in its absolute value."
  },
  {
    "objectID": "posts/fourier/index.html#tools",
    "href": "posts/fourier/index.html#tools",
    "title": "Fourier Analysis",
    "section": "Tools",
    "text": "Tools\n\nJulia\nThere is a FourierAnalysis.jl package. I tried to follow what are available inside that package: it’s very complicated. The author tries to be thorough in the documentation, but it’s far from perfect.\nThere is another one, SignalAnalysis.jl, which I used to generate spectrum before. I need to learn more about the pros and cons between these packages."
  },
  {
    "objectID": "posts/kalman-filter/index.html",
    "href": "posts/kalman-filter/index.html",
    "title": "Kalman Filter",
    "section": "",
    "text": "The first time I’ve heard about Kalman filter is during my exploration of image feature extraction. A MATLAB demo shows how Kalman filter can be used to track passengers in a monitor video. It was actually after a while until I realized that Kalman filter became well-known after being successfully applied to the Apollo project for inferencing the satellite orbit."
  },
  {
    "objectID": "posts/kalman-filter/index.html#example-gps-sensor",
    "href": "posts/kalman-filter/index.html#example-gps-sensor",
    "title": "Kalman Filter",
    "section": "Example: GPS + sensor",
    "text": "Example: GPS + sensor\nImagine you are driving a vehicle. Let the average of position given by GPS signal be z1, and the standard error square be σ1. A gaussian distribution N(z1,σ1) is used to describe the distribution of actual position.\nOnboard you also have a sensor that gives N(z2,σ2), which may be different from the GPS outputs. The question is: how to estimate the actual position?\nKalman discovered the most optimal estimation to be a combined normal distribution with \\[ z = z_1 + z_2 \\] and \\[ = + . \\]"
  },
  {
    "objectID": "posts/kalman-filter/index.html#example-navigation",
    "href": "posts/kalman-filter/index.html#example-navigation",
    "title": "Kalman Filter",
    "section": "Example: Navigation",
    "text": "Example: Navigation\nImagine you are sailing on the sea. At time \\( t_1 \\), you obtain the location \\( x_1 \\) and velocity \\( v_1 \\), such that you can estimate your new position after \\( t \\) at time \\( t_2 \\). Meanwhile, when you reach time \\( t_2 \\), you can measure your location and velocity again. What is then the optimal estimate of your actual location? Kalman filter.1\n\\[\n\\hat{x}_k = A \\hat{x}_{k-1} + B u_k + K_k(y_k - C(A \\hat{x}_{k-1} + B u_k) )\n\\] is the posteriori estimate where \\[\n\\hat{x}_k^- = A \\hat{x}_{k-1} + B u_k\n\\] is called a priori estimate. \\( y_k \\) is the measurement at step k.\nFor the prediction part \\[\\[\\begin{eqnarray}\n\\hat{x}_k^- &= A \\hat{x}_{k-1} + B u_k, \\\\\\\\\nP_k^- &= A P_{k-1}A^T + Q,\n\\end{eqnarray}\\]\\] where \\( P_k^- \\) is the error covariance (which increases with steps). In a single state case, \\( P_k^- \\) is just the deviation of the prediction at step k.\nThese predictions are then fed to the update step \\[\\[\\begin{eqnarray}\nK_k &= \\frac{P_k^- C^T}{CP_k^-C^T+R}, \\\\\\\\\n\\hat{x}_k &= \\hat{x}_k^- + K_k(y_k - C\\hat{x}_k^-), \\\\\\\\\nP_k &= (I - K_k C)P_k^-,\n\\end{eqnarray}\\]\\] where C is just a linear coefficent in the relation between \\( y_k \\) and \\( x_k \\): \\[\\[\\begin{eqnarray}\nx_k &= A x_{k-1} + B u_k + w_k, \\\\\ny_k &= C x_k + v_k.\n\\end{eqnarray}\\]\\]\nFor a more general form which includes nonlinearity, \\[\\[\\begin{eqnarray}\nx_k &= f(x_{k-1}, u_k) + w_k, \\\\\ny_k &= g(x_k) + v_k.\n\\end{eqnarray}\\]\\] However, note that the new difficulty here is that after nonlinear transformation, the original Gaussian distribution at step k-1 may not be Gaussian anymore, such that the Kalman filter may not converge. One first idea to overcome this issue is to use the extended Kalman filter (EKF), which linearize the system at each step.2 Obviously this won’t work well if the system is intrinsically highly nonlinear.\nA better approach is called Unscented Kalman Filter(UKF). Instead of approximating a nonlinear function, UKF approximates the probability distributions. The filter selects a minimal set of sample points such that their mean and covariance is the same as the probability distribution, and are symmetrically distributed around the mean. Then after the nonlinear transformation, the mean and covariance of the transformed sigma points are used to calculate the new state estimate.\nAnother approach which is based on very similar concept is called Particle Filter (or Ensemble Kalman Filter). It also uses sample points, referred as “particles”. A significant difference between Particle Filter and Unscented Kalman Filter is that it approximates any distribution function, not only restricted to Gaussian. This also indicates that it needs much more particles than UKF does.\nThis is in essence exactly the same application as the human tracking in the monitor videos. You measure location and speed; you predict the next location; you measure again and correct the results. However note that in the latter application, Kalman filter enables tracking the same person who may goes out of sight for a short period, which is also why it significantly improves the result."
  },
  {
    "objectID": "posts/kalman-filter/index.html#example-rocket-throttle-temperature-measurement",
    "href": "posts/kalman-filter/index.html#example-rocket-throttle-temperature-measurement",
    "title": "Kalman Filter",
    "section": "Example: Rocket throttle temperature measurement",
    "text": "Example: Rocket throttle temperature measurement\nWe need to know the temperature at the center of the throttle \\( T_{in} \\) to control the fuel injection of the engine. However, the temperature is so high in the throttle such that it is impossible to put a sensor right inside the throttle. Instead, we have to measure it from outside and get \\( T_{ext} \\). How should we proceed?\nWith prior knowledge, we can build a mathematical model with input fuel \\( w_{fuel} \\) and output \\( {in}, {ext} \\). However, the mathematical model is only an approximation to the real system, which is subject to uncertainties. Our goal here is to eliminate the difference between \\( T_{ext} \\) and \\( {ext} \\) so that \\( T{in} \\) converges to \\( _{ext} \\). This negative feedback loop is called state observer.\n\n\nActually, Kalman filter is one kind of state observer designed for stochastic system."
  },
  {
    "objectID": "posts/kalman-filter/index.html#footnotes",
    "href": "posts/kalman-filter/index.html#footnotes",
    "title": "Kalman Filter",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere is a bug for displaying LaTeX symbols like hat and widehat. I don’t know how to fix it.↩︎\nThis is where all the Jacobians, either analytically or numerically, come up. And most importantly, the system must be differentiable.↩︎"
  },
  {
    "objectID": "posts/data-vis/index.html",
    "href": "posts/data-vis/index.html",
    "title": "我与数据可视化的那点事儿",
    "section": "",
    "text": "学习工作中反复和图像打交道，更能感受到人类的视觉动物本性。五感中，视觉可谓是信息量最大的输入，也同时深入影响着抽象的思维逻辑。我们力图在复杂中寻找简单，高度提炼的数据是关键的一环。\n从事科研若干年，关于成果展示，一句经典老话：“字不如表，表不如图。”从一开始不明所以在海报里塞入大量文字，到后来转而力求简洁清晰的图像，本质上就是随着随着认知的深入能深入浅出地发掘重要信息进行归纳总结。比如现在的文献检索，当你用关键词找到若干篇备选，也不会每一遍都从头到尾地看，而是依据本身的熟悉程度寻找核心线索和结论，着重看关键的公式和图表。如果恰巧你能在一个公式或一张图中找到这样的关键信息，而无需为了诸多细节阅览全篇，你会庆幸自己遇到了个好作者。我们喜欢图像，就像是在混乱中寻找秩序的冲动。\n\n大家频繁接触数据做图多半是从中学开始学习几何以后。想着当年各种手绘解析几何的直线曲线图形，为后来的电子化做图打下了坚实的基础。这种经典的教学方式如今可能会受到电子化的冲击，但动手画图依旧是我们最快的理解方式。记得高中时候鸟蛋就开始玩儿几何画板，那对于搞奥赛平面几何简直就是神器：各种图形中涉及到的不动点、共线、共圆，手绘是静态的很难看出，但是用几何画板设几个不动点拖几下可能就出来了。在苏州参加集训的时候一次请来的老师讲课不经意之间在我们面前秀了一把操作，让台下所有学生羡煞了眼。鸟蛋一次还跟我讲拿几何画板看旋轮线轨迹，对当时的我来说已是超乎想象的了。后来认识了楚哥，自吹几何画板也是用得飞起，我信个七分，羡慕个三分。\n关于计算机绘图，个人上手最早的经历可以追溯到大一C语言作业要求的命令行输出。当时有一类练习输出的题目就是让你在命令行里画各种图形。现在有一些仿古的绘图库，比如UnicodePlots，还能让人依稀回忆起那样的图形风格。真正开始大量实践是从大学物理实验开始的，这系列课程我连上了四个学期，每学期就占1.5个学分，占用的时间和投入的经历却几乎相当于一门3学分的课程。每周一次用一个下午或者一个晚上的时间做实验，然后拿着数据按照要求一通分析，为了写实验报告经常弄得焦头烂额。一开始全电子版的实验报告还不熟练，大部分都是手写的，只是图表是用Origin做的，误差估计啥的经常是拿着计算器手算的，最后到打印店把做好的图用A4纸打出来，裁剪好贴到手写的报告上面去。到了本科高年级的物理课和研究项目中，手写的报告几乎不复存在了，无论是实地操作的仪器中采集的数据，还是计算机模拟跑出来的数据，数据分析和处理全部电子化了。大三开始接触MATLAB进行动态绘图，大四上手LaTeX折腾得死去活来但入门后蓦然回首发现公式、图表和排版竟然可以如此简单，画图这事儿就自然而然地走进了我的日常学习之中。做本科毕业论文的时候，主要的粒子模拟是用Fortran跑的，输出的格式也是自定义的，然后传到MATLAB里面画图做动画截图分析结果。\n\n研究生以后画图更成了家常便饭的活，各种project需要的图主要靠MATLAB做，而组里做研究主要靠IDL。一遍又一遍的写报告制图中，摸爬滚打学习着如何制作大小适宜、风格统一、简洁明快的图片，顺带也涉猎了大量有文档可查的功能。研一的冬季学期上了门系里的编程课，主讲老师Dan是个Python狂粉，我在这里第一次系统学习了Python并了解了著名的由已故生物学家John Hunter在2002年创造的类MATLAB绘图库Matplotlib。由于和MATLAB的渊源，我上手起来非常快，虽然不是很喜欢Python的语法，但是对Matplotlib非常认可。另一方面，IDL这门古早的语言至今还被用在大量空间物理的数据分析中，虽然我就几乎没见过年轻人说它的好话。当年理论力学课最后李毅教授曾经展示过他写的陀螺模拟程序，还有GUI界面，似乎就是IDL写的。研究生组里老板精通Fortran,Perl和IDL，用IDL写一整套的模拟数据可视化包，渡过安装的镇痛后，参照说明操作绘图倒是非常便利。然而这里的“便利”，指的是照猫画虎做既定规格的图的时候——若是遇到稍微想订制一下的出版规格的图，基于IDL的这套工具用起来真是有苦难言。当时Python已经火起来了，组里也有老师写了个Python的模拟文件处理程序，但一来我并不喜欢Python，二来这个包第一次安装时还失败了，所以就没了下文。Mathematica虽然很早就见识过它的厉害，但是我不熟，由于也更偏向符号运算，一时对我的需求也不是很多，就没有仔细折腾。远在大一的时候去曹原租住的小屋，刚进门就看见他在用Mathematica玩一个可调参数的函数，当时就被惊艳到了。同样程度的可视化通过拖拽控制槽来即时显示函数的工具，MATLAB在17年前后才引入，前后查了5年有余。更不用提后来再次惊艳我的Wolfram Alpha，虽然不怎么用，但依然感叹匪夷所思。Mathematica的创始人Stephen Wolfram是一名天才型的人物，我在校那几年和MATLAB的创始人Cleve Moler曾先后两年来过密歇根做演讲，但那天我不巧病倒了，未能去现场。\n然而没有摆脱IDL的阴影仍在笼罩。本来IDL就够难用了，老板还只用命令行的IDL，更是雪上加霜。曾经我试图修改些他写的IDL脚本，先是在自己尝试的时候连个简单的循环都不能编译，后来又是看到了Fortran66中“臭名昭著”的common block遍地横飞，全然苦不堪言。折磨两年后，17年暑假我回国，励精图治开始写一个基于MATLAB的模拟数据分析包。多年的课程锻炼让我对MATLAB绘图如数家珍，所以主要的难点在于数据格式的读入。我们组这个小作坊说来也是神奇，几乎所有的研究工具都是私人定制的，其中也包括数据格式。这格式显然是没有啥文档说明的，尤其是主要使用的二进制文件，只能靠读源代码进行分析。花了一个月，我参考老板的IDL包写出了自己的MATLAB包的雏形。这也是我真正意义上对于数据处理和绘图底层架构的入坑尝试，收获了非常多的实战经验。我第一篇文章中所有的图都是拿这个MATLAB包做的。\n在上计算流体力学的时候，我被Christof Fidkowski教授的电子版讲义深深震撼了：那是我学生生涯里见过的最好的教学讲义，甚至比很多教材都精致。他用来画概念图的那款软件我至今不得其名，但是自己后来在Mac上找到了一款叫Zebra的免费版类几何画板软件，也已经十分好用了。\n18年底，机缘巧合我结识了Julia。关于这段故事，详情可以转见Perception. 19年初，我觉得时机已然成熟，为何不写个基于Julia的模拟数据处理包呢？有了先前MATLAB包的经验，这次改写效率高了很多，基本上一个星期就完成了第一版。期间遇到的主要问题源于我对Julia的不熟悉以及Julia本身对于文件I/O底层的支持当时还不够健全（譬如read!(iostream, @view A[:,1]) 这样的操作，在Julia 1.4以前并不原生支持，需要一些hack）。然而这次改写，加上Julia本身对于绘图后端选择的强调，让我开始思考我们需要一个什么样的数据可视化包。我们可以越俎代庖般给所有的已有绘图库中的方法添加自己写的一套wrapper，并且定制所有的参数，但是这么做的代价就是出产的包异常臃肿并且难以维护：每当遇到新的情景，新的参数，你都需要在wrapper中添加相应的改动，最终的代码就会又臭又长。这里不得不提Python中令我深受启发的特殊传参方法 *args 和 **kwargs： Julia中类似的操作叫做splat operator ...，利用它，你可以很方便的为已有的方法构建简洁的wrapper。\n不久后我意识到Julia中三维绘图分析功能相比于Tecplot和ParaView来说实在是太简陋了，于是四处寻找解决办法。Tecplot是一款组里一直在使用的三维数据可视化软件，功能很强大，可惜是收费的。它的数据格式除了最新的高性能并行规格作为商业机密保密以外其它的都有详细的说明，所以组里的计算程序能够直接输出该老格式的文件。遗憾的是，这个格式并不能直接被ParaView读取。ParaView是一款业界非常出名的三维可视化开源软件，同他的兄弟VisIt一样师出VTK，也已经深耕了二三十年。VTK则是一套历史悠久的计算机图形学底层库，定义了诸多基础几何结构的表示方法，也是现在诸多可视化的软件的基石。这时候我也临近毕业，一心的想法就是不能栓死在付费小众软件上，而应向着更通用的格式靠拢，于是详细了解了VTK的基本格式，包括传统的和现代基于XML的，并且上手了ParaView的操作流程。更巧的是，一位Julia社区中的法国人搞出了一个生成基于XML格式的VTK文件的开源包，打通了最后一个关节。虽然从Tecplot的PLT到VTK格式转换需要些时间，但是受惠于XML中的压缩算法文件大小可以减小2-10倍，在我看来是非常重要的优势。这里的逻辑有点绕，但结局是我搭好了Julia+ParaView的可视化分析生态，并成功应用到了第二篇科学文章的数据分析之中。\n\n当我开始芬兰的博士后工作后，这边的组里又是一套全新的C++代码+数据格式+自定义Python包。如果是个写的好维护的好的Python包我也就直接用了，可是我进组两个月屡次要求开发者在文档缺失的情况下给一个绘图包的使用教学，一路被各种莫名其妙的借口拖到看不见尽头……我一念之下自己动手从零开始用Julia写了一个新的。所幸这次数据格式的文档还不错，Python理解起来也不难，第一版的数据读取+简易绘图模块大概两周弄出来了。这次的新挑战在于，原先的Python代码头重脚轻的逻辑让我看得连连叹息：在读取数据这块，它定义了Python class中最核心的方法是一个通用参数的接口，之后在各个地方再调用基于这个通用方法的实现。众所周知，Python是一门本来就不是以速度闻名的动态语言，这么一折腾更是代码又长运行又慢。如果我照着原样翻译一遍，当然可以立刻在Julia中运行，但是运行效率上一定是没谱的。于是凭借两年来写Julia的经验、对文件格式的理解、以及对Python代码的分析，我从头构建了整个数据流的逻辑，结果是几十KB的小文件读取快了10倍，1MB左右的快了2倍，30MB以上的基本持平——根据我先前的经验，这部分主要的时间都消耗在了系统I/O上面，越大的文件越是如此；理论上Python的I/O由于是用C实现的，不会比任何语言慢。这不能反映出我的Julia代码写得好，只能说明原先的Python代码的确存在设计问题。\n后来陆陆续续我不断在丰富这个Julia包的功能、构建完整的测试和文档，并且注册到了官方包管理目录中以方便安装使用。基于Python Matplotlib的绘图后端代码，我用200行实现了原先Python中1200行实现的功能。核心的设计理念就是用户不需要额外阅读我写的文档才能知道如何作图：如果他有需求，可以直接在Matplotlib或者其他后端库的详细文档中找到相应的实现方法。这样大大节约像我这样中间开发者的工作，利于长久维护。还是那句话，不是友军太给力，奈何敌军不争气。最开始的时候，我其实也可以选择全面更新已有的Python代码，但是出于对劝服先前维护者改动的疑虑、所有功能重新实现工作量的担忧、以及淘汰老旧错误使用习惯的代价，我放弃了走这条路的念头。用新工具很多时候不得不从头造轮子，但是相应的我们没有历史的负担，不必念及旧情。我花了不少时间尝试一些细节上的优化，许多都是无疾而终，但也并非无功而返：失败带来的都是宝贵的经验，做你不知道的或者别人没做过的尝试才能淬炼手艺。于是临近一年时间这个包的版本号也即将达到0.8,而我的如意算盘则是在手头的新数据分析完发文章的那一天达成1.0的目标。让我们拭目以待。\n\n学习Julia的过程中，我也一直在跟进社区里数据可视化方面的进展。早期的Julia中是没有自己的绘图库的；当时的做法主要是搭好了和各种其他语言的接口，直接调用其他语言中成名已久的绘图包，比如Matplotlib和GGPlot。为了方便使用，Plots.jl的主要作者设计了一套前后端的逻辑，后端是这些调用的库，前端则是统一的Julia语法。然而由于各种后台库之间的差异，使用起来时常会遇到前端不支持的功能或者不能调整的地方，最终还不如直接调用底层库方便。同时逐步诞生的是一个原生的Julia基于OpenGL的绘图库Makie，概念很新颖，但是尤其是早期又慢又难用，开发人手不足缺失众多功能，仍处在尝鲜的阶段。曾经我就这方面的问题在论坛问了很多，最终得出结论在19年当时若想有productive ready的工具还是得用PyPlot，其他包里不足之处还是得靠时间去磨。\n如今两年过去了，传统上time-to-first-plot的知名问题随着新版本的问世得到很大改善，但依旧还达不到Python的水准；Makie临近1.0版本，文档逐步丰富，接口逐渐统一，多图排版得到了显著提升，自定义数据接口也修复了bug,但是默认的流程下启动速度还是太慢。很多人期待着Makie最终能取代Plots.jl成为Julia的招牌绘图库，毕竟亲儿子，需要秀肌肉。按如今的发展势头，再等两年说不定我可以正式向别人推荐这个包了。\n\n我还折腾过好一段时间图形化界面GUI。MATLAB中提供了自定义的GUI编写模块，从最古老的GUIDE，到现在的App Designer。早先是写VisAna的时候想搞一个简单的快速浏览数据的用户界面，弄了一半，数据能通过菜单读取了，能画一张最基础的图。没继续弄的原因，就是我发现这是一个大坑：很多细节的调整非常花时间，并且做出来了可能也没人用。对于像我自己这样的，直接写脚本或者命令行绘图是更高效的方式；对于不想直接敲代码写函数的，可能也不会亲自去画图。于是这个GUI的想法变成了一个很鸡肋的功能，我也半途而废了。一次在运动之后我和睿豪聊起这个事儿，他笑了笑说我应该去搞计算机——我想着设计个没人用的用户界面如此麻烦，还真不适合我这个缺少艺术细胞的人做。 有天跟老板Gabor抱怨模型输入参数检查很费心的时候，他不知道从我们代码库的哪个角落给我翻出来一个基于HTML的GUI，可以修改并检查模型的输入参数。我在组里已经干了好几年了也从没听人谈起过这个，也没见人用过，可见这东西做出来是吃力不讨好。\n最早上Python课的时候，我就玩过相关的GUI开发包，虽然很简陋，但是对我而言很新奇。18年我参加完ISSS13的workshop以后，对一个日本研究组开发的以教学为主要目的的PIC代码很感兴趣。当时这套代码是从Fortran改到MATLAB的，并且添加了个GUI，能调输入参数，也能实时监控输出，的确适合教学；但由于年代久远，GUI部分是用GUIDE写的，正巧App Designer刚出来不久，我借着东风把原始的代码改成了兼容App Designer的版本，大致了解了一个App的实现框架。20年底楚哥跟我抱怨过他老板写的MATLAB程序多么难用，我一看是个裸的脚本加上一个GUIDE的壳，框架好不好另说一没文档说明二没数据测试，也就放弃帮他改进了。如今的MATLAB App Designer明显是更加趋近于Java风格的，毕竟整个MATLAB的前端和可视化部分都是Java实现的。\nJulia中也有封装的一些做App或者图形化界面的包，比如GTK、Electron之类的，但是毕竟不是原生的支持有限，很容易碰壁。结合先前的经验，我也就没有继续探索下去。设计前端的界面真是个体力活，码农那么多，Java那么火，也是因为需要大量人力来完善面向普通用户的图形界面。新时代密集型劳动，码农称谓诚不欺我。\n\n科学绘图有别于艺术绘画，但依旧可以拥有风格甚至幽默。xkcd就是一个风靡在PhD群体中的漫画库。在Matplotlib中使用plt.xkcd()，或者在PyPlot中使用xkcd()，你可能会惊讶地发现加入点小曲折的线段无意间消解了你过于规矩的焦虑："
  },
  {
    "objectID": "posts/wavelet/index.html",
    "href": "posts/wavelet/index.html",
    "title": "Wavelet Transform",
    "section": "",
    "text": "There are already many nice introduction of wavelet transform, like here and the following video. This is my simple note on WT while reading those tutorials.\nBefore we talk about cross-wavelet transform (CWT), we need to first understand wavelet transform (WT). Conceptually wavelet transform is similar to Fourier transform, but with the main difference that wavelets are localized in both time and frequency  whereas the standard Fourier transform is only localized in frequency . This means that for a given time series, Fourier analysis gives you precisely the frequency magnitude and phase across the whole time interval, but you cannot tell when in time the signal is sounded. Wavelet analysis takes the temporal extent into consideration by sacrificing the accuracy of the frequency spectrum.\nThe end result looks similar as if you perform a local Fourier tranform in a small time span around each time stamp (which is how the traditional spectrogram plots are done). The latter, which is also well-known, is called windowed Fourier tranform (WFT), where the FT is performed on short consecutive (overlapping or not) segments. The main limitation of this method is the lack of precision to either the time or the frequency domain. The size of the segment will determine either a high level of precision in the time domain or in the frequency domain. For example, a small window would not allow for the detection of any event larger than the window while maintaining a good localization in time. On the other end, a large window will take into account the long-term event (frequency domain) but with a high level of imprecision in the temporal domain.\nSome more detailed explanation can be found in this Q&A.\nHistorically, the WT method was introduced in seismic research by Morlet (1983). Since then, wavelets are commonly used in geosciences as they are particularly well-suited in characterizing the “local” properties of time-series.\nThe joint characterization of the frequency content of the time-series in time while keeping a high level of precision in both time and frequency domains constitutes one of the WT advantages."
  },
  {
    "objectID": "posts/wavelet/index.html#time-frequency-plane",
    "href": "posts/wavelet/index.html#time-frequency-plane",
    "title": "Wavelet Transform",
    "section": "Time-Frequency Plane",
    "text": "Time-Frequency Plane\n\n\n\nFIGURE 1. Tiling of the time-frequency plane for the wavelet transform (WT) method. Narrow rectangles are used for the high frequencies that give a precise localization in time. Large rectangles are used for the low frequencies that give a precise localization in frequency. This illustrates the trade-off between the accuracy in time and the accuracy in frequency.\n\n\nFor the study of the WT, Flandrin (1988) called the time-frequency plane a scaleogram. In a scaleogram like Figure 1, we are able to perform a multi-scale analysis. One important line often shows up in a scaleogram is the cone of influence: within the region, the WT coefficient estimates are unreliable"
  },
  {
    "objectID": "posts/wavelet/index.html#dilatationcontractiontranslation-of-the-analyzing-function",
    "href": "posts/wavelet/index.html#dilatationcontractiontranslation-of-the-analyzing-function",
    "title": "Wavelet Transform",
    "section": "Dilatation/Contraction/Translation of the Analyzing Function",
    "text": "Dilatation/Contraction/Translation of the Analyzing Function\nA Wavelet is a wave-like oscillation that is localized in time. The WT is calculated by convolving the time-series s(t) with an analyzing wavelet function ψ(a,b) (derived from a mother function ψ) by dilatation of a and translation of b.1\n\na: scale factor that defines how “stretched” or “squished” a wavelet is. It determines the characteristic frequency so that varying a gives rise to a spectrum.\nb: translation in time, i.e. the “sliding window” of the wavelet over s(t). It determines where the wavelet is positioned in time. Location is important because unlike waves, wavelets are only non-zero in a short interval. Furthermore, when analyzing a signal we are not only interested in its oscillations, but where those oscillations take place.\n\n\n\nYour browser does not support the video tag. \nThe basic idea is to compute how much of a wavelet is in a signal for a particular scale and location: a signal is convolved with a set wavelets at a variety of scales. In other words, we pick a wavelet of a particular scale (like the blue wavelet in the animation). Then, we slide this wavelet across the entire signal i.e. vary its location, where at each time step we multiply the wavelet and signal. The product of this multiplication gives us a coefficient for that wavelet scale at that time step. We then increase the wavelet scale (e.g. the red and green wavelets) and repeat the process.\n\n\n\nFIGURE 2. Definitions of Continuous and Discrete Wavelet Transforms.\n\n\nThere are two types of Wavelet Transforms: Continuous (CWT) and Discrete (DWT). Unlike FT, the “continuous/discrete” here does not refer to the property of input data. Definitions of each type are given in the Figure 2. The key difference between these two types is CWT uses every possible wavelet over a range of scales and locations i.e. an infinite number of scales and locations. While DWT uses a finite set of wavelets i.e. defined at a particular set of scales and locations.\nMathematically a great number of analyzing functions (e.g. Mexican Hat, Morlet) could be created (Torrence and Compo, 1998). The choice of the analyzing function is neither unique nor arbitrary and mostly dependent on the likeness between the time-series and the analyzing function. Specific descriptions and recommendations of the properties of the analyzing function can be found in the literature.\n\nMother, Father and Daughter Wavelet\nThe wavelets are scaled and shifted copies (known as “daughter wavelets”) of a finite-length or fast-decaying oscillating waveform (known as the “mother wavelet”).\nWavelets can be defined by the wavelet function ψ(t) (i.e. the mother wavelet) and scaling function φ(t) (also called father wavelet) in the time domain. The father wavelet is also used for smoothing/denoising.\nThe Daughter Wavelet is created changing the time index input of the variable from t to (t-b)/a in the wavelet function. Here is a simple example for creating a daughter wavelet based on the Morlet function with scale a=0.5 and position b=3s:\na = 0.5\nb = 3.0\nt = range(-4, 4, length=200) # Wavelet support for t in [-4, 4] with 200 sample points\ns = @. exp( -((t-b)/a)^2/2 ) * cos(5*(t-b)/a)\nWhen the daughter wavelet has only scaling but no shifting, it is equivalent to the father wavelet."
  },
  {
    "objectID": "posts/wavelet/index.html#statistical-test",
    "href": "posts/wavelet/index.html#statistical-test",
    "title": "Wavelet Transform",
    "section": "Statistical Test",
    "text": "Statistical Test\nIntuitively, the WT coefficients near the edges of the time-series is less trust-worthy than in the middle. This observation can be captured analytically by performing a statistical test. Torrence and Compo, 1998 have demonstrated that, each point of the WT spectrum is statistically distributed as a chi-square with two degrees of freedom. The confidence level is computed as the product of the background spectrum (the power at each scale) by the desired significance level from the chi-square (\\(\\chi^2\\)) distribution. When the WT spectrum is higher than the associated confidence level it is said to be “statistically significant.” Following this statistical test, we can obtain what is usually known as the cone of influence. See the MATLAB documentation for a live example."
  },
  {
    "objectID": "posts/wavelet/index.html#in-production-with-machine-learning",
    "href": "posts/wavelet/index.html#in-production-with-machine-learning",
    "title": "Wavelet Transform",
    "section": "In Production With Machine Learning",
    "text": "In Production With Machine Learning\nA nice post Multiple Time Series Classification by Using Continuous Wavelet Transformation introduces the idea of using continuous wavelet transform as a tool for data cleaning before feeding into convolutional neural networks. This is really a sweet spot where we can combine available math tools together to solve problems."
  },
  {
    "objectID": "posts/wavelet/index.html#tools",
    "href": "posts/wavelet/index.html#tools",
    "title": "Wavelet Transform",
    "section": "Tools",
    "text": "Tools\n\nMATLAB\nMATLAB has a mature wavelet toolbox.\n\n\nPython\nPyWavelets\n\n\nJulia\nThe main package for wavelet in Julia is Wavelets.jl. Note that as of version 0.9.3, this package only supports discrete wavelet tranform. As an extension, ContinuousWavelets.jl implements the continuous wavelet transform, with some examples of scaleograms as well. I’m contacting the authors to see if it’s possible to extend the package even further."
  },
  {
    "objectID": "posts/wavelet/index.html#footnotes",
    "href": "posts/wavelet/index.html#footnotes",
    "title": "Wavelet Transform",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe original inventors of WT used jargons like “dilation/contraction/translation” to describe the processes. I prefer to call them scale and shift.↩︎"
  },
  {
    "objectID": "posts/san-francisco/index.html",
    "href": "posts/san-francisco/index.html",
    "title": "三番杂记",
    "section": "",
    "text": "在湾区坐了一天车，开了一天车，地方没多大，堵车可一点也不少。我之前错误地估计了三番的地理区划，多待的一天选择住在了市中心，结果三番市里离圣何塞竟有一个小时车程，折腾来去大费周章在了路上。湾区车多，路线选择却仅有两条，上下班的高峰期天天堵车，红色的尾灯连成一片，无可奈何中或许焦虑感顿增——然而也有些许的温情。回三番的路上，夜幕降临，租的车不熟，忘了开前灯。缓慢挪动的档口，左侧一辆白色轿车忽地鸣了一声喇叭。起初我一晃神，以为是打招呼，或是甚么飙车的信号；四下一看，发现原来前侧漆黑一片，似是未开车灯。这位仁兄见我不久打开了头灯，便一脚油门扬长而去。而后走走停停，又一次追上的时候，我朝着窗外做了手势以表谢意。人人皆谈孤独，我却隔着两扇车窗，在三番的夜色中觅得了一抹温情。下高速的路口经过一个高坡，顷刻间整座城市饱览在我的眼下。长夜漫漫，似是故人来。"
  },
  {
    "objectID": "posts/san-francisco/index.html#驾车",
    "href": "posts/san-francisco/index.html#驾车",
    "title": "三番杂记",
    "section": "",
    "text": "在湾区坐了一天车，开了一天车，地方没多大，堵车可一点也不少。我之前错误地估计了三番的地理区划，多待的一天选择住在了市中心，结果三番市里离圣何塞竟有一个小时车程，折腾来去大费周章在了路上。湾区车多，路线选择却仅有两条，上下班的高峰期天天堵车，红色的尾灯连成一片，无可奈何中或许焦虑感顿增——然而也有些许的温情。回三番的路上，夜幕降临，租的车不熟，忘了开前灯。缓慢挪动的档口，左侧一辆白色轿车忽地鸣了一声喇叭。起初我一晃神，以为是打招呼，或是甚么飙车的信号；四下一看，发现原来前侧漆黑一片，似是未开车灯。这位仁兄见我不久打开了头灯，便一脚油门扬长而去。而后走走停停，又一次追上的时候，我朝着窗外做了手势以表谢意。人人皆谈孤独，我却隔着两扇车窗，在三番的夜色中觅得了一抹温情。下高速的路口经过一个高坡，顷刻间整座城市饱览在我的眼下。长夜漫漫，似是故人来。"
  },
  {
    "objectID": "posts/san-francisco/index.html#学校",
    "href": "posts/san-francisco/index.html#学校",
    "title": "三番杂记",
    "section": "学校",
    "text": "学校\n斯坦福，顶尖院校，美国乃至全世界最有钱的大学。在斯坦福的校园里，我们同学三人异口同声地感叹：壕。我们到的时间恰好赶上了寒假前最后一次免费校园导游，两名刚考完试的学生带着我们步行游览。斯坦福蝉联了全美NCAA冠军榜20年，上一次的奥运会单列斯坦福学生的奖牌榜能列世界第六，可见其对于体育方面的投入。然而在主要集体项目中斯坦福却并不突出，更显示出他们对于个人竞技项目的关注，以及不差钱的底蕴。三个礼堂，二十个图书馆，百分之八十的本科生学费减免，每个学期的公费出游活动……各个方面都是。而这一切最集中的体现莫过于带领我们的导游。他应是墨西哥裔，来自佛罗里达，大三，计算机和经济双学位，宿舍长，也是多个学生社团的主席。连珠炮一样的语速中无时无刻不体现着自信，真是恰如其分地代表着斯坦福的精神，美国的精神。他们这种从小培养起来的溢出的自豪感，和东方传统的内敛对比鲜明。这是文化塑造的人性，并无高下之分。 相比于同样很大的密歇根，斯坦福地势平坦，校园集中，近处几无遮拦，远处群山环绕，天高地远，更显磅礴通透。一方水土一方人。"
  },
  {
    "objectID": "posts/san-francisco/index.html#公司",
    "href": "posts/san-francisco/index.html#公司",
    "title": "三番杂记",
    "section": "公司",
    "text": "公司\n论及湾区，怎能不谈遍布的科技公司。\n在斯坦福游客接待中心的墙上，贴了一幅展示科技巨头分布的俯瞰图。这就是引领当今世界科技走向的前沿阵地。恰好有同学在Google Photos上班，借着机会头一次到这家享誉世界的公司参观。"
  },
  {
    "objectID": "posts/san-francisco/index.html#饮食",
    "href": "posts/san-francisco/index.html#饮食",
    "title": "三番杂记",
    "section": "饮食",
    "text": "饮食"
  },
  {
    "objectID": "posts/san-francisco/index.html#流浪汉",
    "href": "posts/san-francisco/index.html#流浪汉",
    "title": "三番杂记",
    "section": "流浪汉",
    "text": "流浪汉"
  },
  {
    "objectID": "posts/san-francisco/index.html#同学",
    "href": "posts/san-francisco/index.html#同学",
    "title": "三番杂记",
    "section": "同学",
    "text": "同学\n罗铤在搞VR，说起来也是很有趣。他们老板成立了公司在尝试教育科普方面的VR应用，他每天搭一个小时的车到合肥新创区上班。公司不大，困惑不少。关键在于如何找到合适的应用场景。他给我展示了基于NASA提供的SDO数据做的日面可视化立体图：论数据的质量，国内目前还没有能和NASA匹敌的提供方。"
  },
  {
    "objectID": "posts/san-francisco/index.html#街头的布道者",
    "href": "posts/san-francisco/index.html#街头的布道者",
    "title": "三番杂记",
    "section": "街头的布道者",
    "text": "街头的布道者\nGod believes in us."
  },
  {
    "objectID": "posts/san-francisco/index.html#博物馆",
    "href": "posts/san-francisco/index.html#博物馆",
    "title": "三番杂记",
    "section": "博物馆",
    "text": "博物馆"
  },
  {
    "objectID": "posts/basketball/index.html",
    "href": "posts/basketball/index.html",
    "title": "BU篮球半年记",
    "section": "",
    "text": "来BU打球半年有余，从一开始的不太适应到现在持续地和各种水平的选手过招，见识了不少人，也见证了自己的成长。常来的球友不少，偶尔光顾的众多，不断地观看和切磋，为了自己热爱的运动挥洒汗水。"
  },
  {
    "objectID": "posts/basketball/index.html#对手印象",
    "href": "posts/basketball/index.html#对手印象",
    "title": "BU篮球半年记",
    "section": "对手印象",
    "text": "对手印象\n\nBU华人球队的教练：他的力量略强于我，速度略逊于我。防守时喜欢对位协防人，体能的原因喜欢偷懒；进攻端持球核心打法，传球威胁很大，投篮能力强于BU华人球队所有队员，大概传六投四的比例。他不好防，因为有篮不能放太远，运球不追求速度但是节奏感很好，上篮慢悠悠的但低手上篮的手感不错。对位几次后，找到的最佳策略是逼他中距离急停跳投，受限于身体素质，无论是绕掩护还是生突的爆发力都不够，空位流畅舒展的投篮动作受到挤压后变形命中率下降很多。\nBU华人球队控卫：个子矮，大约165.爆发力极好，跳起来能摸筐。投篮弧度极高，在比赛强度的无球跑位中有能力瞬间甩开对手完成动作，是该队外线第一人。传球手法到位，传五投五的比例。然而突破攻击篮筐的效率很低，无论运球再流畅、速度再出色，到了篮下总是会被干扰进而打铁。两方面原因，其一是力量对抗不足，容易失去平衡；其二是臂展和手臂力量不足，起球后容易失去对球的控制。\nBU华人球队新人锋线：182左右，臂展长，身体素质好。喜欢单手完成上篮。投篮有明显甩的动作，不好封盖，命中率不稳，喜欢尝试高难度。年轻气盛，喜欢顶有球单防，但是容易吃假动作和掩护。组织串联意愿很低。在我看来属于全面弱化版的启轩Steven。\nBU华人球队得分后卫：跟我差不多高，速度快，第一次跟他打球的时候连连感慨自己跟不上年轻人的步伐了。投篮姿势是推的，辅助手有发力，有点篮子但没那么准。快攻的时候展示过欧洲步十分惊艳。\nJohn Wong: 香港人，左撇子。他的投篮和一般人不同，落脚时习惯右脚在前左脚在后，但是接球投篮的命中率相当可观。空切嗅觉很好，也有点抛投，但是运球能力一般，只走左边，防守时只要贴着堵左边就能限制。面如死灰，球场上毫无情感波澜。\nRyan: 左撇子白人，偷下能力非常强。上篮都是几乎脚不离地的低手舔篮，反篮也有两下子。三分神经刀，姿势不标准，出手点低但速度快。标准魔球打法，没有中距离。\nBrian：个子180，身体强壮的内线。进攻全凭三板斧：快下、定点三分、背转身跳投。下快攻跑得比后卫还快。包夹出球意愿不错，手法一般。各项指标中最突出的是体力，作为有着健美身材的选手非常难得。\n白衣韩国哥：强，全方位的。投篮准，不能放；突破放左边，人家就是能顶着进来上篮；进攻有条理，不勉强；下快攻速度快，我都不一定追得上。\n打过一次半场3V3的白人：那次周六早上全场前的3V3，是这半年打的强度最大的半场。对位的白人球员我完全防不住，扛着我的投篮导致我完全无法起跳，往里打的背身由于身体差距也是只能望洋兴叹。后来有个和我单挑过两局11分的白人，和这位哥们有些类似，但是没有远投，只用中距离和背打就连赢我两局。输的点在于省体力的三威胁投篮稳定性不足，也是敦促我加强该技术的动力。\n只出现过一次的白人巨星：在BU球场见过的扣篮最轻松的球员。一米九几的外线，那天看到的时候根本没认真打，抢篮板一点儿不跳。仅一球，一个体前变向衔接三步扣篮，举球过框带曲臂，那些个黑人球员也少有能完成的。我一度认为是NCAA校队私自溜出来打野的。\n出现过两次的2米白人：2米110公斤的外线球员。准，八成终结外线完成。有运球能力而没有速度，通过身体对抗和身高制造空间完成投篮。属于重型外线炮台。\n双色鞋的黑人：没有直接对位过。进攻节奏极其出色，三分撤步跳投非常流畅，个人进攻技巧野球翘楚。根据我对位类似黑人球员的感觉，他们的核心力量都非常好，撞一下跟撞上墙似的。但大部分的此类球员都不喜欢传导球，所谓传球都是奔着助攻去的，缺乏整体性的打球思路。\n半职业黑人：瘦高臂展长，见过三回。其貌不扬，但非常厉害，防守端的判断和下手准度出类拔萃。曾经在一场15分的比赛里完成两次转换球权的上篮切球和一次正面外线防守的生断快攻。进攻端的个人快攻终结能力很强。传球能力并没有体现。\n白衣黑人：性格友善，上肢强壮，终结多在外线。喜欢撤步跳投，但是弧度不高，命中率有却不稳定。他抗住我对抗后的跳投终结基本全看自己手感。上次对位时不知是不是先练了力量，篮下手感糟糕一个没进。防我进攻时脚步有些跟不上。\n暴躁黑人：老哥来得挺勤快，一周两三次。脾气非常暴躁，时常和人发生争执和口角。身体强壮，对位几乎所有防守者都有能力完成突破；上篮时收球的手臂如同螃蟹的钳子，跟哈登一样，犯规和加罚的概率很高。传球技巧和视野非常好，绝对的传球优先。弱电是投射，外线几乎没有威胁。他的传球能力是建立在强健的身体基础之上的，体格类似德隆威廉姆斯。"
  },
  {
    "objectID": "posts/basketball/index.html#个人训练",
    "href": "posts/basketball/index.html#个人训练",
    "title": "BU篮球半年记",
    "section": "个人训练",
    "text": "个人训练\n我十分清楚自己参与篮球运动的短板：身体素质一般，缺乏对抗力量和吨位，运球意愿不足，高强度下动作稳定性不佳。具体反映到球场上，就是体能跟不上跑不动，防守内线吃力，运球稳定性差，比赛中投篮命中率下降。\n不想通过增重的方式提高对抗的前提下，更倾向提高肌肉的密度和可持续性。篮球的对抗讲究的是抗击打性，即高频率小力量的输出；这点和拳击有异曲同工之处。一场比赛并非通过单独一次举重式的绝对力量爆发而获胜，而是反复持续的有氧无氧切换，寻找全局层面的最优解。观看高水平运动员的训练，极少有大重量的器械锻炼，倒是充满了各种小肌肉群的小重量、多组数训练。这是在认识自己身体条件的基础之上为了特定的运动目标找到合适训练项目的过程。\n有了身体作为基础，才可能谈及其它技术层面的东西。目前所有的终结训练项目以及比赛中使用情况：\n\n\n\n\n\n\n\n\n项目\n比赛使用频率\n说明\n\n\n\n\n抛投\n常用\n大部分左手，右侧的左手抛投不稳定\n\n\n左右勾手\n常用\n左手为主，原地对抗发力转身会有吃不住人的情况\n\n\n低手上篮\n常用\n右侧突破也是左手居多\n\n\n顺步挑篮\n偶尔\n有对抗命中率不高\n\n\n正手反篮\n常用\n稳定\n\n\n反手反篮\n极少\n因为两只手都是顺手，比赛几乎不用该动作\n\n\n转身上篮\n偶尔\n行进间使用不够熟练\n\n\n欧洲步上篮\n极少\n吃膝盖和腿部力量\n\n\n体前绕球上篮\n极少\n对手部力量和大小有要求，很容易脱手\n\n\n身后绕球上篮\n无\n训练偶尔练习\n\n\n背身跳投\n极少\n练习的时间不短，比赛中使用极少，因为缺少有防守人的感觉，并且落地平衡难以保证，很容易摔倒。\n\n\n背身转身挑篮\n偶尔\n我的右腰外侧转身up & under属于无师自通。然而完整的版本包括两侧共四个角度，有练过，但比赛中没有使用过。\n\n\n三威胁跳投\n偶尔\n软肋，举球动作速率和正常投篮不同；近半年有所进步\n\n\n中距离左右急停\n极少\n左侧脚步调整慢，右侧发力会着急\n\n\n中距离正面急停\n极少\n练习稳定，但比赛中使用场景极少\n\n\n中距离撤步跳投\n极少\n难度高，核心力量要求高\n\n\n绕掩护急停\n偶尔\n对脚步有要求\n\n\n三分定点\n常用\n主要得分手段，稳定性不断提升\n\n\n三分接球投篮\n常用\n对传接球能力和脚步调整技术有要求，命中率不如定点\n\n\n三分侧撤步\n极少\n难度高，命中率不稳定\n\n\n三分后撤步\n无\n难度极高，也不常练习\n\n\n\n整体上通过多次运球完成的终结效率都会下降，和克莱倒是有几分相像。个人常用动作里面三威胁的干拔是弱项，这个本该是最轻松的得分方式，反倒是我最不稳定的投篮技术。问题可能在于在做完低重心的原地晃动以后，举球抬重心出手的过程中下肢力量没有很好地传递到手上。一直在改进，取得了些许进步。另外一点，也是持续要提醒自己的一点，提高运球比重，增强运球对抗的信心。\n热身套餐经过这些年的打磨，已经形成了固定套路。行进间抛投似乎是个缺失的部分，可以考虑把升级第四级的投篮变成抛投。一套下来从拉伸到抛投12球、中距离跳投6球连进、罚球10球、三分50球，目前需要大概40分钟。三分50球有记录的自投自抢最高命中率是58%。FIBA三分线和美国常见的高中线有一定差别，投FIBA线有时候还是会感觉力量欠缺。\n篮球的个人技术十分琐碎，需要每个人自己根据需求不断打磨。而个人技术和团队意识又是两个截然不同的东西，很容易造成顾此失彼的问题。我关注到的近些年国内青少年篮球培训，全部都是个人技术训练，没有任何讲解和练习团队配合的部分。这样训练出来的少年，在类似路人王这种单挑比赛的加持下，会不会认为篮球更多是个个人项目而非团队项目？而在我看来，篮球的乐趣更多在于它的团队属性，这是个人体育项目所不能比拟的。在国内打球，许多孩子的技术挺不错，但是并不能称得上会打球，是因为对于场上空间和时间的理解太浅，全然在乎的只有运球的自身和唯一的防守者。然而大局观是个很玄乎的东西，更切实际的或许是移动意识的培养：要告诉球员，手里没球的时候同样可以制造威胁、做出贡献。\n好想打比赛啊。"
  },
  {
    "objectID": "posts/linux/index.html",
    "href": "posts/linux/index.html",
    "title": "Linux Distros and WSL2",
    "section": "",
    "text": "Being annoyed by the CENTOS linux distro from Redhat, I’ve decided to take a look at some latest distros available. There are several amazing ones already! If I have time, I would love to try this Garuda ASAP. There has never been a linux version that shocked me at first sight; this one did. It is an unbelieveable attempt that with this level of frontend design they claim that it is performance-focused, with all the latest tools at your hand. One quote that caught my eye was &gt; Any unused memory is waste memory.\nIf I decide to have my own desktop server, this will be my OS."
  },
  {
    "objectID": "posts/linux/index.html#wsl2",
    "href": "posts/linux/index.html#wsl2",
    "title": "Linux Distros and WSL2",
    "section": "WSL2",
    "text": "WSL2\nI started playing with the Windows Sub-Linux system since its initial version. WSL1 is a good attempt, but not good enough: it is not a real linux kernel such that a lot of softwares has compatibility issues. WSL2 is a huge improvement. More than a year later after its debut, I have no complains about anything I want from linux. With native VSCode remote support, Nvidia shared CUDA driver between Windows and Linux, and XWindow display, this can now be claimed finished for scientific software developers. Amazing! This also lifts my burden of dual OSs on one machine. Definitely a game changer.\nAround mid 2021, Microsoft released wslg for native GUI support. This means that we no longer need any 3rd party Xwindow server to display graphics! If anything is not working properly at first, check the GitHub repo and look for the troubleshooting wiki page first. My issue was that because my previous x server changed DISPLAY environment variable, the new built-in x window server could not work properly. The easy fix is to comment out the related setting in the shell config file."
  },
  {
    "objectID": "posts/linux/index.html#motivation",
    "href": "posts/linux/index.html#motivation",
    "title": "Linux Distros and WSL2",
    "section": "Motivation",
    "text": "Motivation\nOne big reason Microsoft is taking incorporating Linux seriously is their shift from a PC system and software company to a cloud service provider. Since they are making big money with Azure, they have been consistently contributing to Linux kernel and providing more and more support for Linux integrity into the Windows world."
  },
  {
    "objectID": "posts/linux/index.html#reason-for-linuxs-success-on-supercomputers",
    "href": "posts/linux/index.html#reason-for-linuxs-success-on-supercomputers",
    "title": "Linux Distros and WSL2",
    "section": "Reason for Linux’s Success on Supercomputers",
    "text": "Reason for Linux’s Success on Supercomputers\n\nFree –&gt; low cost\nCustomizable –&gt; easily adapted to a new machine\nEasy transition from Unix –&gt; similar syntax, no steep learning curve for Unix users"
  },
  {
    "objectID": "posts/matplotlib/index.html",
    "href": "posts/matplotlib/index.html",
    "title": "Matplotlib",
    "section": "",
    "text": "Matplotlib is a great library, but there are still issues. Over 20 years of development and 3 major version releases, Matplotlib has evolved into a giant library."
  },
  {
    "objectID": "posts/matplotlib/index.html#stepping-through-versions",
    "href": "posts/matplotlib/index.html#stepping-through-versions",
    "title": "Matplotlib",
    "section": "Stepping Through Versions",
    "text": "Stepping Through Versions"
  },
  {
    "objectID": "posts/matplotlib/index.html#calling-from-julia",
    "href": "posts/matplotlib/index.html#calling-from-julia",
    "title": "Matplotlib",
    "section": "Calling from Julia",
    "text": "Calling from Julia"
  },
  {
    "objectID": "posts/matplotlib/index.html#issues",
    "href": "posts/matplotlib/index.html#issues",
    "title": "Matplotlib",
    "section": "Issues",
    "text": "Issues\n\nBackend Support\nMatplotlib comes with a bunch of backend graphic support. Different backends come with different dependencies, which may or may not work on your machine. However, most of the users only use 1 or 2 of them. Nowadays the Tk backend works pretty well and is available everywhere. In practice as a 3rd party tool developer we may just use it (or the Agg backend for non-interactive code) and drop support for all of the other backends (which complicate the code a lot for not much benefit).\n\n\nTicks And Labels\nThese are some annoying little stuff that frequently show undesired behaviors here and there. There are two key concepts/classes: Locator and Formatter. Locator controls where the ticks are drawed, whereas Formatter decides the label formats. For example, sometimes the labels will overlap with each other; sometimes the default format is really not what you want, so you need to tweak it carefully.\n\n\nSubfigures\nSubfigures are considered as experimental as of Matplotlib v3.5. I happened to discover a bug related to the callback methods of quiver that will be fixed in v3.5.2."
  },
  {
    "objectID": "posts/juliacn-2021/index.html",
    "href": "posts/juliacn-2021/index.html",
    "title": "Development Report For Vlasiator.jl",
    "section": "",
    "text": "最近给了一个线上的有关Vlasiator.jl的报告,\n\n\n顺带稍微介绍了一下我们的学科，以及空间数值模拟的基础概念。依旧没有达到我很满意的程度，但是可以一点点提高，无论是实际的内容、时间的控制、 配套的讲解、和遇到突发情况的准备。\n很久没有给过中文演讲了，自诩水平差强人意，其实在放大镜下观察仍然漏洞百出。即便有过众多演讲比赛和主持的经历，我几乎没有听过自己的声音，就是担心各种不熟练的表达和怯场叨扰了受众的耳朵。然而讲过了不去面对自己，永远不会提高。思路的连贯性可以训练，表述时的卡壳可以控制，而当面演说时的面部表情和身体姿态也可以调整。一方面，是你想讲什么，是否能清晰地表述；另一方面，是听众想听什么，如何根据他们的背景选择合适的内容。希望有朝一日，我能自如地在任何场合把握自己的演讲。\n这是个有爱的组织，我们有着不尽相同的背景，却有着相似的追求。开源与分享，星星之火、可以燎原。"
  },
  {
    "objectID": "link.html",
    "href": "link.html",
    "title": "Links",
    "section": "",
    "text": "Plasma Key Notes\nTestParticle.jl\nResearch Log\nMy Personal Vlasiator Manual\nCFD in Practice\nVlasiator.jl\nBatsrus.jl\nData Processing in Space Physics\nFieldTracer.jl\nIdeal MHD Toy Model\nMultigrid Solver in MATLAB\n1D PIC in Julia1\nCoding in Julia\nCoding in Fortran\nCoding in C++2\nWorking on Clusters3\nVlasiator: simulating near-Earth space with high-performance computing"
  },
  {
    "objectID": "link.html#tools",
    "href": "link.html#tools",
    "title": "Links",
    "section": "Tools",
    "text": "Tools\nexcalidraw\nexcalidraw-math\ntinypng\nMP4COMPRESS\nCompiler Explorer"
  },
  {
    "objectID": "link.html#footnotes",
    "href": "link.html#footnotes",
    "title": "Links",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nthe repos may currently be private.↩︎\nthe repos may currently be private.↩︎\nthe repos may currently be private.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "景田日志",
    "section": "",
    "text": "Computer Hardwares and Drivers\n\n\n装机记录\n\n\n\nprogramming\n\nhardware\n\n\n\n\n\n\n\n\n\nAug 17, 2025\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nDes Moines之行\n\n\nGEM二刷\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nJun 29, 2025\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nTV Display Techniques Review\n\n\n\n\n\n\ntech\n\n\n\n\n\n\n\n\n\nJun 14, 2025\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n染发剂\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nAug 19, 2024\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning Overview and Examples\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nAug 10, 2024\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on Large Language Models\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nJul 25, 2024\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nBU篮球半年记\n\n\n\n\n\n\nsports\n\n\n\n\n\n\n\n\n\nJul 7, 2024\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nBasketball Court in Shenzhen\n\n\n\n\n\n\nsports\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of Time-Frequency Transforms\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nMar 17, 2023\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nProfiling\n\n\nWith Intel OneAPI\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nFeb 9, 2023\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nHaskell\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nFeb 9, 2023\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nR Notes\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nJan 6, 2023\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nNushell\n\n\nA new type of shell\n\n\n\nsoftware\n\n\n\n\n\n\n\n\n\nSep 25, 2022\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nExperiment Design\n\n\nHow to perform trustworthy experiments\n\n\n\nscience\n\n\n\n\n\n\n\n\n\nAug 20, 2022\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nMatplotlib\n\n\n\n\n\n\nsoftware\n\n\n\n\n\n\n\n\n\nMay 22, 2022\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nPractical Tricks in Signal Processing\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nApr 1, 2022\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nRust\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nJan 25, 2022\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n瑞典游记\n\n\n\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nJan 23, 2022\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nThe Effectiveness of Modern CPUs\n\n\n\n\n\n\nhardware\n\nprogramming\n\n\n\n\n\n\n\n\n\nJan 23, 2022\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nGravity Wave\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nJan 10, 2022\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nJavaScript\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nJan 5, 2022\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nBlunt Body Problem in Hydrodynamics\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nDec 22, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nParallel Programming Concepts\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nDec 19, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nKinetic Plasma Simulations\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nDec 16, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nDevelopment Report For Vlasiator.jl\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nDec 16, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nFourier Analysis\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nNov 18, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nCross-Wavelet Transform\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nNov 12, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nLinux Memory\n\n\n\n\n\n\nhardware\n\nsoftware\n\n\n\n\n\n\n\n\n\nOct 18, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nUbuntu Soundtrack\n\n\n\n\n\n\nhardware\n\nsoftware\n\n\n\n\n\n\n\n\n\nOct 18, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n简报制作\n\n\n\n\n\n\nvisual\n\n\n\n\n\n\n\n\n\nOct 15, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Python\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nOct 15, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nRefactoring\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nOct 8, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nEvolution of Programming\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nOct 1, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nN-Body Simulation\n\n\n\n\n\n\nmath\n\nprogramming\n\n\n\n\n\n\n\n\n\nSep 29, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nGreen’s Function\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nSep 24, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nGeometric Algebra\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nSep 17, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nKalman Filter\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nSep 10, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nDebugger\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nApr 14, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nData Transfer\n\n\n\n\n\n\nsoftware\n\n\n\n\n\n\n\n\n\nApr 7, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nIO Hardwares\n\n\n\n\n\n\nhardware\n\n\n\n\n\n\n\n\n\nApr 7, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n语言小论\n\n\n\n\n\n\nlanguage\n\n\n\n\n\n\n\n\n\nMar 20, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nMake for a Better World\n\n\nTowards a robust compilation process\n\n\n\nprogramming\n\nsoftware\n\n\n\n\n\n\n\n\n\nMar 12, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nCompilers\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nFeb 26, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nChromium Browsers\n\n\n\n\n\n\nsoftware\n\n\n\n\n\n\n\n\n\nFeb 24, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nRemote Access through SSH\n\n\n\n\n\n\nsoftware\n\n\n\n\n\n\n\n\n\nFeb 19, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nLinux Distros and WSL2\n\n\n\n\n\n\nsoftware\n\n\n\n\n\n\n\n\n\nFeb 19, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nCommand Line Tools\n\n\nUseful tips and tricks\n\n\n\nsoftware\n\n\n\n\n\n\n\n\n\nFeb 11, 2021\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Installation\n\n\nWhere we can do better\n\n\n\nsoftware\n\n\n\n\n\n\n\n\n\nNov 14, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n启程赫尔辛基\n\n\n\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nNov 5, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nCappella\n\n\n\n\n\n\nmusic\n\n\n\n\n\n\n\n\n\nOct 18, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nARM-64 Architecture\n\n\nPerformance Benchmark\n\n\n\nhardware\n\nprogramming\n\n\n\n\n\n\n\n\n\nSep 10, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n我与数据可视化的那点事儿\n\n\n\n\n\n\nvisual\n\n\n\n\n\n\n\n\n\nSep 10, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nPracticing C++\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nSep 2, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nMac Setup\n\n\nSoftware installation and usage on Mac OS\n\n\n\nsoftware\n\n\n\n\n\n\n\n\n\nAug 20, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nPassing Arguments\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nAug 4, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nGit Version Control\n\n\n\n\n\n\nvisual\n\n\n\n\n\n\n\n\n\nJul 24, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nEditors\n\n\nEmacs, Vim, Atom, VSCode, and Typora\n\n\n\nsoftware\n\n\n\n\n\n\n\n\n\nJul 24, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nLearning AMReX\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nJul 18, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nLyrics Collection\n\n\n\n\n\n\nmusic\n\n\n\n\n\n\n\n\n\nJun 29, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nColormaps\n\n\n\n\n\n\nvisual\n\n\n\n\n\n\n\n\n\nJun 10, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nFigure Processing\n\n\n\n\n\n\nvisual\n\n\n\n\n\n\n\n\n\nJun 1, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nWavelet Transform\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nJun 1, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nInternet Connection\n\n\n\n\n\n\nsoftware\n\nhardware\n\n\n\n\n\n\n\n\n\nApr 19, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nObject Oriented Programming\n\n\nPersonal experiences\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nApr 15, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nShared Library\n\n\nWhat is it and how to use it\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nApr 4, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nMagic Angle\n\n\nThe magic behind MRI and reinforced rubber hose\n\n\n\nscience\n\n\n\n\n\n\n\n\n\nMar 3, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nMPM与CG特效\n\n\n\n\n\n\nprogramming\n\nvisual\n\n\n\n\n\n\n\n\n\nJan 12, 2020\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n任天堂大乱斗\n\n\nAGU\n\n\n\ngame\n\n\n\n\n\n\n\n\n\nDec 28, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nBehaviour of BibLaTeX\n\n\nDetails you may neglect\n\n\n\nlatex\n\n\n\n\n\n\n\n\n\nDec 20, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n三番杂记\n\n\nAGU\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nDec 20, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nUsing latexdiff\n\n\nCompare and show the differences between files\n\n\n\nsoftware\n\nlatex\n\n\n\n\n\n\n\n\n\nNov 8, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nOle Solskjaer Returning to MU\n\n\n\n\n\n\nsports\n\n\n\n\n\n\n\n\n\nOct 27, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nParaview Usage Notes\n\n\n\n\n\n\nvisual\n\n\n\n\n\n\n\n\n\nOct 27, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nMaking Videos from Figures\n\n\n\n\n\n\nvisual\n\n\n\n\n\n\n\n\n\nOct 25, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nRemote Access through X11\n\n\nXWindow forwarding\n\n\n\nvisual\n\n\n\n\n\n\n\n\n\nOct 25, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nBiostation Retreat\n\n\n\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nSep 15, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n新加坡之行\n\n\nAOGS初体验\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nAug 6, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n仙台之行\n\n\n又是一年MOP\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nJun 22, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n麦迪逊游记\n\n\n比赛，亦或旅游\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nApr 1, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to CNN\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nJan 25, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting of Streamlines\n\n\n\n\n\n\nvisual\n\n\n\n\n\n\n\n\n\nJan 24, 2019\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nDC 三番记\n\n\n\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nDec 15, 2018\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n洛杉矶杂记\n\n\nISSS\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nSep 14, 2018\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n东游记\n\n\n从安娜堡到纽约\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nJul 30, 2018\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n科罗拉多杂记\n\n\n又是一年MOP\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nJun 20, 2018\n\n\nHongyang Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n墨西哥杂记\n\n\n圣诞新年七日谈\n\n\n\ntravel\n\n\n\n\n\n\n\n\n\nJan 1, 2018\n\n\nHongyang Zhou\n\n\n\n\n\nNo matching items"
  }
]